,url,Position,Company,Location,Job_Description
1,https://www.glassdoor.co.in/partner/jobListing.htm?pos=227&ao=437149&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_8d7d58d1&cb=1562003628530&jobListingId=3267628912,Data Scientist,GO-JEK, – Bengaluru,"Responsibilities:

Work as part of a product team in defining, prototyping and implementing data science models/algorithms as part of the product.

Take ownership of the data science model end-to-end - from data collection to model building to monitoring the model in production.

Along with product managers, own the business outcomes/metrics which the data science model/algorithm drives.

Participate in conferences, attend and help organise meet-ups.

Mentor junior colleagues, conduct internal workshops and external meet-ups, participate in external conferences and give talks.

Help to make data science and data-driven decision making a part of the organisation's DNA.

Requirements:

Solid understanding of the mathematics related to data science - probability, statistics, linear algebra etc.

Ability to understand business concerns and formulate them as technical problems that can be solved using data and math/stats/ML.

Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.

Experience working with large data sets, coming from varied sources, is a plus.

Familiarity with data engineering technologies (Kafka/Flink/Spark etc) is a plus.

Masters in a quantitative discipline with 5 - 9 years experience working as a Data Scientist in a product company (OR).

PhD in a quantitative discipline with 2 - 5 years working as Data Scientist in a product company."
2,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1004&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_2be395a0&cb=1562003715324&jobListingId=3201562242,Data Analyst,Proziod Analytics, – Bengaluru," Proziod Analytics Pvt Ltd is looking for Data Analyst with 1+ years' Energy Domain experience What you'll do: Working in SAP utilities process, meter configurations, specialized in meter exchange and to update the readings  Associated with both internal meter and basic meter billing  Efficiently post all payments and report month to month finances for several clients  Well verse in centricity practice management including settings and daily operation processes  Comfortable with working insurance denials to increase overall practice's revenue  Delegated to cross-train employees to promote individual skill sets  Entrusted to complete specialize projects in effective and timely manner  Responsible for the automation of electronic remittance processor within centricity for several clients.  Simplified reporting process by developing excel templates using excel functions and macros."
3,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2816&ao=132976&s=58&guid=0000016baeafa65a98836b4f5999adf7&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5a8fb391&cb=1562003875873&jobListingId=3225555825,Consumer Banking Technology - UK Consumer Deposits Technology - Data Engineer,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBWhat We DoAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.Who We Look ForGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.What We Do At Goldman Sachs, our Engineers don’t just make things – we make things possible. We change the world by connecting people and capital with ideas and solve the most challenging and pressing engineering problems for our clients. Our engineering teams build scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Engineering, which is comprised of our Technology Division and global strategist groups, is at the critical center of our business. Our dynamic environment requires innovative strategic thinking. Want to push the limit of digital possibilities? Start here. Who We Look For Goldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.

Consumer and Investment Management (CIMD)

The Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.

Consumer

Consumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses. It also includes our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of insights and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• As a Security Engineer in Commercial Banking, you will be responsible for securing the applications (Web/API/Mobile) managed by the business unit.• The position is hands-on and requires close collaboration with Product Management, Engineering, Program Management, and Dev Ops teams.• In addition to developing / maintaining / operating / integrating security Infrastructure, you will act as a security advisor to architects, developers, analysts and others to ensure we embed security into the platform.• Drive adoption of embedded application security controls as part of the Software Development Life Cycle (SDLC) in Agile methodology• Automate security test cases for continuous controls monitoring• Review requirements / architecture to ensure security and privacy by design• Secure Code Reviews and Penetration Testing• Serve as an advisor for security related product features like authentication, cryptography, etc.SKILLS AND EXPERIENCE WE ARE LOOKING FOR• 10 years’ experience in application security or related fields and risk analysis techniques• Expert knowledge of application security best practices including OWASP and CWE• Strong software engineering background; programming experience in Java and Python preferred• Secure software development practices and frameworks• Security testing methodologies, tools and techniques with understanding of common application security vulnerabilities and controls to remediate• Hands-on experience with web and mobile application security code reviews written in popular programming languages (Java, JavaScript, C++, C#, Python, Perl, optionally Objective-C, etc.)• Hands-on experience with web application Penetration Testing• Hands-on experience with cloud security/designing secure systems on AWSPreferred Qualifications• Proficient communication skills and an effective team player• Experience working in Agile development and scrum teamsABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
4,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1314&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e88db500&cb=1562003740655&jobListingId=3271820263,Data Engineer,LifeSight, – Bengaluru,"Responsibilities:

Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities.

Implementing ETL process.

Monitoring performance and advising any necessary infra structure changes.

Defining data retention policies.

Requirements:

B.Tech in Computer Science or related fields with 3-5 years of professional experience.

Proficient understanding of Java / Scala.

Proficient understanding of distributed computing principles.

Proficiency with Map Reduce, Hadoop, Spark.

Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.

Good knowledge of Big Data querying tools, such as Pig, Hive, Cassandra and Impala.

Experience with Flink, Kafka Streams.

Experience in developing ETL pipelines using EMR or other schedulers like Oozie, Airflow etc.

Experience with NoSQL databases, such as Aerospike, HBase, MongoDB.

Good understanding of Lambda Architecture, along with its advantages and drawbacks.

Experience with Big data stores such as Redshift, ElasticSearch, Druid.

Worked closely with the data science team.

Experience with OLTP and OLAP.

Experience with AWS / GCP.

Data Warehousing, ETL, Flink, Hadoop, Hive, Kafka, NoSQL, Pig, Search, Spark, Storm, Aerospike, Cassandra, Elasticsearch, MongoDB, Redshift."
5,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1901&ao=437149&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_62de739e&cb=1562003805550&jobListingId=3201564694,Data Engineer,LifeSight, – Bengaluru,"Responsibilities:

Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities.

Implementing ETL process.

Monitoring performance and advising any necessary infra structure changes.

Defining data retention policies.

Requirements:

B.Tech in Computer Science or related fields with 3-5 years of professional experience.

Proficient understanding of Java / Scala.

Proficient understanding of distributed computing principles.

Proficiency with Map Reduce, Hadoop, Spark.

Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.

Good knowledge of Big Data querying tools, such as Pig, Hive, Cassandra and Impala.

Experience with Flink, Kafka Streams.

Experience in developing ETL pipelines using EMR or other schedulers like Oozie, Airflow etc.

Experience with NoSQL databases, such as Aerospike, HBase, MongoDB.

Good understanding of Lambda Architecture, along with its advantages and drawbacks.

Experience with Big data stores such as Redshift, ElasticSearch, Druid.

Worked closely with the data science team.

Experience with OLTP and OLAP.

Experience with AWS / GCP.

Data Warehousing, ETL, Flink, Hadoop, Hive, Kafka, NoSQL, Pig, Search, Spark, Storm, Aerospike, Cassandra, Elasticsearch, MongoDB, Redshift."
6,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1919&ao=399392&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_54455098&cb=1562003805564&jobListingId=3238534976,Computer Scientist (C/C++),Adobe, – Bengaluru,"Responsibilities



Would be working as a developer on the Cloud File System / Sync / ACP Local development team

Requirements
4 -5 years of C/C++ development experience
Good knowledge in C/C++, algorithms with good problem solving skills
Working knowledge of Android/iOS development would be an added advantage.

At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.

If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.

Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age, sexual orientation, gender identity, disability or veteran status.
"
7,https://www.glassdoor.co.in/partner/jobListing.htm?pos=726&ao=433326&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_65d13edf&cb=1562003690303&jobListingId=3252672270,"Data Analysis, DL Data scientists",QuEST Global, – Bengaluru,"Title

Data Analysis, DL Data scientists

08-Apr-2019

Job DescriptionMinimum Qualification:

Bachelor Degree in computing or related degree. (Masters/PhD with a focus on machine learning would be a definite plus)At least 5 years of professional experience in the field of data science, machine learning or statistics

Roles & Responsibilities:

You solve business problems with machine learning methods, signal processing, optimization methods and relevant techniques and create data analytics solutions based on business requirements.You design and implement robust data driven algorithms on a massively parallel platform (i.e. Hadoop, HBase, MapReduce, AWS).Identify valuable data sources and automate collection processes, analyse, Present information using data visualization techniquesPropose solutions and strategies to business challengesCustomer engagement. Understand the customer requirements and also work with offshore team closely to satisfy the customer requirements

Required Skills (Technical Competency):

Extensive knowledge in data mining processes, signal processing, image processing, time series analysis or related fieldsExpertise in one or more of the following data analytics frameworks or libraries and programming (i.e. KNIME, Python, R, Anaconda, Scikit-Learn, Tensorflow, Java)Ideally, you have first experience with massively parallel processing i.e. Hadoop, Spark, Pig, Hive, AWS etc.Ability to plan, prioritize, organize, schedule and execute assignmentsStrong analytical skills, with strong problem-solving capabilityExcellent interpersonal, presentation and communication skills

Desired Skills:

Machine learning / AI related certifications would be a plus.

Auto req ID

8263BR

Job Type

Full Time-Regular

Assignment Country

India

Total Years of Exp

10-15

Education Type

B.E/B.Tech/BS-Computer Science

Assignment State

Karnataka

Assignment Location

Bangalore (Bengaluru)

Experience Level

Mid Level
"
8,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1218&ao=444236&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_2a10f623&cb=1562003730778&jobListingId=3275042387,Sr Data Engineer,Honeywell, – Bengaluru,"Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.JOB ACTIVITIESAs a Sr. Data Engineer, you will be part of a team that delivers contemporary analytics solutions for all Honeywell business groups and functions. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, PostgreSQL, etc.

You will identify and implement process improvements – and you don’t like to the same thing twice so you will automate it if you can. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, and a bunch of other acronyms.

You will work on a team including scrum masters, product owners, data architects, data engineers, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in couple of sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.YOU MUST HAVE· Bachelor's degree in Computer Science, Engineering, Applied Mathematics or related field

· 6-8 years of data engineering experience

· Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.

· Should have minimum 4 years of hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.

· Minimum 3 years of experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).

· Minimum 2 years of experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.

· Experience in writing complex SQL statements

· Experience in working with cloud based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).

· Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.

· Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo

· Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)

· Effective communication skills and succinct articulationWE VALUE· Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.

· Experience with dimensional modeling, data warehousing and data mining

· Experience with machine learning solutions and data science methods promotion

· Database performance management and API development

· Technology upgrade oversight

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration

· Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisivenessbody {

 font-family: 'Honeywell Sans Book', Arial, sans-serif;

}

Sr Data Engineer

Deliver business value through Right and Fast partnershipJoin a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.JOB ACTIVITIESAs a Sr. Data Engineer, you will be part of a team that delivers contemporary analytics solutions for all Honeywell business groups and functions. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, PostgreSQL, etc.

You will identify and implement process improvements – and you don’t like to the same thing twice so you will automate it if you can. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, and a bunch of other acronyms.

You will work on a team including scrum masters, product owners, data architects, data engineers, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in couple of sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.YOU MUST HAVE· Bachelor's degree in Computer Science, Engineering, Applied Mathematics or related field

· 6-8 years of data engineering experience

· Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.

· Should have minimum 4 years of hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.

· Minimum 3 years of experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).

· Minimum 2 years of experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.

· Experience in writing complex SQL statements

· Experience in working with cloud based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).

· Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.

· Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo

· Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)

· Effective communication skills and succinct articulationWE VALUE· Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.

· Experience with dimensional modeling, data warehousing and data mining

· Experience with machine learning solutions and data science methods promotion

· Database performance management and API development

· Technology upgrade oversight

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration
· Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness  Key Responsibilities
 Hadoop  Spark  MapReduce
Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.JOB ACTIVITIESAs a Sr. Data Engineer, you will be part of a team that delivers contemporary analytics solutions for all Honeywell business groups and functions. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, PostgreSQL, etc.

You will identify and implement process improvements – and you don’t like to the same thing twice so you will automate it if you can. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, and a bunch of other acronyms.

You will work on a team including scrum masters, product owners, data architects, data engineers, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in couple of sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.YOU MUST HAVE· Bachelor's degree in Computer Science, Engineering, Applied Mathematics or related field

· 6-8 years of data engineering experience

· Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.

· Should have minimum 4 years of hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.

· Minimum 3 years of experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).

· Minimum 2 years of experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.

· Experience in writing complex SQL statements

· Experience in working with cloud based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).

· Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.

· Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo

· Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)

· Effective communication skills and succinct articulationWE VALUE· Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.

· Experience with dimensional modeling, data warehousing and data mining

· Experience with machine learning solutions and data science methods promotion

· Database performance management and API development

· Technology upgrade oversight

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration
· Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness  Additional Information



JOB ID: req193060
Category: Engineering
Location: HW Camp II,Bldgs 9A&9B,Plot C2,RMZ Ecoworld,Varturhobli, Sarjapur Marathahalli Outer Ring Road, Bangalore, KARNATAKA 560103 IND
Exempt


Careers at Honeywell - Engineering"
9,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2806&ao=437149&s=58&guid=0000016baeafa65a98836b4f5999adf7&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_8f340094&cb=1562003875863&jobListingId=3258641412,Data Science Opportunity - Automotive Domain,Altran, – Bengaluru,"As global leader in innovation and high-tech engineering consulting, Altran accompanies its clients in the creation and development of their new products and services.

Altran has been providing services for around thirty years to key players in the Aerospace, Automotive, Energy, Railway, Finance, Healthcare and Telecoms sectors. Covering every stage of project development from strategic planning through to manufacturing, Altran’s offers capitalise on the Group’s technological know-how in five key areas: : Intelligent Systems, Innovative Product Development, Lifecycle Experience, Mechanical Engineering, and Information Systems.

An international group, Altran operates in over twenty countries throughout Europe, Asia and the Americas. As a strategic partner, Altran offers its clients global project support while guaranteeing a consistent level of service. In order to offer specific support to dedicated local markets, Altran has chosen to keep a local dimension in order to better serve specific dedicated markets."
10,https://www.glassdoor.co.in/partner/jobListing.htm?pos=928&ao=437149&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d0557e4d&cb=1562003705667&jobListingId=3200278025,Data Science Opportunity - Automotive Domain,Altran, – Bengaluru,"As global leader in innovation and high-tech engineering consulting, Altran accompanies its clients in the creation and development of their new products and services.

Altran has been providing services for around thirty years to key players in the Aerospace, Automotive, Energy, Railway, Finance, Healthcare and Telecoms sectors. Covering every stage of project development from strategic planning through to manufacturing, Altran’s offers capitalise on the Group’s technological know-how in five key areas: : Intelligent Systems, Innovative Product Development, Lifecycle Experience, Mechanical Engineering, and Information Systems.

An international group, Altran operates in over twenty countries throughout Europe, Asia and the Americas. As a strategic partner, Altran offers its clients global project support while guaranteeing a consistent level of service. In order to offer specific support to dedicated local markets, Altran has chosen to keep a local dimension in order to better serve specific dedicated markets."
11,https://www.glassdoor.co.in/partner/jobListing.htm?pos=818&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_289c9249&cb=1562003698146&jobListingId=3245195924,Senior Data Scientist,Walmart Labs, – Bengaluru,"We are looking for savvy Data Scientists to join our growing team. They will be responsible for solving complex big-data problems in the display advertising space using data mining, machine learning, statistical analysis and computational economics. The right candidates will have strong depth and breadth knowledge in machine learning, data mining and statistics, reasonable programming and design skills to manipulate unstructured and big data and be able build prototypes that work on massive datasets. They should be able to apply business knowledge to perform broad data analysis as a precursor to modelling and to provide valuable business intelligence.

Requirements:

5+ yrs Experience.

Experience using data intelligently to optimize product performance.

Experience performing analysis on raw event data in modern data warehouse systems.

Deep understanding of data platforms in which you've previously worked.

Good understanding of how to grow and shape data tools and datasets to improve data-driven decision making.

Ability to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact.

Solid experience with Python (preferred) and/or R."
12,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1309&ao=78716&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_031077ee&cb=1562003740651&jobListingId=3281333265,Senior Data Scientist,Walmart Labs, – Bengaluru,"We are looking for savvy Data Scientists to join our growing team. They will be responsible for solving complex big-data problems in the display advertising space using data mining, machine learning, statistical analysis and computational economics. The right candidates will have strong depth and breadth knowledge in machine learning, data mining and statistics, reasonable programming and design skills to manipulate unstructured and big data and be able build prototypes that work on massive datasets. They should be able to apply business knowledge to perform broad data analysis as a precursor to modelling and to provide valuable business intelligence.

Requirements:

5+ yrs Experience.

Experience using data intelligently to optimize product performance.

Experience performing analysis on raw event data in modern data warehouse systems.

Deep understanding of data platforms in which you've previously worked.

Good understanding of how to grow and shape data tools and datasets to improve data-driven decision making.

Ability to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact.

Solid experience with Python (preferred) and/or R."
13,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2729&ao=643978&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_dc08fa37&cb=1562003865846&jobListingId=3281813379,"Data Science Associate (Bengaluru, India)",ZS Associates, – Bengaluru,"ZS is a professional services firm that works side by side with companies to help develop and deliver products that drive customer value and company results. From R&D to portfolio strategy, customer insights, marketing and sales strategy, operations and technology, we leverage our deep industry expertise and leading-edge analytics to create solutions that work in the real world. Our most valuable asset is our people—a fact that’s reflected in our values-driven organization in which new perspectives are integral and new ideas are celebrated. ZSers are passionately committed to helping companies and their customers thrive in industries ranging from healthcare and life sciences, to high-tech, financial services, travel and transportation, and beyond.

ZS’s India Capability & Expertise Center (CEC) houses more than 60% of ZS people across three offices in New Delhi, Pune and Bengaluru. Our teams work with colleagues across North America, Europe and East Asia to create and deliver real world solutions to the clients who drive our business. The CEC maintains standards of analytical, operational and technological excellence across our capability groups. Together, our collective knowledge enables each ZS team to deliver superior results to our clients.

ZS's Business Consulting group partners with clients to design and deliver solutions to help them tackle a broad range of business challenges. Our teams work on multiple projects simultaneously, leveraging advanced data analytics and problem-solving techniques. Our recommendations and solutions are based on rigorous research and analysis underpinned by deep expertise and thought leadership.

DATA SCIENCE ASSOCIATE

Data Science Associates (DSAs) design, develop and execute high-impact analytics solutions for large, complex, structured and unstructured data sets (including big data) to help clients make better fact-based decisions.

Responsibilities:

Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner;Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning and retrieval processes) on large data sets to identify trends, figures and other relevant information;Collaborate with clients and other ZS stakeholders to effectively integrate and communicate analysis findings;Contribute to the evaluation of emerging datasets and technologies that may contribute to our analytical platform.

Qualifications:

Bachelor's or master's degree in Computer Science (or Statistics), and strong academic performance with analytic and quantitative cousework is required;Knowledge of big data/advanced analytics concepts and algorithms (e.g. text mining, social listening, recommender systems, predictive modeling, etc.);Knowledge of programming (e.g. Java/Python/R);Exposure to tools/platforms (e.g. Hadoop eco system and database systems);Excellent oral and written communication skills;Strong attention to detail, with a research-focused mindset;Excellent critical thinking and problem solving skills;High motivation, good work ethic and maturity.

ZS is a global consulting firm; fluency in English is required, additional fluency in at least one European or Asian language is desirable. 

Candidates must possess work authorization for their intended country of employment. An on-line application, including a cover letter expressing interest and a full set of transcripts (official or unofficial), is required to be considered.

ZS offers a competitive compensation package with salary and bonus incentives, plus an attractive benefits package.

NO AGENCY CALLS, PLEASE.

Connect with ZS in India on social media:

Like ZS in India on FacebookFollow ZS in India on Twitter and InstagramFollow ZS on LinkedIn for more job opportunitiesSubscribe to the ZS in India YouTubechannelExplore the Life at ZS blog

ZS has been recognized globally for its expertise in consulting and its flexible work environment. View ZS’s accolades.

 "
14,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2026&ao=437149&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_0df630ea&cb=1562003813162&jobListingId=3201048942,Data Engineer II,ADS India Pvt Ltd, – Bengaluru,"We are looking for Data Engineer who has a passion for their customers and a passion for working with data. You like working with your customers, understanding their challenges, and partnering with them to invent great solutions. You like working with large data sets, and bringing data together from multiple systems to answer critical business questions and drive change. You are analytical and creative. You should also have the following skills or experiences:



Bachelors degree in Engineering
3+ years developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
3+ years experience in relational database concepts with a solid knowledge of star schema, Oracle, SQL, PL/SQL, SQL Tuning, OLAP, Big Data technologies
Practical Knowledge of Linux or Unix shell scripting
Basic Knowledge of Python
Experience in working with business customers to drive requirements analysis
Have analytical skills and be creative
Experience with Big Data solutions: Hadoop, Spark or other frameworks
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Strong troubleshooting and problem solving skills


Hundreds of millions of customers, billions of transactions, petabytes of data… How to use the world’s richest collection of e-commerce and device usage data to acquire new customers, target existing customers, and predict customer behavior? Amazon’s Consumer Marketing Analytics team seeks a Data Engineer to lead the Marketing Attribution team that is at the forefront of large scale, algorithmically driven foundation for marketing attribution. You will build data analytical solutions that will address increasingly complex business questions.

We are a high-energy and innovative group that drives hundreds of millions of dollars in sales on Amazon.com. Our goal is to bring customers to the Amazon web site and provide them with the very best experience. We also deliver business intelligence solutions on profitability, cash flow, margin and operational performance to a diverse community of internal customers.

Amazon.com has a culture of data-driven decision-making and demands business intelligence that is timely, accurate, and actionable. This team provides a fast-paced environment where every day brings new challenges and new opportunities.

As a Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should be passionate about working with huge data sets and be someone who loves to bring datasets together to answer business questions. You should have deep expertise in creation and management of datasets.

You should be expert at implementing and operating stable, scalable data flow solutions from production systems into end-user facing applications/reports. These solutions will be fault tolerant, self-healing and adaptive.

You will be working on developing solutions that provide some of the unique challenges of space, size and speed. You will implement data analytics using cutting edge analytics patterns and technologies that are inclusive of but not limited to Star Schema and Hive. You will extract huge volumes of data from various sources and message streams and construct complex analyses. You will write scalable queries and tune performance on queries running over billion of rows of data. You will implement data flow solutions that process data real time on message streams from source systems.

You should be detail-oriented and must have an aptitude for solving unstructured problems. You should work in a self-directed environment, own tasks and drive them to completion.

You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You own customer relationship about data and execute tasks that are manifestations of such ownership, like ensuring high data availability, low latency, documenting data details and transformations and handling user notifications and training.

You will work with distributed machine learning and statistical algorithms upon a large EMR cluster to harness enormous volumes of online data at scale to serve our customers.



Expert in SQL
Experience with Python and experience with scripting languages like Unix shell scripts
Experience partnering with business owners directly to understand their requirements and provide data which can help them observe patterns and spot anomalies.
Experience with web technology to develop dashboards.
Demonstrated experience in dealing with Senior Management on addressing their reporting and metrics requirements.
Some familiarity with econometrics, machine learning, or statistics
"
15,https://www.glassdoor.co.in/partner/jobListing.htm?pos=302&ao=437149&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9137c934&cb=1562003656966&jobListingId=3201229010,Data Scientist,Jumbotail, – Bengaluru,"As an Analyst - Decision Science at Jumbotail you will

Bring a thorough understanding of product analytics tools and data pipeline, and help the product and tech team with right data instrumentation frameworks, and data platforms.

Lead investigations into multiple streams of product data, analyze behavioral and click through data, and build user behavior models, and data visualization on user funnels; Work, analyze, evaluate, and generate insights on the how users are interacting with our products and factor that into our pricing/merchandising models.

Provide insights to the product team to develop new methods for optimizing product performance, selection strategies, and inventory guidance to drive GMV/CX goals.

Design experiments to answer targeted questions and conduct exploratory data analysis in high dimensions.

Research and develop new frameworks, models and processes for computing product affinity scores, and demand supply curves, based on behavioral and transactional data.

Build business cases and models to quantify new opportunities, using data and solid business judgment"
16,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1922&ao=437149&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_eece9de1&cb=1562003805566&jobListingId=3232500590,"Data Analyst, 2",Epsilon India, – Bengaluru,"Data Analyst Job Description

Role Summary:

A Data Analyst is accountable for accurate, on-time delivery of multiple and concurrent analytics projects. The Data Analyst works closely with the UK-based Customer Solutions Team to extract, manipulate, and analyse transactional data to support direct marketing campaigns and customer insight.

Job Tasks and Responsibilities:

§ Work closely with the UK-based Customer Solutions Team on the delivery of analytics and modelling solutions

§ Import raw data files into SAS environment

§ Extract, manipulate, and analyse transactional data

§ De-bug SAS code and QC processes

§ Conduct data investigations and troubleshoot

§ Update Excel-based reports and dashboards

§ Accountable for accuracy ond on-time delivery of analysis

§ Comply with the group’s policies and procedures for programming, documentation, and system management

Skills

§ Strong attention to detail: Verifies all work to ensure accuracy; Recalls specific facts quickly and efficiently; Notices details not obvious to others

§ Analytical skills to extract, interrogate, and analyse data

§ Experience navigating Unix environment

§ SAS programming experience: Understands basic procedures; is able to perform standard data manipulation steps. Has the ability to interpret and adapt existing code, and to identify and fix errors relating to formatting and syntax

§ Experience working with relational databases

§ Proficient in MS Excel, PowerPoint and Word

§ SQL experience a plus

§ Familiarity with customer segmentation and direct marketing a plus

Personal Qualities

§ Able to work independently

§ Proactive and resourceful

§ Strong time-keeping skills and the ability to work on multiple projects simultaneously

§ Good written and verbal communication skills

§ Ability to work under pressure

§ Ability to work with people remotely

Qualifications and Experience:

§ Bachelor’s degree in Statistics or quantitative field

§ 1+ years experience navigating Unix environment

§ 1+ years of SAS programming experience

§ 1+ years experience using relational databases

§ 1+ years prior experience with data analysis or modeling with large transactional databases"
17,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2620&ao=433315&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9e8a4a30&cb=1562003857981&jobListingId=3207166599,Data Engineering Developer for HPE InfoSight,Hewlett Packard Enterprise, – Bengaluru,"Data Engineering Developer for HPE InfoSight

Hewlett Packard Enterprise (HPE) is seeking an outstanding software engineer to play a key role in developing the HPE InfoSight. This industry-leading HPE analytics solution builds AI for the datacenters. HPE InfoSight collects and analyzes more sensor data points from our customers storage arrays than there are stars in our galaxy. Predictive Analytics are then used to correlate vast amounts of information to find the needle in the haystack, and solve our customers most complex infrastructure issues.

You will be joining a small, agile, empowered team, focused on analyzing call-home data sent from HPE Storage and enterprise products to provide business value through analytics.The team leverages a state-of-the-art big data (SMACK Stack) and micro service based technology stack for our end-to-end data processing, analysis, API, and web application to provide our users with the insights they need to be successful.

Responsibilities

Technical hands on contributor, as a full-stack software developer (were heavy users of Scala), in a small cross-functional development team, focused on providing data analytics as a service to internal and external consumersContribute to the continuous improvement of our IoT analytics platform, powered by big-data technologies, including Spark, Mesosphere, Akka, Cassandra, Kafka, Lagom, ElasticSearch, and VerticaDesign and implement scalable modules. Develop unit, integration, system or any tests that are needed to help the team deliver value quickly, with a high degree of quality. Design and develop tools and utilities.Contribute to the continuous improvement of our Data Streaming platform and pipelineWork with the DevOps engineers to define state-of-the-art CI/CD strategies

Education and Experience

Bachelor/Master's degree in Computer Science/Engineering program, or equivalent8-15 years of relevant experience and hands on development skills

Knowledge and Skills

Hands on progressive dev experience in Scala / Functional programmingExperience building a scalable data pipeline using Big Data technologies and engineering practicesWorked with the Front End, Data Scientists and DevOps teams and optimized data handling capabilities at scaleExposure to full stack development and implementing REST APITeam player with a passion for self-learning, programming, automation, and data analyticsExcellent analytical and problem solving skillsExcellent communications skills

Experience with the following skills are desired/preferred:

Spark - advantageAkka - advantageKafka- advantageMesos and DC/OSReactive framework / Lagom / Event sourcingNoSQL databases such as Cassandra or ElasticSearchMicroService architecture using PlayAnalyticsMachine Learning

Hewlett Packard Enterprise Values:

Partnership first: We believe in the power of collaboration and building long term relationships with our customers, partners and each other

Bias for action: We never sit still, we take advantage of every opportunity

Innovators at heart: We are driven to innovate, creating both practical and breakthrough advancements

If you are looking for challenges in a pleasant, caring, and global hi tech work environment, feels excited to use latest technology stack, and innovate to a new high, then we definitely want to hear from you. Apply now directly via our career portal at www.hpe.com/careers

You can also find us on:

https:/www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1042857"
18,https://www.glassdoor.co.in/partner/jobListing.htm?pos=3017&ao=437149&s=58&guid=0000016baeafe7388a34bfd62b4e5a9a&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e3d9ea3f&cb=1562003892508&jobListingId=3261967685,Workfusion Machine Learning Engineer,IntroPro, – Bengaluru,"Project Description

Luxoft is building RPA practice in India and is looking for talented and ambitious RPA engineers to put together automation teams able to deliver end to end solution to its global clients from different domains. These teams will implement solutions using WorkFusion platform which is AI-driven RPA software that creates and manages software robots for knowledge work. Built for data-first companies, it automates business processes by combining AI, RPA and people in one intuitive platform.

Responsibilities

Develop reusable machine learning components for the delivery team
Solve difficult architecture and machine learning tasks that coming from the customers
Collaborate with data-science, engineering and customers to build production machine learning models and provisioning systems
Take part in the project delivery onsite
Take role as a stakeholder for the product team
Work on the best practices for delivery

Skills

Must



5+ years of production Java/JEE experience
1+ years of experience in Workfusion
Hands-on experience with machine learning platforms and related tools is a must
Proficiency in algorithms, data structures and computer science fundamentals
Good knowledge of statistics and probability theorySolid background in machine learning concepts and probability theory
Good knowledge of Regex (regular expressions)


Unit test frameworks, Junit4 and good debugging skills.



Basic knowledge on NLP nomenclature is must.
Good understanding of RESTful web services.
Hands on Maven: Scoping, Versioning, multi-module builds and dependency management is must.
Solid understanding of Java design patterns and OOP
Strong working knowledge of Databases and SQL.
Proficient DevOps Skills and mind-set
Working experience of GiT/SVN version control repositories


Nice to have



Hands-on experience with rule-based models
Working familiarity and understanding of tools and libraries such as: Weka, Stanford NLP, Apache UIMA, Apache Mahout, NLP, Tableau, Deep Learning, Tensor Flow, Pytorch, Caffe


Languages

English: Upper-intermediate"
19,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2701&ao=437149&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_760f220d&cb=1562003865824&jobListingId=3200733638,Lead Computer Scientist, – Bengaluru, – Bengaluru,"Project Description

Luxoft is building RPA practice in India and is looking for talented and ambitious RPA engineers to put together automation teams able to deliver end to end solution to its global clients from different domains. These teams will implement solutions using WorkFusion platform which is AI-driven RPA software that creates and manages software robots for knowledge work. Built for data-first companies, it automates business processes by combining AI, RPA and people in one intuitive platform.

Responsibilities

Develop reusable machine learning components for the delivery team
Solve difficult architecture and machine learning tasks that coming from the customers
Collaborate with data-science, engineering and customers to build production machine learning models and provisioning systems
Take part in the project delivery onsite
Take role as a stakeholder for the product team
Work on the best practices for delivery

Skills

Must



5+ years of production Java/JEE experience
1+ years of experience in Workfusion
Hands-on experience with machine learning platforms and related tools is a must
Proficiency in algorithms, data structures and computer science fundamentals
Good knowledge of statistics and probability theorySolid background in machine learning concepts and probability theory
Good knowledge of Regex (regular expressions)


Unit test frameworks, Junit4 and good debugging skills.



Basic knowledge on NLP nomenclature is must.
Good understanding of RESTful web services.
Hands on Maven: Scoping, Versioning, multi-module builds and dependency management is must.
Solid understanding of Java design patterns and OOP
Strong working knowledge of Databases and SQL.
Proficient DevOps Skills and mind-set
Working experience of GiT/SVN version control repositories


Nice to have



Hands-on experience with rule-based models
Working familiarity and understanding of tools and libraries such as: Weka, Stanford NLP, Apache UIMA, Apache Mahout, NLP, Tableau, Deep Learning, Tensor Flow, Pytorch, Caffe


Languages

English: Upper-intermediate"
20,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1906&ao=437149&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_0e0570d8&cb=1562003805554&jobListingId=3249750721,Computer Scientist - iOS,Adobe, – Bengaluru,"Requirements:

Looking for a seasoned, passionate, and hands-on iOS developer with 8+ years of experience in developing iOS apps.

Experience in C/C++/Objective-C and strong programming fundamentals.

Intimate knowledge of UIKit, Cocoa Touch, and Xcode.

Strong understanding of MVC concepts, Design Patterns, and Object Oriented Programming.

Experience developing in teams and utilizing source control software (Git/Github).

Working knowledge of open source third-party iOS libraries, and the iOS Ecosystem.

A minimum of 3+ years of relevant experience on iOS and frontend development.

Ability to work independently and strong communication skills within and across teams.

Ability and willingness to learn new technologies quickly.

Should be having sound understanding of data structures and algorithms.

Strong analytical and problem-solving skills.

Minimum of a Bachelor's degree or equivalent in Computer Science, Information Technology, Engineering, or related field from a premium institute."
21,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2216&ao=437149&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a40065a0&cb=1562003826201&jobListingId=3269276141,Cloud Data Engineer - Contract to Hire,Sharp Gaze Tech, – Bengaluru," Roles and responsibilities  Greetings from Sharp Gaze  We have a opening for Cloud Data Engineer JD 5+ years of overall experience in IT with 3+ years on Amazon Web Services (AWS) Good working experience on Amazon Redshift, Amazon Glue and other tools related to data storage and content within AWSExperience with cloud-based big data storage, processing, ETL/ELT, and ingest tools such as S3, AWS Glue, and Apache Spark Good understanding of core AWS services, uses, and AWS architecture best practices with exposure to Informatica /AWS Integration  Exposure to Agile methodologies. Proficiency in developing, deploying, and debugging cloud-based applications using AWS  The resource should be flexible to work in shifts based on the project demand  Interested can send their profiles to priya@sharpgts.com Salary: Not Disclosed by Recruiter Industry: IT-Software / Software Services Functional Area: IT Software - Application Programming, Maintenance Role Category: Programming & Design Role: Software Developer Employment Type: Permanent Job, Full Time Keyskills: Desired Candidate Profile  Doctorate - Doctorate Not Required,"
22,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2907&ao=116277&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f9056f59&cb=1562003887216&jobListingId=1069989146,Data Analyst (2-5 Years) For an Emerging Real-Estate Portal..!!,Zyoin, – Bengaluru,"Job responsibilities:

Plan and implement the overall analytics and business intelligence strategy
Lead the design and development of analytical projects designed to understand key business behaviors that drive customer acquisition, retention, and engagement
Identify opportunities to develop forecasts, statistical models, segmentation schemes, and data-driven analyses to drive marketing and merchandising efforts around customer acquisition and conversion
Discover new opportunities to optimize the business through analytics and statistical modeling
Partner with the Technology teams to deliver a stable and highly available reporting platform
Work with business owners to identify information needs and develop reporting; primary partners include the management team, finance & accounting, marketing, online retail, merchandising and operations
Oversee all aspects of analytics and business intelligence projects
Develop and maintain reporting and analytical tools, including Business Objects
 Develop KPI dashboards
Integrate web analytics into transactional and customer analytics
Hire, train, and supervise Analytics team and ensure that team meets the reporting and analytical needs of the business users

Required Skills
Bachelors degree from Top Engineering or Management College
Relevant prior experience in product management of at least 2 -5 years, preferably in consumer internet domain. (e-commerce background)
Understanding of, or passionate about commerce and retail domain
Analytical Skills: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyze it to find conclusions.
Communication Skills: Data analysts are often called to present their findings, or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas.
 Critical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings.
Attention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions.
Math Skills: Data analysts need math skills to estimate numerical data.
"
23,https://www.glassdoor.co.in/partner/jobListing.htm?pos=106&ao=438575&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e4e2dc52&cb=1562003586318&jobListingId=3245770508,Data Scientist - Machine Learning,HP Inc., – Bengaluru,"HP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works. We are looking for a technology leader in the areas of Solution Architecture and Machine Learning. We expect this leader to be passionate about enabling business solutions for HP Print as well as taking a cross program role of assuring the quality of software by designing systems, automation frameworks and smart systems. Should be aware of latest technologies in Machine Learning that can be applied to developing automated, smart systems. As a senior architect this person will be expected to work across multiple teams in HP PPS R&D Center as well as with our customers and partners.At HP, we have been increasingly adopting and investing in machine learning to provide solutions helping to improve device performance and diagnostics, customer issue redressals, building an entire machine learning based ecosystem to further drive sales for HP as well as several other potential avenues. At HP PPS R&D Center, Bangalore, we have been developing solutions based on time-series analysis for printer part failure predictions so that a better insight can be provided into device health leading to proactive failure management. We are also focused on applying various Natural Language Processing (NLP) techniques to improve the way human agents attempt to guide customers, facing printer or other device issues, by incorporating human knowledge and experiences available in terms of case notes. This will help in providing a dynamic context-aware redressal steps instead of fixed and static steps. We are also on the way to provide deep learning (both Computer Vision and NLP) and recommendation-based solutions to a larger ecosystem which aims to integrate image search, purchase and print facilities.Responsibilities: Define the strategic direction around improving Service and Support and conceptualizing and architecting business solutions integrating various aspects of the solution.Provide an outside in perspective on Customer and Market direction and reflect this in both Architecture and Quality focus.Use Machine Learning and related AI areas in maximizing the use of data to develop system insights and build smart systems in the areas of Service and Support and Engineering AnalyticsWork across multiple business units, stakeholders and technologists in roadmap definition, architecture and achieving desired outcomes. Drive Innovation across the Lab in the focus areasMentor Next level of Architects and play an active role in the TCP communityQualification: PhD degree in Machine Learning / Data Science / Statistics or Masters with 4+ years of experience in the aforementioned fields. Deep knowledge of fundamentals of AI, Machine / Deep Learning, Data Mining and Predictive Modelling is required with solid experience in applying these techniques on real world problemsInterdisciplinary skills in Big Data Technologies, ETL, statistics and causal inference is desirable. Strong skills in software engineering practices (Design, Development and Requirement Management) with expertise in applicable programming languages and frameworks such as scikit-learn, XGBoost, Pytorch, Tensorflow, Spacy, H2O.Hands on experience in solution building, deployment, testing, and release processes using version control and continuous integration is desirable. Strong analytical, written and verbal communication skills.Demonstrated ability to propose novel solutions to problems, performing experiments to prove feasibility of solutions and working to refine the solutions into real world context."
24,https://www.glassdoor.co.in/partner/jobListing.htm?pos=202&ao=7438&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_afa2c821&cb=1562003628499&jobListingId=3088550857,Data Scientist - Associate,TheMathCompany, – Bengaluru,"Associate–Job Description

Location -Bangalore

An Associate of TheMathCompany is the face of the organization in our client engagements. As an associate, you will be responsible for a wide range of things [just to ensure you don’t get bored and always keep learning :)] We have listed a few of them below to help you get an idea

•Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques

•Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution



Staying connected to the Analytics industry trends-data, techniques, technology etc. and leveraging them to develop learning packages •Contributing to the hiring and learning programs-through interviews, sessions, content creations etc. based on the nature of the engagements

•Building TheMathCompany. As a Startup that is on the growth trajectory, it would provide opportunities to design and execute initiatives that will help us in this endeavor

So, what does it take to be an Associate@TheMathCompany?

We are looking out for people who share our passion for analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role

•Experience of working on analytics projects and initiatives, preferably around 2-5 years

•Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc.)

•Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve

•Ability to do what it takes. We want,you to be part of our growth story and this would entail roles and responsibilities that would be new, exciting and dynamic

TheMathCompany would provide you with an ecosystem to learn and grow in your professional journey, offering guidance to help you be successful.We are also a fun bunch and will help you in making this memorable.

So, based on what you have readdo you believe you have what it takes to build TheMathCompany and analytics capabilities for Fortune 500 organizations?

Have some questions or suggestions? Unclear about certain opportunities? Feel free to reach out to us anytime for a friendly chat:

Website: http://themathcompany.com/

e-mail: careers@themathcompany.com

Off: 080 - 4624 5904
"
25,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2202&ao=132976&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_4c598007&cb=1562003826184&jobListingId=3225837171,CCBD Technology - Data Engineer,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBWhat We DoAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.Who We Look ForGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.

Consumer and Investment Management (CIMD)

The Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.

Consumer

Consumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses. It also includes our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of insights and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• Design and develop data ingest and transform processes• Develop data visualizations using BI tools and web-based technologies• Work as part of a global team using Agile software methodologies• Partner with Marcus risk, product, acquisition and servicing teams• Use Marcus data to drive change throughout the Marcus businessSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Minimum 3 years of relevant professional experience• Bachelor’s degree or equivalent required• Experience with SQL and relational databases• Proficient at Python, Spark and the Hadoop ecosystem• Self-starter, motivated, and good communication skills Strong sense of ownership and driven to manage tasks to completionPreferred QualificationsABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
26,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2001&ao=437149&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f758ac01&cb=1562003813141&jobListingId=3201517418,CCBD Technology - Data Engineer,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBWhat We DoAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.Who We Look ForGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.

Consumer and Investment Management (CIMD)

The Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.

Consumer

Consumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses. It also includes our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of insights and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• Design and develop data ingest and transform processes• Develop data visualizations using BI tools and web-based technologies• Work as part of a global team using Agile software methodologies• Partner with Marcus risk, product, acquisition and servicing teams• Use Marcus data to drive change throughout the Marcus businessSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Minimum 3 years of relevant professional experience• Bachelor’s degree or equivalent required• Experience with SQL and relational databases• Proficient at Python, Spark and the Hadoop ecosystem• Self-starter, motivated, and good communication skills Strong sense of ownership and driven to manage tasks to completionPreferred QualificationsABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
27,https://www.glassdoor.co.in/partner/jobListing.htm?pos=906&ao=4120&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_064367da&cb=1562003705649&jobListingId=3232231761,CCBD Technology - Data Engineer,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBWhat We DoAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.Who We Look ForGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.

Consumer and Investment Management (CIMD)

The Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.

Consumer

Consumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses. It also includes our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of insights and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• Design and develop data ingest and transform processes• Develop data visualizations using BI tools and web-based technologies• Work as part of a global team using Agile software methodologies• Partner with Marcus risk, product, acquisition and servicing teams• Use Marcus data to drive change throughout the Marcus businessSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Minimum 3 years of relevant professional experience• Bachelor’s degree or equivalent required• Experience with SQL and relational databases• Proficient at Python, Spark and the Hadoop ecosystem• Self-starter, motivated, and good communication skills Strong sense of ownership and driven to manage tasks to completionPreferred QualificationsABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
28,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1406&ao=437149&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_69b0d16d&cb=1562003752609&jobListingId=3213975719,Senior Manager data science,Kimberly-Clark, – Bengaluru,"Job Description

Customer expectations:

Delivery of innovative, efficient and cost-effective data science and analytics solutions globally to drive business growth and profitability.

Insight and understanding on “best practices” and keeping pace with competition and peer companies Thought leadership in emerging data science trends.

Work with businesses and capability teams to establish business process sustainability and business benefits

Extensive collaboration with other IT Services Delivery Teams to ensure high performance of the global application portfolio.

Recommend and drive the prioritization of Information Technology decisions for the global businesses to ensure world class delivery and value for ITS investment.

The right person for this role is proactive with stakeholders, a self-starter who can work under broad direction, and passionate about delivering world-class analytics solutions that allow business users to tell a story with data.

Scope/ Categories

Key Internal Stakeholders: Leaders, Global Process Owners, Business based data scientists and local business resources, ITS leadership including business partners, engineering and application leaders, and the enterprise architecture team.

Key External Stakeholders: Consultants and Managed Services Providers.

Travel may include approximately 15% of work time.

Key Accountabilities

Manage a team of Data Scientists in global application delivery – Define, analyze, prove and operationalize data science and analytical initiatives in accordance with business and IT priorities and annual budgets.

Business-IT Strategy - Promote and support the long-range IT systems plan consistent with business objectives. Support and facilitate the alignment of IT and Data & Analytics strategies to business strategies.

BPO Relationship Management - Represent the face of IT to the customer. Identify technology opportunities which provide strategic/tactical advantages in planning, managing and conducting the business. Engage with key customers and other external business partners to deliver IT solutions in a high quality, globally conscience manner.

Build Talent – Promote and build global leaders, develop staff with the needed functional and technical skills required to meet a growing application portfolio and changing technology needs.

Innovation: Design, develop and pilot machine learning models. Identify opportunities to leverage new models and technologies in innovative ways which deliver new value.

Partner with business and product teams to prove out capabilities which improve business outcomes.

Work with businesses and capability teams to establish business process sustainability and business benefits. Collaborate with Business Partner organization on roadmaps and strategy.

Leads others to complete Continuous Improvements (CI) initiatives; consult and share knowledge across organization.

Understand the importance of emerging metrics, models & benchmarking techniques in business.

Ensure insight and understanding of “best practices”, keeping pace with competition and peer companies.

Key Qualifications and Experiences

MS degree in computer science, statistics, operations research or related technical discipline. A PhD degree in a related field is preferred but not required.

8-12 years or equivalent experience in analytics. 5+ years experience leading large, remote, global teams. Ability to train, mentor and coach Data Scientists.

Exceptional business acumen. Solid understanding of CPG business. Strong strategic thinking and exceptional analytic capability. Deep knowledge of machine learning, statistics, optimization or related field and ability to generate profound insights from data. Understand the range and potential measurements & models needed in a large CPG business.

Demonstrated skills in application delivery, client relationship management, strong sense of urgency in delivering results, business knowledge, intuition and judgment, high cross-cultural awareness and sensitivity, strong communication/collaboration.

Hands-on experience developing data science solutions from concept to production leveraging R, Python, etc. Experience working with large data sets and distributed computing tools a plus (Azure ML Cloud Platform (end to end implementation expertise), Spark, Python, R).

Prefered knowledge & experience with SAP HANA and PAL desired.

Experience leading IT projects and/or programs with strong SDLC experience including Agile/Waterfall methodologies.

Significant experience working with outsource partners.

Strong portfolio management experience.

Strong facilitation skills required. Must display vision and resiliency

Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.

Experience leading large projects, leading large teams and leaders of teams

(Standard) Verbal and written fluency in English is mandatory. Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.

Global VISA and Relocation Specifications:

K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.

This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role

Primary Location

IT Centre Bangalore GDTC

Additional Locations

Worker Type

Employee

Worker Sub-Type

Regular

Time Type

Full time"
29,https://www.glassdoor.co.in/partner/jobListing.htm?pos=110&ao=629783&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_df41e284&cb=1562003586322&jobListingId=3265621207,Data Scientist - Early Career Program,Ericsson-Worldwide, – Bengaluru,"Date: Jun 14, 2019Job description will be provided later"
30,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1116&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e0385073&cb=1562003722972&jobListingId=3252776662,Hiring Data Analyst for Bangalore,Gramener, – Bengaluru,"Job ID: 1300094

Experience: 3+ years

Work Location: Hyderabad and Bangalore

Job Description:

3+ yrs of experience using analytical tools/languages like Python, R, SAS, SQL.

Background in Computer Sciences or any quantitative discipline (Statistics, Mathematics, Economics/Operations Research, etc.) from a reputed institute.

Machine Learning techniques experience such as Linear Regression, Logistic Regression, Forecasting, Cluster analysis, Decision trees, Linear Optimization, Text mining, etc.

Ability to work on large scale data (structured and unstructured).

Ability to translate business problems into the data realm and identify pertinent and meaningful solutions.

Must be able to converse with business users and understand business processes."
31,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1127&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a2091785&cb=1562003722986&jobListingId=3227687023,Data Analyst,Goalreify, – Bengaluru,"Job Description

Required Skills:

2+ years of experience who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.

Knowledge of SQL, R, Python

Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop) optional

Knowledge of applied mathematics, statistical methods, machine learning and algorithms.

Experience in applied statistics, understanding of controlled experiments is an advantage.

Deadline driven, ability to work independently.

Proven ability to work in a fast-paced environment, and to meet changing deadlines and priorities on multiple simultaneous project

Detail oriented, with a strong passion for analytics and problem solving.

Excellent written and oral communication skills.

Responsibilities:

Develop models & recommend insights

Customer segmentation and targeting, promotion effectiveness and churn prevention

Customer Cohort analysis, comparative analysis etc

Drive analysis on global projects to improve the experience of our customers and support agents

Build and own periodic reporting - Take advantage of the ever-growing amount of data we have at our fingertips to help stakeholders all over the world manage and improve our agent experiences

Analyze advanced A/B testing data (exposure to experimental design is a plus)

Execute quantitative analyses that translate data into actionable insights.

Provide analytical and data-driven decision-making support for key projects

Understanding business requirements and implementing analytical solutions & techniques.

Developing algorithms and predictive models to solve critical business problems and test feasibility of solution approach.

Prototyping new ways to visualize and understand data relationships.

Own the design, development, and maintenance of on-going reports, dashboards, etc.

Developing tools and libraries that will help the team to improve efficiency.

Salary: Not Disclosed by Recruiter

Industry:IT-Software / Software Services

Functional Area:IT Software - Application Programming, Maintenance

Role Category:Programming & Design

Role:Software Developer

Keyskills

CPythonMachine LearningSQLAlgorithmsJavascriptROpen SourceStatistical SoftwareStatisticsClever TapQuebole

Desired Candidate Profile

Please refer to the Job description above

Education-

UG:B.A - Economics, Maths, Statistics, B.Com - Commerce, B.Sc - Computers, Statistics, B.Tech/B.E. - Any Specialization

PG:M.A - Any Specialization, Economics, Statistics"
32,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1412&ao=7438&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_62026e30&cb=1562003752614&jobListingId=3260939293,Chief Data Scientist,Simpl, – Bengaluru," About the company:  Since 2015, Simpl has been helping e-commerce merchants separate the buying(the fun part) from the paying(OTPs, payment failures, ugh..). Instead of forcing users to authenticate every transaction, Simpl carries out sophisticated background authentication using device and transaction-level data - allowing you to transact with just 1 tap. After all, how many devices and delivery addresses does a regular user have anyway?  All your transactions, across merchants, get added to one bill - which you pay once in two weeks. This separation of buying from the paying opens the possibility for breakthrough customer experiences on apps like Zomato, bigbasket, MakeMyTrip, Grofers, dunzo and BookMyShow.  In order to create these experiences for consumers and merchants, our team is composed of engineers, analysts, designers, operations leads and more, all excited by the possibility of taking a sledgehammer to the status quo, every day.  WHAT YOU WILL DO Apply advanced analytics techniques to generate actionable insights that would impact important product decisionsBe involved in the product testing during new releasesHave regular catch up with the market stakeholders (Client Services, Traders, Sales)Automation and Local Product SolutionsBe involved in testing existing products in innovative ways for performance & insightsIn addition of being an individual contributor, Lead the team of analysts across verticals WHAT YOU WILL NEED ANALYTICAL THINKING - Should follow a logical approach towards solving business problems. Should be able to step in on open ended analytics problems and provide solutions and ideas on what’s possiblePROJECT MANAGEMENT SKILLS - Tracking time-resource engagement for projects/deliverables to ensure timely deliveries. Should be able to function in a high pressure environment. Demonstrate high degree of organization and ability to manage multiple, competing prioritiesPEOPLE MANAGEMENT SKILLS - You will be responsible for leading the team of Analysts which would require a strong people management skill. As the team lead you would be responsible to make sure the sanity of works and standards are being maintained. TECHNICAL PROFICIENCY 4-6 Years of experience working in the field of Data Sciences, with at-least 1-2 years as project owner / team leadExpertise in SQL, Excel, Python/R and PowerPointBeginners level knowledge of dashboarding tool like QlikSense/Tableau/R ShinyExperience implementing basic Clustering and Regression algorithmsExperience setting up and analysing Experiments and A/B testsBeing able to independently come up with ideas and advise commercial teams on ideas for analysis/opportunities for upweightsGood verbal and written communication & data presentation skills, including the ability to effectively communicate with both business and technical teamsGood sense of attention to detail, ex - able to spot interesting patterns and outliers in dataHigh levels of motivation and desire to constantly get better and contributeWillingness to try new tools/technologies and ability to grasp and learn quicklyBe a strong TEAM PLAYER"
33,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1425&ao=14295&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_85273d3b&cb=1562003752624&jobListingId=2616873337,Team Lead - Data Scientist (NLP), – Bengaluru, – Bengaluru," About the company:  Since 2015, Simpl has been helping e-commerce merchants separate the buying(the fun part) from the paying(OTPs, payment failures, ugh..). Instead of forcing users to authenticate every transaction, Simpl carries out sophisticated background authentication using device and transaction-level data - allowing you to transact with just 1 tap. After all, how many devices and delivery addresses does a regular user have anyway?  All your transactions, across merchants, get added to one bill - which you pay once in two weeks. This separation of buying from the paying opens the possibility for breakthrough customer experiences on apps like Zomato, bigbasket, MakeMyTrip, Grofers, dunzo and BookMyShow.  In order to create these experiences for consumers and merchants, our team is composed of engineers, analysts, designers, operations leads and more, all excited by the possibility of taking a sledgehammer to the status quo, every day.  WHAT YOU WILL DO Apply advanced analytics techniques to generate actionable insights that would impact important product decisionsBe involved in the product testing during new releasesHave regular catch up with the market stakeholders (Client Services, Traders, Sales)Automation and Local Product SolutionsBe involved in testing existing products in innovative ways for performance & insightsIn addition of being an individual contributor, Lead the team of analysts across verticals WHAT YOU WILL NEED ANALYTICAL THINKING - Should follow a logical approach towards solving business problems. Should be able to step in on open ended analytics problems and provide solutions and ideas on what’s possiblePROJECT MANAGEMENT SKILLS - Tracking time-resource engagement for projects/deliverables to ensure timely deliveries. Should be able to function in a high pressure environment. Demonstrate high degree of organization and ability to manage multiple, competing prioritiesPEOPLE MANAGEMENT SKILLS - You will be responsible for leading the team of Analysts which would require a strong people management skill. As the team lead you would be responsible to make sure the sanity of works and standards are being maintained. TECHNICAL PROFICIENCY 4-6 Years of experience working in the field of Data Sciences, with at-least 1-2 years as project owner / team leadExpertise in SQL, Excel, Python/R and PowerPointBeginners level knowledge of dashboarding tool like QlikSense/Tableau/R ShinyExperience implementing basic Clustering and Regression algorithmsExperience setting up and analysing Experiments and A/B testsBeing able to independently come up with ideas and advise commercial teams on ideas for analysis/opportunities for upweightsGood verbal and written communication & data presentation skills, including the ability to effectively communicate with both business and technical teamsGood sense of attention to detail, ex - able to spot interesting patterns and outliers in dataHigh levels of motivation and desire to constantly get better and contributeWillingness to try new tools/technologies and ability to grasp and learn quicklyBe a strong TEAM PLAYER"
34,https://www.glassdoor.co.in/partner/jobListing.htm?pos=716&ao=583864&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_6bfb95e4&cb=1562003690288&jobListingId=3085569709,Microsoft Modern Data Platform,Accenture, – Bengaluru,"Accenture Technology powers our clients businesses with innovative technologiesestablished and emergingchanging the way their people and customers experience work, life and entertainment. Join Accenture Technology and youll translate the operational needs of the worlds governments and leading businesses into the innovative technical solutions that will enable them to better serve their customersyour friends, family and neighbors.Youll deliver everything from point solutions for a single business function to large, long-term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. Youll create custom-designed solutions or integrate our technology platforms with their operations.

Role :Application Lead

Role Description :Lead the effort to design, build and configure applications, acting as the primary point of contact.

Must Have Skills :Microsoft Modern Data Platform

Good To Have Skills :Industry Strategy

Job Requirements : 1: Responsibilities -

a: Develop database solutions to store and retrieve company information

b: Methodologies used:Data Ingestion, ComsumptionStorage,Transformation,Visualization

c: Migrate data from legacy systems to new solutions

d: Knowledge of data mining and segmentation techniques

e: Define security and backup procedures

f: Proven work experience as a Data Architect, Data Scientist, Data Analyst or similar role

2: Professional Experience - 

a: Candidates should have minimum 10 years of IT experience 

b: Candidates should have 6 years of extensive database experience with a good knowledge of Business Intelligence, SQL Server, Data Warehousing Concepts Knowledge on internal working of YARN and HDFS

c:Should have Minimum 2 years of experience on Hadoop and strong knowledge of Hadoop HDInsight ecosystem Pig, Hive,MapReduce,HBase,Azure Blob Storage,SQOOP 

d:Should have experience in Azure Analytics components like DocDB,Azure SQL Data Warehouse, Azure SQL DB and Azure Data Factory"
35,https://www.glassdoor.co.in/partner/jobListing.htm?pos=813&ao=46442&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_09e985c4&cb=1562003698142&jobListingId=3282150715,Senior Data/NLP Scientist,AnswerIQ, – Bengaluru,"AnswerIQ is looking for a Senior Data/NLP Scientist to join our data science team. Our data science team dedicate to apply Natural Language Processing and Machine Learning in the enterprise customer support space. We develop sophisticated algorithms and applications to automate the customer service including responding the ticket, classifying ticket issues, engaging conversations with customers. You will lead the development in the ML/NLP intelligence engine to empower SmartAssist products and services.

Qualifications

PhD in natural language processing, machine learning or equivalent experience;
Solid background in statistical learning techniques for NLP (HMMs, CRFs, LDA, LSI, MRFs, etc.) and NLP tools (NLTK, GENSIM, etc.)
Experience with deep learning frameworks (Tensorflow, CNTK, Mxnet, Keras, etc.) and applying these frameworks to NLP
Experience in applying and implementing NLP algorithms, especially in the following areas: conversations and dialogues, text generation, information extraction, semantics analysis, question answering
Strong programming skills in at least one object oriented programming language (Python, Java, Scala, C++, etc.)
Experience in building and deploying large-scale applications related to natural language processing and machine learning
Track-record of publications in NLP/ML conferences (ACL, NAACL, EMNLP, NIPS, etc.)

"
36,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2720&ao=629783&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d005eea9&cb=1562003865839&jobListingId=3208203462,Senior Data Engineer - R&D (GAIA,Ericsson-Worldwide, – Bengaluru,"Date: Apr 26, 2019Ericsson Overview:

Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Senior Data Engineers to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Role Summary:

As a Senior Data Engineer, you shall be a part of our growing team of MI experts. As a team leader, you will be evolving and optimizing our data and data pipeline architecture, as well as, optimizing data flow and collection for cross functional teams. You are an expert data pipeline builder and data wrangler who enjoys optimizing data systems and evolving them. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data and models devOps (dataOps) architecture is consistent throughout ongoing projects. You are self-directed and comfortable supporting the dataOps needs of multiple teams, systems and products. You will also be responsible for integrating them with the architecture used across the company. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s dataOps architecture to support our existing and next generation of MI-driven products and solutions initiatives.

Key Responsibilities:

Create and maintain optimal data and model dataOps pipeline architectureAssemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies from AWS, Azure and others.Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Keep data separated and secure across national boundaries through multiple data centers and strategic customers/partners.Create tool-chains for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.Work with data and machine learning experts to strive for greater functionality in our data and model life cycle management systems.Support dataOps competence build-up in Ericsson Businesses and Customer Serving Units

Key Qualifications:

Bachelors/Masters/Ph.D. in Computer Science, Information Systems, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.Overall industry experience of around 15 years, at least 5 years’ experience as a Data Engineer.5+ years of experience in the following:


Software/tools: Hadoop, Spark, Kafka, etc.Relational SQL and NoSQL databases, including Postgres and Cassandra.Data and Model pipeline and workflow management tools: Azkaban, Luigi, Airflow, Dataiku, etc.Stream-processing systems: Storm, Spark-Streaming, etc.Object-oriented/object function scripting languages: Python, Java, Scala (Advanced level in one language, at least)
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.Experience performing root cause analysis on internal and external data and processes to answer specific business questions and seek opportunities for improvement.Experience in Data warehouse design and dimensional modelingStrong analytic skills related to working with unstructured datasets.Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of other databases/date-sources.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Experience with Docker containers, orchestration systems (e.g. Kubernetes), continuous integration and job schedulers.Familiar with functional programming and scripting languages such as Javascript or GOKnowledge of server-less architectures (e.g. Lambda, Kinesis, Glue).Experience with microservices and REST APIs.Familiar with agile development and lean principles.Contributor or owner of GitHub repo.Strong project management and interpersonal skills.Experience supporting and working with cross-functional teams in a dynamic environment.Good communication skills in written and spoken EnglishCreativity and ability to formulate problems and solve them independently Ability to build and nurture internal and external communitiesExperience in writing and presenting white papers, journal articles and technical blogs on the results

Additional Requirements:

Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.Experience with data visualization and dashboard creation is a plusAbility to work independently with high energy, enthusiasm and persistenceExperience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

Location : Bangalore (or) Chennai

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics.

Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.

Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.

Primary country and city: India (IN) || || Bangalore || R&D

Req ID: 277724"
37,https://www.glassdoor.co.in/partner/jobListing.htm?pos=120&ao=481833&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_dedebc8b&cb=1562003586333&jobListingId=3261312048,Data Scientist,JDA Software, – Bengaluru,"Your day-to-day work will entail

» Develop and operate solutions that optimize and automate business decisions using

large data sets and algorithms

» Work with complex data analysis, data preparation and developing prognostic

models based on modern statistical methods

» Develop a deep understanding of retail and supply chain problems

» Write productive software that generates value for our customers

» Take ownership of on boarding new customers and continuously improve our existing

solutions

» Work as part of a highly motivated, interdisciplinary and agile team

You are / should have

» In-depth knowledge of data analysis and multivariate statistics, preferably in the

Python data ecosystem

» Passion for writing software with emphasis on quality, testability and automation

» Expertise in working with SQL

» Experience in building machine learning models or optimization software to solve

business problems

» Ability to communicate results clearly to both colleagues and less technically versed

audiences

Everyday, our teams work enthusiastically with our customers on innovative AI-based

solutions and sophisticated optimization for the retail industry. Working with us means you

can look forward to coworkers who use creativity to collectively develop ideas and

appreciate each other’s expertise.

Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values

Check out JDA's blog - Supply Chain Nation - the platform for supply chain trends and innovations."
38,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1114&ao=7438&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_930ae97d&cb=1562003722970&jobListingId=3249976492,Data Scientist – Operations Research,Grofers, – Bengaluru,"Grofers is a low-price online supermarket. We enable customers to order products via our mobile application or website across categories such as grocery, fruits & vegetables, beauty & wellness, household care, baby care, pet care, bakery and meats & seafood and get them delivered to their doorstep. At Grofers we believe in improving the quality of life of our customers by providing them best products at best prices. To be able to meet customer expectations and enrich their shopping experience, we provide them with products they best relate with, help them save money on everyday purchases, and give them the spending power they need. We operate in 13 cities in India and are continuously growing. We’ve raised $226.5 million till date from SoftBank, Tiger Global and Sequoia Capital.

Objective of this Role

As a Data Scientist – Operations Research you will be part of a highly energetic supply chain product team and be part in building next-gen supply chain products for Grofers. You will participate in planning and launching new products and deployments across Pan-India and identifying areas of opportunities

Responsibilities:

Specific day to day responsibilities will include, but will not be limited to:

 Design, build, configure and solutioning applications to meet Grofers business process and requirements.

 Coordinate with operations and training team for new Product deployments and feedback

 Update relevant stakeholders about newly launched features and provide support for product related

queries

 Drive and Track adoption of deployed features

 Coordinate with tech and product team to report bugs and product enhancement

 Resolve ad-hoc queries raised by operations team/business teams

 Work with design and engineering teams through feature implementations

Qualification/Desired Attributes

 Linear Programming, Graphical Solution,

 BFS, Simplex Method, Duality theory, Dual Simplex Method, Sensitivity Analysis,

 Nonlinear Programming, Optimization Models and Techniques, Constraint Optimization, Unconstrained

Optimization, KKT, Relaxation Method,

 Integer Programming, Branch and Bound Method, Cutting Plane Algorithm,

 Linear Integer Programming, Mixed Integer Programming, Bilinear Programming.

 Knowing SQL is added advantage

 Expert in Python, R programming. Preferable to have knowledge in GUROBI / IBM ILOG CPLEX.

 Good to know basics of Data Analysis, Supply Chain Management and retail industry.

 Work with Data Team and Product Manager to understand business requirement and build OR Models

such as linear programming model / integer programming model / mixed-integer programming model and

solve it.

 Must have experience in communication skills, logics of Operations Research and programming.

 Preferred to have knowledge in Warehouse Optimization, Replenishment strategy, Purchase – Demand

planning – Dispatch planning in the supply chain management, Network Optimization, Forecasting and

Predictive analysis in business applications. .

 Required qualification is PhD in Operations Research, M.Sc / M. Tech in Operations Research. If any other

discipline has experience in Operations Research modelling they can also apply.

Excited? You will be, once you visit our Engineering Blog where you can deep dive into all the cool stuff that our engineers have been working on.

All candidates interested in exploring the opportunity are requested to apply with us on careers@grofers.com"
39,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1308&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_3ae9d906&cb=1562003740650&jobListingId=3276854656,Data Scientist – Operations Research,Grofers, – Bengaluru,"Grofers is a low-price online supermarket. We enable customers to order products via our mobile application or website across categories such as grocery, fruits & vegetables, beauty & wellness, household care, baby care, pet care, bakery and meats & seafood and get them delivered to their doorstep. At Grofers we believe in improving the quality of life of our customers by providing them best products at best prices. To be able to meet customer expectations and enrich their shopping experience, we provide them with products they best relate with, help them save money on everyday purchases, and give them the spending power they need. We operate in 13 cities in India and are continuously growing. We’ve raised $226.5 million till date from SoftBank, Tiger Global and Sequoia Capital.

Objective of this Role

As a Data Scientist – Operations Research you will be part of a highly energetic supply chain product team and be part in building next-gen supply chain products for Grofers. You will participate in planning and launching new products and deployments across Pan-India and identifying areas of opportunities

Responsibilities:

Specific day to day responsibilities will include, but will not be limited to:

 Design, build, configure and solutioning applications to meet Grofers business process and requirements.

 Coordinate with operations and training team for new Product deployments and feedback

 Update relevant stakeholders about newly launched features and provide support for product related

queries

 Drive and Track adoption of deployed features

 Coordinate with tech and product team to report bugs and product enhancement

 Resolve ad-hoc queries raised by operations team/business teams

 Work with design and engineering teams through feature implementations

Qualification/Desired Attributes

 Linear Programming, Graphical Solution,

 BFS, Simplex Method, Duality theory, Dual Simplex Method, Sensitivity Analysis,

 Nonlinear Programming, Optimization Models and Techniques, Constraint Optimization, Unconstrained

Optimization, KKT, Relaxation Method,

 Integer Programming, Branch and Bound Method, Cutting Plane Algorithm,

 Linear Integer Programming, Mixed Integer Programming, Bilinear Programming.

 Knowing SQL is added advantage

 Expert in Python, R programming. Preferable to have knowledge in GUROBI / IBM ILOG CPLEX.

 Good to know basics of Data Analysis, Supply Chain Management and retail industry.

 Work with Data Team and Product Manager to understand business requirement and build OR Models

such as linear programming model / integer programming model / mixed-integer programming model and

solve it.

 Must have experience in communication skills, logics of Operations Research and programming.

 Preferred to have knowledge in Warehouse Optimization, Replenishment strategy, Purchase – Demand

planning – Dispatch planning in the supply chain management, Network Optimization, Forecasting and

Predictive analysis in business applications. .

 Required qualification is PhD in Operations Research, M.Sc / M. Tech in Operations Research. If any other

discipline has experience in Operations Research modelling they can also apply.

Excited? You will be, once you visit our Engineering Blog where you can deep dive into all the cool stuff that our engineers have been working on.

All candidates interested in exploring the opportunity are requested to apply with us on careers@grofers.com"
40,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1823&ao=215203&s=58&guid=0000016baeae7564a2953d77b61044d8&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_73c624ac&cb=1562003797815&jobListingId=3267604333,Data Science Engineer,Involvio, – Bengaluru,"
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities


Selecting features, building and optimizing classifiers using machine learning techniques

Data mining using state-of-the-art methods

Extending company's data with third party sources of information when needed

Enhancing data collection procedures to include information that is relevant for building analytic systems

Processing, cleansing, and verifying the integrity of data used for analysis

Doing ad-hoc analysis and presenting results in a clear manner

Creating automated anomaly detection systems and constant tracking of its performance



Skills and Qualifications


Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.

Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. (excellence in at least one of these is highly desirable)

Great communication skills

Experience with data visualisation tools, such as D3.js, GGplot, etc.

Proficiency in using query languages such as SQL, Hive, Pig

Experience with NoSQL databases, such as MongoDB, Cassandra, HBase

Good applied statistics skills, such as distributions, statistical testing, regression, etc.

Good scripting and programming skills in Ruby and Python

Data-oriented personality
"
41,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2209&ao=576937&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_aebd05c8&cb=1562003826192&jobListingId=3245571264,Senior Data Modeler,SiteMinder, – Bengaluru,"Senior Data ModelerWe're looking for a Senior Data Modeler who will be responsible for all the data modelling and analysis projects using SQL, Python and various AWS data stack tech catering to various BI and analytics projects.You will build OLAP data models from scratch by analysing the existing application and business process systems, build optimised summary layers catering to various BI and analytics projects and optimise the existing BI data pipeline by implementing best practices.Who we are Ever booked hotel accommodation on Booking.com, Expedia or TripAdvisor? Chances are, youve used SiteMinder. Our goal is to liberate hoteliers with technology that makes a world of difference, and we do that by helping them find and acquire guests online.We are the worlds leading guest acquisition platform for hotels, supporting 35,000 hotels in 160 countries to generate more than 87 million reservations on our platform each year.Were not like other tech companiesIt's rare that a global tech company is headquartered in Australia, not to mention one thats backed by the same Silicon Valley investor as Facebook, Netflix and Expedia. Hows that for good company?We pioneered a SaaS model for hotels in 2006, and 13 years on, competition is tough but we work hard to call ourselves the worlds leading guest acquisition platform for hotels. So far, we have 35,000 hotel customers in 160 countries, and were on a mission to make a world of difference to 60,000 hotels by 2022!As Senior Data Modeler, your primary responsibilities will include:Build OLAP data models from scratch by analysing existing application and business process systemsBuild optimised summary layers catering to various BI and analytics projectsOptimise the existing BI data pipeline by implementing best practicesBuild strong functional and business knowledge of various applications and business process systems like Salesforce, Zuora etc. Cater to day to day Data Operations and ad-hoc data analysis requestsThe ideal candidate will possess:You have 6+ years of experience in a Data Modelling and analysis role with at least 2 complete data modelling project experience You have developed conceptual, logical and physical data models with associated metadata, including data lineage and technical data definitionsYou have worked on OLTP to OLAP data modelling projectsYou have experience in designing and implementing Dimensional and Fact tablesExperience working within AWS data services such as Redshift, Glue, S3, Athena, Aurora is a plus!You have experience in creating automated data pipelines via Hadoop, SQL and Python based ETL frameworksYou are familiar with complex data lake environments that span across OLTP, MPP and Hadoop platformsProven experience with major big data components like Hive, Hbase, Spark, Pig, Sqoop, Flume, Kafka, MapReduce is advantageous As you are working in our offshore office you will be able to work under minimal supervision and leverage your knowledge, experience, and judgment to accomplish well-defined goalsAs you will have regular communication with our Sydney HQ team you will have competent verbal and written communication skills to discuss projects with remotely located managers and work well in in-person and remote team situations How to applyDoes this job sound like you? If yes, we'd love for you to be part of our team! Please send a copy of your resume and our Talent Acquisition team will be in touch. Why join SiteMinder?At SiteMinder, youll do the best work of your career. Were the trailblazers of our industry and our enemy is closed thinking, so youll have the chance to be creative and question the status quo. Every day, youll have new problems to solve - and meet new people to learn from. We continue to grow rapidly and were committed to supporting the learning you need as you grow with us."
42,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1418&ao=437149&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ec2449de&cb=1562003752619&jobListingId=3201206818,Senior Data Modeler,SiteMinder, – Bengaluru,"Senior Data ModelerWe're looking for a Senior Data Modeler who will be responsible for all the data modelling and analysis projects using SQL, Python and various AWS data stack tech catering to various BI and analytics projects.You will build OLAP data models from scratch by analysing the existing application and business process systems, build optimised summary layers catering to various BI and analytics projects and optimise the existing BI data pipeline by implementing best practices.Who we are Ever booked hotel accommodation on Booking.com, Expedia or TripAdvisor? Chances are, youve used SiteMinder. Our goal is to liberate hoteliers with technology that makes a world of difference, and we do that by helping them find and acquire guests online.We are the worlds leading guest acquisition platform for hotels, supporting 35,000 hotels in 160 countries to generate more than 87 million reservations on our platform each year.Were not like other tech companiesIt's rare that a global tech company is headquartered in Australia, not to mention one thats backed by the same Silicon Valley investor as Facebook, Netflix and Expedia. Hows that for good company?We pioneered a SaaS model for hotels in 2006, and 13 years on, competition is tough but we work hard to call ourselves the worlds leading guest acquisition platform for hotels. So far, we have 35,000 hotel customers in 160 countries, and were on a mission to make a world of difference to 60,000 hotels by 2022!As Senior Data Modeler, your primary responsibilities will include:Build OLAP data models from scratch by analysing existing application and business process systemsBuild optimised summary layers catering to various BI and analytics projectsOptimise the existing BI data pipeline by implementing best practicesBuild strong functional and business knowledge of various applications and business process systems like Salesforce, Zuora etc. Cater to day to day Data Operations and ad-hoc data analysis requestsThe ideal candidate will possess:You have 6+ years of experience in a Data Modelling and analysis role with at least 2 complete data modelling project experience You have developed conceptual, logical and physical data models with associated metadata, including data lineage and technical data definitionsYou have worked on OLTP to OLAP data modelling projectsYou have experience in designing and implementing Dimensional and Fact tablesExperience working within AWS data services such as Redshift, Glue, S3, Athena, Aurora is a plus!You have experience in creating automated data pipelines via Hadoop, SQL and Python based ETL frameworksYou are familiar with complex data lake environments that span across OLTP, MPP and Hadoop platformsProven experience with major big data components like Hive, Hbase, Spark, Pig, Sqoop, Flume, Kafka, MapReduce is advantageous As you are working in our offshore office you will be able to work under minimal supervision and leverage your knowledge, experience, and judgment to accomplish well-defined goalsAs you will have regular communication with our Sydney HQ team you will have competent verbal and written communication skills to discuss projects with remotely located managers and work well in in-person and remote team situations How to applyDoes this job sound like you? If yes, we'd love for you to be part of our team! Please send a copy of your resume and our Talent Acquisition team will be in touch. Why join SiteMinder?At SiteMinder, youll do the best work of your career. Were the trailblazers of our industry and our enemy is closed thinking, so youll have the chance to be creative and question the status quo. Every day, youll have new problems to solve - and meet new people to learn from. We continue to grow rapidly and were committed to supporting the learning you need as you grow with us."
43,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2201&ao=140609&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a35910da&cb=1562003826183&jobListingId=2982200161,Salesforce Wave Analytics Consultant,Enquero, – Bengaluru,"
Ability to work collaboratively in a creative, Agile environment and manage multiple task assignments.
Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.
Good exposure on Wave Analytics.
Must have created Wave dashboards.
Exposure on Datasets, Dataflows, Recipes, Lenses, Dashboards, SAQL and JSON.
Experience creating Work and Approval Flows.
Experience with developing data models within Salesforce.
"
44,https://www.glassdoor.co.in/partner/jobListing.htm?pos=829&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e33c45ff&cb=1562003698158&jobListingId=3200823628,Salesforce Wave Analytics Consultant,Enquero, – Bengaluru,"
Ability to work collaboratively in a creative, Agile environment and manage multiple task assignments.
Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.
Good exposure on Wave Analytics.
Must have created Wave dashboards.
Exposure on Datasets, Dataflows, Recipes, Lenses, Dashboards, SAQL and JSON.
Experience creating Work and Approval Flows.
Experience with developing data models within Salesforce.
"
45,https://www.glassdoor.co.in/partner/jobListing.htm?pos=216&ao=7438&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_9d65e119&cb=1562003628518&jobListingId=3082473168,Data Scientist - Fraud,Simpl, – Bengaluru,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things. Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”. Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

Job Description :

JD

Simpl is building a highly efficient multi dimensional fraud team. The fraud team consists of people from different domains like engineering, data sciences, operations, products etc with a single objective to fight fraud.

As a data scientist in the team you would be responsible for


Analysing and finding new fraud patterns
Design, develop and evaluate predictive models to flag suspicious users based on found pattern
Quantifying the impact of your models on business and evangelising it
Working with other team members of fraud team with an objective to have a complete feedback loop and give a good user experience to the end customers who were falsely flagged

Required skills - Non Negotiable


Good programming skills with clarity in fundamentals - preferably python
Proficient with SQL and relational databases
Proficient with git (https://guides.github.com/introduction/git-handbook/)
Understanding of statistics and model building techniques
Familiarity with AWS infrastructure (EC2, EMR, Redshift, RDS, Redis, Kafka)
Good communication skills
"
46,https://www.glassdoor.co.in/partner/jobListing.htm?pos=714&ao=437149&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c7b4f9a7&cb=1562003690286&jobListingId=3201559772,Data Scientist,Aptus Data LAbs, – Bengaluru,"Job Description:

Hands on Development and Complete Life Cycle experience on one


of the Data Analytics Platform Environment like Rapid Miner, Python,

R and other implementation like Google Analytics, Big ML and Azure

ML.

While most of these tools can be useful, a special concentration would


be on Rapid Miner tool and knowledge of Python and R is also preferred.



Utilize Rapid Miner, Python and R for Statistical Analysis as appropriately.
Good understanding of both open source and commercial distributions


available in the market.



Should have strong implementation of experience of Predictive


Analytics Algorithms like

 Clustering Algorithm

 Decision Tree Algorithm

 Linear Regression Algorithm

 Naïve Bayes Algorithm

 Neural Network Algorithm

 Sequence Clustering Algorithm

 Time Series Algorithm



Also knowledge on the Python and R Packages for the following algorithms


 Machine Learning & Statistical Learning;

 Cluster Analysis & Finite Mixture Models;

 Time Series Analysis;

 Multivariate Statistics; and

 Analysis of Spatial Data.



Optimization and Segmentation
Knowledge of PMML and ability to extend analytical algorithms
Utilize PMML to export and import models from Python, R and


other platforms.



Knowledge of Query language to support analytical models is a plus.
Nice to have knowledge of other products on the Big Data Eco System


 Hadoop

 Hive

 HQL

 HBase

 Mahout



Good Understanding of User Visualization needs of the Analytics
Should have good written and spoken communication skills and should have


played a client facing role

Experience: 2-10 years of experience in data science.

Qualification: B.E, B.Tech, M.sc, M.Tech in computer science"
47,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1310&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_369509f2&cb=1562003740651&jobListingId=3200920772,Data Analyst,Nineleaps, – Bengaluru,"Responsibilities:

Develop complex SQL code.

Analysing results.

Identify, analyse, and interpret trends or patterns in complex data sets.

Defining new data collection and analysis processes.

Requirements:

An analytical mind and inclination for problem-solving.

Experience in data models and reporting packages.

Ability to analyse large datasets.

Perform data quality checks for extremely complex and large data sets.

Bachelor's Degree, preferably in a quantitative discipline.

1-3 years relevant experience in data analytics.

Experience defining user-experience and business metrics.

Proficiency with SQL and a scripting language such as R or Python.

Experience using experimentation to analyse the impact of new features.

Experience working with large / diverse data sets.

Experience telling stories with data to both technical and non-technical audiences and creating clear and compelling visualizations to convey complex data.

Experience managing stakeholders including strong communication and presentation skills.

Strong analytical skills with the ability to collect, organize, analyse, and disseminate data."
48,https://www.glassdoor.co.in/partner/jobListing.htm?pos=820&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_83e05492&cb=1562003698147&jobListingId=3201452864,Data Analyst,Nineleaps, – Bengaluru,"Responsibilities:

Develop complex SQL code.

Analysing results.

Identify, analyse, and interpret trends or patterns in complex data sets.

Defining new data collection and analysis processes.

Requirements:

An analytical mind and inclination for problem-solving.

Experience in data models and reporting packages.

Ability to analyse large datasets.

Perform data quality checks for extremely complex and large data sets.

Bachelor's Degree, preferably in a quantitative discipline.

1-3 years relevant experience in data analytics.

Experience defining user-experience and business metrics.

Proficiency with SQL and a scripting language such as R or Python.

Experience using experimentation to analyse the impact of new features.

Experience working with large / diverse data sets.

Experience telling stories with data to both technical and non-technical audiences and creating clear and compelling visualizations to convey complex data.

Experience managing stakeholders including strong communication and presentation skills.

Strong analytical skills with the ability to collect, organize, analyse, and disseminate data."
49,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1929&ao=116277&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b67a7b96&cb=1562003805572&jobListingId=1396827865,Data Scientist (3+ Years) for an Internet Marketing & Advertising Company,Zyoin, – Bengaluru,"We are looking for a Data Scientist for one of our esteemed Clients for Bangalore Location.

RESPONSIBILITIES:

You need to be a thinker.
We are looking for a very curious data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.
You also need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.
You need to be smart and build smart products.
A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques.
Translate analytic insights into concrete, actionable recommendations for business or product improvement.
You need to be ambitious.
You must be passionate about applying mathematical modeling to solve real world problems.
You must be willing to work with a team of modelers on cutting-edge prediction techniques who knows the best practices around modeling and validation and more than anything, you must love to turn ideas into reality.
If you are the happiest when you can prove the impact of statistical models/machine learning in generating business impact, let us know.

REQUIREMENT:

MTech with 3 years of minimum experience in the area of data science/machine learning (OR) PhD degree specializing in a relevant field such as Probability, Statistics, Machine Learning, Data Mining, Artificial intelligence/Computer Science.
Deep understanding of statistical modeling/machine learning/ data mining concepts
Strong analytical and quantitative problem solving ability
Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data, to folks across various levels of the company.
Understanding of Big Data Technologies like Map Reduce and Hadoop.
Proficiency with any general purpose programming language Java/Python/C/C++.
Proficiency with data analysis platforms, preferably R/Octave/any other open source statistical platform.
Knowledge in Financial Services domain.
Attitude to work in a fast paced and continuously changing environment.
"
50,https://www.glassdoor.co.in/partner/jobListing.htm?pos=309&ao=375053&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c6520d85&cb=1562003656971&jobListingId=3257701823,Data Scientist,SAP, – Bengaluru," 

 

Requisition ID: 217052

Work Area: Software-Design and Development

Expected Travel: 0 - 10%

Career Status: Professional

Employment Type: Regular Full Time

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.

SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Team

The Competitive and Market Intelligence (CMI) team is responsible for analyzing market trends, understanding key competitors in each market, and assessing the impact to SAP’s overall strategic direction and execution. CMI is a part of the Corporate Strategy Group. CMI Crystal Ball is global account intelligence platform that use modern digital analytics to deliver insights into what SAP customers and prospects own and intend to purchase. The CMI Crystal Ball platform injects Big Data account intelligence from an ecosystem of data vendors to enable marketing and sales stronger lead generation and more efficient prospecting. The CMI Data Scientist Expert will report to the CMI Crystal Ball lead and will be virtually be based in India.

Purpose and Objective

The Data Scientist Expert will be virtually based in India CMI Crystal Ball is looking for an outstanding data scientist with the following 3 objectives:

• Lead Crystal Ball platform projects. Drive planning and monitor end-to-end execution of platform projects. Ensure business needs are accomplished in the development of back-end functionality and UX.

• Develop and design market data analysis programs using internal and external data, enhance account intelligence signals to potential markets, account profiles, target accounts, product opportunities and marketing strategies. Query and aggregate heterogenous data sources to support global programs on account intelligence

• Define, propose and implement experimental research strategies on account intelligence. Consult with decision makers and senior management regarding strategic research, planning and analysis, providing insight, knowledge and understanding of markets, solutions and accounts

Role Requirements

For this Data Scientist position we are considering experienced candidates with high analytical problem-solving skills. A experience in scientific and technical work is required. This position requires highly cross-functional coordination with SAP Internal teams and external vendors.

An ideal candidate should possess the following expertise:

• Bachelors or Masters’ in Mathematics, Physics, Computer Science or an equivalent area



At least four years of professional experience, 2 in Data Science
Software Development experience
Proven leadership skills or project management expertise
Proficient in Data mining techniques and data analysis to drive optimization and improvement of solution
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets
Experience querying databases and using statistical computer languages: R, SQL, etc.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Coordinate with different functional and technical teams to implement models and monitor outcomes
Manage relationship with project stakeholders, including internal and external clients, keeping stakeholders informed of progress and issues in order to manage expectations on all project requirements and deliverables
Manage and communicate a clear vision of the project’s objectives, and motivate the project team to achieve them; create a project environment that enables peak performance by team members
Must have hands-on project experience in HANA data modelling
experience in creating Attribute Views, Analytic Views, Graphical and Scripted Calculation Views, Creating Restricted & Calculated Columns

 

WHAT YOU GET FROM US

Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.

SAP'S DIVERSITY COMMITMENT 


To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com).

Successful candidates might be required to undergo a background verification with an external vendor.

Additional Locations: "
51,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1615&ao=589607&s=58&guid=0000016baeae10d6a5800c7f504ba34c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ba19e065&cb=1562003772051&jobListingId=3096252979,"Lead, BigData Data Engineer",Alliance Data card services, – Bengaluru,"Alliance Data develops market-leading private label, co-brand, and business credit card programs for many of the world's most recognizable brands. As one of Fortune’s 100 Best Companies to Work For in the US and consistently recognized as a best place to work in markets we serve, our associates choose us as an employer to feel appreciated, accepted, valued and fulfilled – both personally and professionally. That’s why we are driven to grow – seeking a diverse mix of individuals who will propel the company forward through challenging, enriching experiences that enable our associates, and our organization, to grow together.

Our success has driven us to expand globally, and we are excited about growing our team in Bangalore in 2019! The role of this team is to design, develop and maintain the Data Lab data pipeline framework and database lifecycle management. As the Lead, BigData Data Engineer you will be responsible for acting as the Database Administrator for Data Lab’s production database creation, publication, maintenance and user support.

The Lead BigData Data Engineer works with business users, to explore, identify, test and recommend any new big data related components and solutions to meet the use case requirements. This an opportunity for you to utilize your skills to mentor and guide Senior Data Engineers and partner with the data science team on projects related to model development and deployment framework. As a lead, you will demonstrate excellent understanding of Hadoop Architecture and underlying Hadoop framework including Storage Management.

Education, experience, and knowledge skills and abilities that are minimal requirements in this role are as follows:


Bachelor’s degree in Computer Science, Information Systems or equivalent practical experience; equivalent technical training and experience considered.
Seven or more years of IT experience to include
A minimum of four years of experience dealing with Apache Hadoop Ecosystem like HDFS, MapReduce, Hive, HBase, Sqoop, Oozie, Spark and BigData Analytics
Three or more years of experience in development and support of RDBMS like MS SQL Server, Netezza

To learn more, visit www.KnowMoreSellMore.com/careers

Apply Now!"
52,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2519&ao=132976&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c7789fd9&cb=1562003849875&jobListingId=3272875287,Corporate Cash Management - Transaction Banking Tech – Data Engineer,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBINVESTMENT BANKING

Our division works on some of the most complex financial challenges and transactions in the market today. Whether advising on a merger, providing financial solutions for an acquisition, or structuring an initial public offering, we handle projects that help clients at major milestones. We work with corporations, pension funds, financial sponsors, and governments and are team of strong analytical thinkers, who have a passion for producing out-of-the-box ideas.

Corporate Cash Management

We aim to build a modern and digital-first cash management solution to serve our clients. Our business combines the strength, heritage, and expertise of a 150-year-old firm with the agility and entrepreneurial spirit of a tech start-up. Our goal is to provide a best-in-class digital product that helps clients to succeed by giving them a holistic view of their business. Through the use of modern technology built on the cloud, we are the alternative to legacy platforms. We’re a team of diverse experts helping our clients to build the future of their Treasury.

Transaction Banking

We aim to build a modern and digital-first cash management solution to serve our clients. Our business combines the strength, heritage, and expertise of a 150-year-old firm with the agility and entrepreneurial spirit of a tech start-up. Our goal is to provide a best-in-class digital product that helps clients to succeed by giving them a holistic view of their business. Through the use of modern technology built on the cloud, we are the alternative to legacy platforms. We’re a team of diverse experts helping our clients to build the future of their Treasury.RESPONSIBILITIES AND QUALIFICATIONSThe Team:

Data Platform is a global team (New-York/London/Bangaluru) responsible for detailed technical design and development of data-intensive capabilities using existing and emerging technologies.

The Role:

As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes development, test and rollout of data platform features. You are expected to contribute to the vision and roadmap, and a world-class engineering culture, while integrating business value and client experience within the team. This initiative is of critical importance to the success of the organization and our roadmap. Services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data is a key differentiator and competitive advantage in the market place. We expect a successful candidate to have excellent communication skills, deliver high quality software and to be passionate about cutting edge data engineering.

Basic Qualifications:

Minimum 3-6 years of relevant Big Data experience using a modern processing frameworks (Hadoop, Spark, Airflow, Flink) and programming languages (Java/Scala/Python)
Minimum 1 year production experience with Kafka, Kinesis or equivalent
S. or higher in Computer Science (or equivalent work experience)
Comfort with Agile operating models
Strong interpersonal and communication skills
Energetic, self-directed, and self-motivated

Preferred Qualifications:

Experience with microservice architecture
Experience with MongoDB, Cassandra
Experience with AWS
Experience in Financial Services or Fintech


ABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
53,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2604&ao=643978&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_50e43e4d&cb=1562003857965&jobListingId=3281813379,"Data Science Associate (Bengaluru, India)",ZS Associates, – Bengaluru,"ZS is a professional services firm that works side by side with companies to help develop and deliver products that drive customer value and company results. From R&D to portfolio strategy, customer insights, marketing and sales strategy, operations and technology, we leverage our deep industry expertise and leading-edge analytics to create solutions that work in the real world. Our most valuable asset is our people—a fact that’s reflected in our values-driven organization in which new perspectives are integral and new ideas are celebrated. ZSers are passionately committed to helping companies and their customers thrive in industries ranging from healthcare and life sciences, to high-tech, financial services, travel and transportation, and beyond.

ZS’s India Capability & Expertise Center (CEC) houses more than 60% of ZS people across three offices in New Delhi, Pune and Bengaluru. Our teams work with colleagues across North America, Europe and East Asia to create and deliver real world solutions to the clients who drive our business. The CEC maintains standards of analytical, operational and technological excellence across our capability groups. Together, our collective knowledge enables each ZS team to deliver superior results to our clients.

ZS's Business Consulting group partners with clients to design and deliver solutions to help them tackle a broad range of business challenges. Our teams work on multiple projects simultaneously, leveraging advanced data analytics and problem-solving techniques. Our recommendations and solutions are based on rigorous research and analysis underpinned by deep expertise and thought leadership.

DATA SCIENCE ASSOCIATE

Data Science Associates (DSAs) design, develop and execute high-impact analytics solutions for large, complex, structured and unstructured data sets (including big data) to help clients make better fact-based decisions.

Responsibilities:

Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner;Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning and retrieval processes) on large data sets to identify trends, figures and other relevant information;Collaborate with clients and other ZS stakeholders to effectively integrate and communicate analysis findings;Contribute to the evaluation of emerging datasets and technologies that may contribute to our analytical platform.

Qualifications:

Bachelor's or master's degree in Computer Science (or Statistics), and strong academic performance with analytic and quantitative cousework is required;Knowledge of big data/advanced analytics concepts and algorithms (e.g. text mining, social listening, recommender systems, predictive modeling, etc.);Knowledge of programming (e.g. Java/Python/R);Exposure to tools/platforms (e.g. Hadoop eco system and database systems);Excellent oral and written communication skills;Strong attention to detail, with a research-focused mindset;Excellent critical thinking and problem solving skills;High motivation, good work ethic and maturity.

ZS is a global consulting firm; fluency in English is required, additional fluency in at least one European or Asian language is desirable. 

Candidates must possess work authorization for their intended country of employment. An on-line application, including a cover letter expressing interest and a full set of transcripts (official or unofficial), is required to be considered.

ZS offers a competitive compensation package with salary and bonus incentives, plus an attractive benefits package.

NO AGENCY CALLS, PLEASE.

Connect with ZS in India on social media:

Like ZS in India on FacebookFollow ZS in India on Twitter and InstagramFollow ZS on LinkedIn for more job opportunitiesSubscribe to the ZS in India YouTubechannelExplore the Life at ZS blog

ZS has been recognized globally for its expertise in consulting and its flexible work environment. View ZS’s accolades.

 "
54,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1030&ao=242900&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_eb7987fd&cb=1562003715360&jobListingId=3274780904,Analytic Consulting-Lead Consultant,FICO, – Bengaluru,"FICO (NYSE: FICO) is a leading global analytics software company, helping businesses in 90+ countries make better decisions. Join our world-class team today and fulfill your career potential!

Job SummaryCredit Risk/Collection Analytics – Modelling & Strategy

Are you up for a challenge to deliver world class collection analytics and advanced credit risk solutions? FICO is looking for highly experienced credit risk analysts/modelers to join our high performing team. This is a great opportunity for you to contribute your credit risk and collections knowledge, showcase your advanced analytical/modelling skills and deliver a fully automated and managed solution combining AWS components with some of FICO’s flagship Analytical, AI and Machine Learning products. Our clients are major Financial institutions, Telcos and Utilities companies from all around Asia.

Role

The Cloud Analytics team at FICO’s Global Delivery Center in Bangalore provides consulting services to leading banks, financial institutions, and Telcos across Asia-Pacific region. The team is focused in developing managed analytics services (models and strategies) deployed on “cloud” based platforms. The team works on a wide variety of projects involving development of advanced predictive models and strategies, optimization, and regulatory compliance using the latest tools & techniques.

The role will involve:

Working with FICO’s leading credit risk and collections consultants to design and develop risk/collection models and strategies.
Working with clients in Asia to understand what are the different sources of data available and how those can be utilized to design analytical solutions that can improve the client’s existing business operational practices (acquisitions, account management, fraud, collections, etc.)Job Description

Responsibilities


Analyze data to draw meaningful insights.Develop scorecard models and advanced Machine Learning models to predict different outcomes through the customer lifecycle management.Lead model development and strategy development initiatives, guiding junior analysts on model design, profile variable generation, choice of data sources and appropriate modeling algorithm.Conduct project management responsibilities – take ownership of delivery timelines and quality, track and provide status update to stakeholders, highlight risk/challenges and work through resolutions.Guide junior analysts to design dashboards and reports that will provide important insights for our customersProvide consulting support to customers for interpretation and effective usage of scorecards and decision rulesWork simultaneously on a number of different projects of varying complexity and length

Basic Skills and Experience

Advanced degree in mathematics, statistics, physics, engineering or similar technical field with relevant course work in probability, statistics and quantitative methods6-9 years of core analytical experience with at least 3 years of project/ people managementAt least 5 years’ experience working in the credit risk industry or within collections department’s BI teams of banksHands-on experience with building models/ scoring algorithms using SAS, Python, R, or FICO Model BuilderStrong command of language with ability to communicate persuasively and effectively

Preferred Skills and Experience

Hands on experience of developing Machine Learning models – such as GBM, Random Forest, XgBoost, etc. and ability to interpret the model results from business perspectiveWorked on big data platforms – Hadoop, Hive, Spark, etc.Experience of designing reporting dashboards on TableauExperience in working with AWS EMR to process files using SQL-on-Hadoop technologies such as Hive, Spark SQL and/or Presto


Why Make a Move to FICO?At FICO, you can develop your career with a leading organization in one of the fastest-growing fields in technology today – Big Data analytics. You’ll play a part in our commitment to help businesses use data to improve every choice they make, using advances in artificial intelligence, machine learning, predictive and prescriptive modeling, and much more.

FICO makes a real difference in the way businesses operate worldwide:

Credit Scoring — 150+ billion FICO Scores have been sold to date, making it the most used credit score in the world.Fraud Detection and Security — 2.6+ billion payment cards globally are protected by FICO fraud systems.Lending — 3/4 of US mortgages are approved using the FICO Score.Anti-Money Laundering — our solutions check more than half a billion transactions a day to prevent criminal schemes such as terrorist financing

Global trends toward digital transformation have created tremendous demand for FICO’s solutions, placing us among the world’s top 100 software companies by revenue. We support many of the world’s largest banks, insurers, retailers, telecommunications providers and other firms reach a new level of success.

Our success is dependent on really talented people – just like you – who thrive on the collaboration and innovation that’s nurtured by a diverse and inclusive environment. We’ll provide the support you need, while ensuring you have the freedom to develop your skills and grow your career. Join FICO and help change the way business thinks!

Learn more about how you can fulfill your potential at www.fico.com/Careers

FICO values the benefit that diversity and a culture of inclusion bring to our workplace. We are an equal employment opportunity and affirmative action employer and we’re proud to offer employment and advancement opportunities to all applicants without regard to race, color, ancestry, religion, sex, national origin, pregnancy, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status."
55,https://www.glassdoor.co.in/partner/jobListing.htm?pos=608&ao=437149&s=58&guid=0000016baeacb2b0969190d7bbef71ae&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_4896971f&cb=1562003682455&jobListingId=3200923118,Data Scientist,ShareChat, – Bengaluru,"Requirements:

Bachelor's / Master's degree in a quantitative discipline, e.g., Computer Science, Mathematics, Statistics, Artificial Intelligence.

2+ years of hands-on experience in designing algorithms in Data Science and Artificial Intelligence.

High proficiency with standard database skills (e.g., SQL), data preparation, cleaning, and wrangling/munging.

Deep conceptual understanding of probability & statistics, ML algorithm intuition, and computer science fundamentals.

Deep experience in statistical and machine learning techniques such as classification, regression, feature selection and feature engineering, hyperparameter tuning, unsupervised learning methods, etc.

Experience with deep learning frameworks (e.g., TensorFlow, pyTorch).

Experience with cloud service providers like AWS, GCP, Azure.

Experience with fundamental building blocks of AI, such as natural language processing and computer vision.

Experience with recommendation systems and reinforcement learning.

Understanding of data visualisation concepts and fundamentals.

Personal projects and Kaggle competition results can serve as differentiation.

Ability to explain statistical reasoning to both experts and non-experts.

Strong communication and interpersonal skills.

Ability to learn new skills/technologies quickly and independently.

Independent problem-solving skills."
56,https://www.glassdoor.co.in/partner/jobListing.htm?pos=627&ao=433315&s=58&guid=0000016baeacb2b0969190d7bbef71ae&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1c17f76e&cb=1562003682574&jobListingId=3230275585,Data Science Expert,Hewlett Packard Enterprise, – Bengaluru,"Hewlett Packard Enterprise is not only the company best equipped to build a bridge from where enterprise IT is today, to where it needs to be, but HPE is also an incredible place to build a career. As the only company that brings it allsoftware, hardware, services, and talented people with the right mindsetwe help organizations innovate, stay competitive, and quickly turn ideas into value.

Designs, develops and applies programs, methodologies and systems based on advanced analytic models (e.g. advanced statistics, operations research, computer science, process) to transform structured and unstructured data into meaningful and actionable information insights that drive decision making.

Uses visualization techniques to translate analytic insights into understandable business stories (eg. descriptive, inferential and predictive insights).

Embeds analytics into clients business processes and applications. Combines business acumen and scientific methods to solve business problems.

Responsibilities:

• Guides and coordinates the formulation and definition of analytics solution objectives and technical requirements based on user needs, an understanding of business processes, industry requirements and advanced analytic models (statistical, operations research, computing, process).

• Conceptualizes, builds, develops and enhances a client's analytic model. Selects the relevant analytic modeling methodologies for the use case, available structured and unstructured data, cost and timing constraints to solve the complex business issues and deliver clear business focused insights.

• Embeds analytic models into an enhanced large scale business process and operational systems by collaborating with Application Developers.

• As an expert, creates best practices for applying analytic methods to problem domains.

• Using advanced visualization techniques, condenses complex ideas into elegant and simple visual models.

• Communicates the innovative analytic solution to stakeholders providing industry insight and improvements to the operational systems.

Education and Experience Required:

•PhD degree in Statistics, Operations Research, Computer Science or equivalent preferred and 3+ years of relevant experience. Or Master´s Degree in these areas and at least 5-6 years of relevant experience.

Knowledge and Skills:

• In-depth knowledge of data science methodologies including but not limited to classical regression, neural nets, CHAID, CART, association rules, sequence analysis, cluster analysis, and text mining.

• Ability to translate business requirements into mathematical models and data science objectives to achieve measurable business outcomes.

• In depth understanding of analytics software (eg. R, SAS, SPSS, Python). Advanced understanding of analytics deployment architectures.

• In-depth machine learning, data integration and mathematical modeling skills and ETL tools (Informatica, Ab Initio, Talend).

• In-depth communication and presentation skills.

• Strong interpersonal skills and effectiveness in working across geographical boundaries.

• Advanced knowledge of programming languages such as Python, SQL, R, SAS, Java, Unix Shell scripting. Advanced knowledge of Hadoop framework desired.

• In-depth knowledge of data visualization techniques and software tools (eg. Spotfire, SAS, R, Qlikview, Tableau, HTML5, D3).

Hewlett Packard Enterprise Values:

Partnership first: We believe in the power of collaboration - building long term relationships with our customers, our partners and each other

Bias for action: We never sit still - we take advantage of every opportunity

Innovators at heart: We are driven to innovate - creating both practical and breakthrough advancements

What do we offer?

Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.

If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers

You can also find us on:

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1044216"
57,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1606&ao=437149&s=58&guid=0000016baeae10d6a5800c7f504ba34c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_79ac350b&cb=1562003772043&jobListingId=3236552343,Sr Data Scientist - Dna,Neustar, – Bengaluru,Neustar Inc is a leading global information services provider driving the connected world forward with trusted holistic identity resolution More information is available at https www home neustar Job Requisition R-1661 Sr Data Scientist - DNA Open Primary Location BANGALORE The Data and Analytics organization at Neustar is the DNA of the company The DNA encodes the essence of existence and character that drives continuous innovation with data continuous insights with analytics and continuous evolution with cutting-edge data products and services Our vision is to be the trailblazer in Connection…
58,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2926&ao=133266&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e398b584&cb=1562003887238&jobListingId=2781184469,Specialized Analytics Manager- SBS,Citi, – Bengaluru,"
Primary Location: India,Karnataka,BangaloreEducation: Master's DegreeJob Function: Decision ManagementSchedule: Full-timeShift: Day JobEmployee Status: RegularTravel Time: Yes, 10 % of the TimeJob ID: 18032985


Description

About us: Global Decision Management is a global community that is driving data driven transformation across Citi in multiple functions with the objective to create actionable intelligence for our business leaders. We are a fast growing organization working with Citi businesses and functions across the world. What do we offer:

As GDM we support analytical functions across all geographies and businesses. Few notables among the multiple areas that we work in:Customer lifecycle management: Design and implement strategies to improve customer experience and drive revenue, spanning across all 3 stages of customer lifecycle acquisition, ECM and RetentionOffer optimization: Design, test and implement innovative and customer-centric offers tailored to drive customer delight and grow engagementProduct & Pricing: Deep-dive into product features, analyze product effectiveness and price products intelligently to create innovative products at attractive prices thatll keep Citi ahead of its competitionDigital: Trace customers digital journey with Citi, design strategies to make digital experience more engaging and drive revenue through low cost digital channelsRevenue/Financial forecasting: Design, maintain and enhance P&L forecasting for all products & portfolios, ensure strict adherence to accounting standards and accurate forecasting techniques to help product managers plan betterIn order to achieve the best in class analytical solutions across business units we use the best in class tools and technology.Expertise Required:

Programming SAS, Unix, SQL, R, PythonDatabases: Teradata Good understanding of the Banking and Lending business along with strong understanding of customer life cycleKnow-how of Modelling techniques traditional and Machine Learning Algorithms is a good to have  Learn and follow industry best practices Ability to work well with a variety of people and to show team-player attitude regardless the scope of responsibilitiesAbility to identify, clearly articulate and solve complex business problems and present them to the management in a structured and simpler formIndependently work on projects end-to-end, manage stakeholder expectations and timelinesContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.Questioning the status quo

Qualifications

Educational and Experience:



MBA / Master degree in Economics / Statistics / Mathematics / Information Technology / Computer Applications / Engineering from a premier institute. BTech / B.E in Information Technology / Information Systems / Computer Applications (Preferred) Post Graduate in Computer Science, Mathematics, Operations Research, Statistics, Econometrics, Management Science and related fields2 to 8 years of hands on experience in delivering Analytical solutions, Banking Industry Exposure would be good to haveExcellent Communication and Inter-personal skillsStrong process/project management skills


"
59,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2624&ao=437149&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f8b4bca3&cb=1562003857985&jobListingId=3223640329,Insight Center - Revenue Analytics _ Manager,State Street, – Bengaluru,"Responsibilities & Tasks Include:

Completion of high quality deliverables within the committed timeframe. Deliverables typically relate to;

Month/quarter/year-end closing and forecast

Annual operational planning process (budget)

Revenue reviews (direct revenues and allocated revenues)

Monthly revenue waterfalls

Multi-dimensional profitability (business, region, product and client)

Business volumes trending (e.g. market activity, client activity)

Variance analysis along with preparation of management presentations describing insights

New business pipeline

Communicates with business units throughout the company to collect information for Revenue management reporting and analyses

Work closely with Revenue Analytics team members to provide requested analysis, reports and metrics

Participate and Lead in various analytics modeling efforts as needed

Innovate analytical approaches to identify business development opportunities through Revenue IC and Revenue related analyses. Integral to this innovation will be the ability to collaborate with other business units to establish an agreed-upon basis of business rules and a united vision of actionable insights.

Collaborate and Lead Information Techonology/Database/Automation initiatives, developing and representing the Revenue analysis requirements from project inception through operationalization.

Document analytical approaches/analyses via Process/Desk Guides. Perform quality assuramce reviews.

Communicate insights and recommendations to senior management through effective oral and written communication

Analyzes and validates prototype, ad hoc, and periodic reports for accuracy

Serves as a subject matter expert on Financial analysis and recommendations and provides guidance, training and oversight to less seasoned analysts

Job Requirements:Education and Experience:

Bachelor’s with 10 – 14 years relevant experience or Master’s with minimum 8-10 years of experience ideally covering multiple of the following:

Financial services industry experience preferred

Preparation and analysis of Financial Statement and experience in a global setting

Experience with gathering, preparation, and consolidation and summary of fiscal data for multi-national companies

Multi-dimensional profitability (business, product, client)

Variance analysis and reporting of insights

Skills/ Knowledge:

Must be able to work in a fast paced environment

Proficiency in Tableau and Spotfire.

Proficiency in Microsoft Office suite (Excel, Access, PowerPoint, Word, Visio), advanced levels of excel (pivot tables, formulas, excel workbook maintenance best practices)

Pride of ownership with the ability to drive results within the Business

Must possess strong communication skills with ability to participate in or lead conference calls and present financial results to financial and non-financial audiences at various levels of seniority

Solid business knowledge as it relates to the financial services industry

Knowledge of Hyperion Profitability Cost Management,Hyperion Essbase, Salesforce 360 all advantageous.

Knowledge of quering database to extract data

Financial product and institutional knowledge

Self-motivated, self-assured, and self-managed

Results oriented ownership mindset

Ability to multi-task and work under high pressure deadlines

Deatailed Skill Requirements

Design & develop Visual reporting solutions based on client requirement

Play a consultant role in technical evaluation & tool selection (industry based)

Recommend best design concepts, architecture & data flow process

Understand & implement BI standards, guidelines and best practices

Expert in end-to-end development from Design to Prod roll-out.

Understands concepts of ETL, having worked on data extraction, Transformation and loading data from different sources

Well versed with SQL queries, Stored Procedures & SSIS

Should have strong analytical, problem-solving and interpersonal skills

Good at stakeholder & expectation management

Strong experience in Data Warehousing and ETL concepts

Design, Develop and support interactive Tableau/Spotfire Dashboard Reports

Extensive knowledge in creating data visualizations using Tableau Desktops and regularly publishing and presenting dashboards.

Should be well versed with concepts of Marks, Actions, Filters, Parameters, calculations, aggregates, hierarchies, formatting, sorting, and grouping.

Have good experience in Development and Production Support from Tableau Server end

Good experience in Spotfire professional, web player and analytics server for loading data from databases, creating visualization and filters

Proficiency in TIBCO Spotfire features like multiple filtering schemes, custom expression, multiple marking, multiple data table and relation between multiple data table, property control etc.

Working knowledge of Alteryx will be an added advantage

Creating, maintaining and updating the technical requirement document, design document, mapping document, issue log, implementing and recommending industry BI standards and best practices"
60,https://www.glassdoor.co.in/partner/jobListing.htm?pos=201&ao=493722&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_722aa5f0&cb=1562003628498&jobListingId=3261516478,Data Scientist,C3.ai, – Bengaluru,"C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The proven C3 AI Suite provides the comprehensive services to build enterprise scale AI applications 40x to 100x faster than alternative approaches. The core of the C3 AI Suite is a revolutionary, extensible, model-driven abstraction layer that dramatically enhances data scientist and application developer productivity. The C3 AI Suite supports any value chain in any industry with pre-built, configurable, high-value AI applications for predictive maintenance, fraud detection, sensor network health, supply network optimization, energy management, anti-money laundering, and customer engagement. www.c3.ai

In this capacity, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating IoT. In addition, you will help find the appropriate machine learning, AI, and specifically deep learning algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.

Qualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.

Your Responsibilities:

Driving adoption of Deep Learning systems into next-generation of C3.ai products.
Designing and deploying deep learning algorithms on industrial IoT applications such as fraud detection and predictive maintenance.
Collaborating with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.

Requirements:

MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred.
Applied Machine Learning experience (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning).
Strong mathematical background (linear algebra, calculus, probability and statistics).
Excellent programming skills in JavaScript and prototyping languages such as Python and R.
Ability to drive a project and work both independently and in a team.
Smart, motivated, can do attitude, and seeks to make a difference.
Excellent verbal and written communication.

Preferred

Experience with Java and Scala is a plus.
A portfolio of projects (GitHub, papers, etc.) is a plus.

C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status."
61,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2204&ao=576937&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_acc1a1b9&cb=1562003826186&jobListingId=3243490638,Big Data Engineer,SiteMinder, – Bengaluru,"Big Data EngineerWe're looking for a Big Data Engineer to build core data architecture components from scratch as part of our enterprise data architecture enhancements. You will be analysing and optimising the existing data architecture, identifying, analysing and integrating various data source systems being used across the business. You will ensure that our data architecture is working as well as undertaking regular maintenance. Who we are:Ever booked hotel accommodation on Booking.com, Expedia or TripAdvisor? Chances are, youve used SiteMinder. Our goal is to liberate hoteliers with technology that makes a world of difference, and we do that by helping them find and acquire guests online.We are the worlds leading guest acquisition platform for hotels, supporting 35,000 hotels in 160 countries to generate more than 87 million reservations on our platform each year.Were not like other tech companiesIt's rare that a global tech company is headquartered in Australia, not to mention one thats backed by the same Silicon Valley investor as Facebook, Netflix and Expedia. Hows that for good company?We pioneered a SaaS model for hotels in 2006, and 13 years on, competition is tough but we work hard to call ourselves the worlds leading guest acquisition platform for hotels. So far, we have 35,000 hotel customers in 160 countries, and were on a mission to make a world of difference to 60,000 hotels by 2022!As our Big Data Engineer, your primary responsibilities will include:Build core data architecture components from scratch as part of enterprise data architecture enhancementsAnalyse and optimise the existing Data architecture using best practicesIdentify, analyse and integrate various data source systems being used across the organisationEnsure existing data architecture works optimally and undertake regular maintenance tasks The ideal candidate will possess:Will have 6+ years of experience in a Data Engineer role with at least 1 complete cloud implementation project experienceYou have demonstrated experience in developing Enterprise data architecture using latest Big Data technologies preferably Open SourceYou have demonstrated experience of working within AWS data services such as Glue, EMR, Kinesis, Redshift, Athena, Aurora, etc.You have demonstrated experience of designing complex workflows on workflow management tools like Airflow, AWS Data pipeline, etc. You have developed customised integration layers in Python through REST and SOAP APIs architecturesStrong technical abilities to understand, design, write and debug complex code in Python, Spark and SQL is a mustWorking knowledge of message queuing, stream processing, and highly scalable big data data stores using Kinesis, Kafka, etc.Experience of Tableau server management and optimisation on Cloud server would be a great advantageGood understanding of data architecture related services on GCP and Azure would be a great advantageYou should have good data analysis skills using SQL or PythonAs you are working in our offshore office you will be able to work under minimal supervision and leverage your knowledge, experience, and judgment to accomplish well-defined goalsAs you will have regular communication with our Sydney HQ team you will have competent verbal and written communication skills to discuss projects with remotely located managers and work well in in-person and remote team situations How to applyDoes this job sound like you? If yes, we'd love for you to be part of our team! Please send a copy of your resume and our Talent Acquisition team will be in touch. Why join SiteMinderAt SiteMinder, youll do the best work of your career. Were the trailblazers of our industry and our enemy is closed thinking, so youll have the chance to be creative and question the status quo. Every day, youll have new problems to solve - and meet new people to learn from. We continue to grow rapidly and were committed to supporting the learning you need as you grow with us. "
62,https://www.glassdoor.co.in/partner/jobListing.htm?pos=518&ao=437149&s=58&guid=0000016baeac946289d87fba82cd68ad&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_32f72122&cb=1562003674692&jobListingId=3230236850,Data Scientist,Walmart Labs, – Bengaluru," This position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits.  The team operates an end to end advertising platform that includes a scalable ad service that serves hundreds of millions of impressions each day, sophisticated ad matching algorithms, real-time reports, self-service interface for end to end program management etc. We are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyze massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms underneath it all to analyze all this data on top of Hadoop and Spark. Responsibilities: Gathering and analyzing data, identifying key prediction/classification problems, devising solutions and building prototypes.  Formulating machine learning/statistical approaches while paying attention to business metrics, designing features from the rich data available from many sources, training, evaluating, and deploying models.  Researching and implementing methodologies to measure the impact of the technologies.  Initiating and proposing unique and promising modeling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate.  Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, product-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.  Staying current on published data mining, machine learning and modeling techniques and competing technologies and sharing these findings with scientists and engineers in the organization.  Maintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community."
63,https://www.glassdoor.co.in/partner/jobListing.htm?pos=824&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_23b75f9a&cb=1562003698150&jobListingId=3203694384,Principal Data Scientist,Oracle, – Bengaluru," Principal Data Scientist-19000BCF  Preferred Qualifications  Job Purpose  The Oracle CEGBU offers customers the industry’s most advanced solutions for planning, scheduling and delivering large-scale construction projects. We provide an end-to-end offering for project management and delivery that enables customers to effectively plan, build, and operate construction projects.  The Analytics & Data Science team at Oracle CEGBU is working to develop and deploy AI and Machine Learning based solutions at scale and throughout all of Oracle's CEGBU existing products and services. We are growing the team with brilliant and diverse individuals with exceptional technical ability. This is a challenging role that will stretch your knowledge and curiosity, while at the same time is a great opportunity to learn new skills and work within an unusually talented, global community at Oracle CEGBU.  This is a hands-on position where you will be expected to solve challenging problems and have the potential to directly impact Oracle’s CEGBU data strategy and business. The role requires that you have an extensive background in prototyping, modelling, model validation, production rollout at scale and post rollout improvements of machine learning based solutions. A proven track record in inventing and modifying advanced innovative algorithms and applying them to large data sets is essential.  This is a leadership role where you will lead a team of local and overseas data scientists. You will be a team player who is eager to both teach and learn daily, that is proactive and self-motivated and has excellent communication skills. Responsibilities Works independently and with a small team to solve complex problems and create scalable models/algorithms that will be integrated into proprietary tools and products.  Works directly with product managers & senior leadership to translate their vision into practical solutions  Effectively communicate what is being worked on, problems being solved, customer impact, and progress of projects from time to time to various stakeholders  Participates in industry forums to showcase the analytical depth of the organization  Actively participate as a contributor and lead a team of peer data scientists, understanding the collaborative and transparent relationships with engineering and product teams and the ways of working of an agile environment.  Proven track record in shipping successful data products  Clearly communicate roadmap, backlog, and team updates across the organization  Leads collaborative processes with cross-functional stakeholders to identify questions and complex business challenges and determine concrete plans of action in order to strategically define, design, and develop sophisticated machine learning models and algorithms to solve for each problem.  Proactively identify and develop expertise in new technologies, methodologies, and techniques facilitating data science and systems engineering  Identify predictive analytics opportunities to solve customer business problems and drive value  Complete end-to-end execution of the data science process. This may be carried out in a collaborative environment with product and engineering teams, but ranges from understanding business requirements, data discovery and extraction, model development and evaluation, to production pipeline implementation.  Required Skills & Experience  Masters, M.S or Ph.D. in a relevant technical field, or practical experience in a relevant discipline such as Computer Science, Physics, Engineering, Mathematics, or another relevant quantitative field.  Overall 3+ years leading, building, mentoring data science teams  Overall 6-8+ years of experience in data science  Exceptionally proficient with Artificial Intelligence/Machine Learning/Data Mining/Natural Language Processing/Pattern Recognition/Computer Vision.  Strong understanding of statistical modelling and its application to solving business problems  Strong experience in building at scale, production grade machine learning solutions and data pipelines.  Highly proficient in languages and tools used in ML modeling like R, Python (SciKit Learn, SciPy, Numpy, etc.), Apache Spark (Scala or Python), H2O, Weka, TensorFlow, Torch, Keras.  Extensive experience in building and rolling out scoring models, response models, optimization, forecasting, segmentation etc.  Experience with cloud infrastructure and deployments is a plus  Experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies such as Map Reduce, Spark, HBase, etc., and associated schemas.  Strong skills in data management approaches such as relational databases, data schemas, object stores, column stores, triple stores, graph stores, and/or document stores  Ability to deliver accurate work products in a cross-functional matrix environment with product teams, engineering teams and business stakeholders.  Excellent technical design, problem solving, debugging and communication skills  Detailed Description and Job Requirements  Designs, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client services and product enhancement.  Interacts with product and service teams to identify questions and issues for data analysis and experiments. Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Identifies meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.  Leading contributor individually and as a team member, providing direction and mentoring to others. Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. 8 years relevant work experience. BS/BA preferred."
64,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2609&ao=437149&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d097f7a2&cb=1562003857968&jobListingId=3201432747,Lead Software Engineering - Data Science,Fidelity Investments, – Bengaluru,"(Job Number: 1902868)  The incumbent would be developing in AI/ML technologies as part of data science team within EP [Data CoE]  The Purpose of This Role  Develop and deliver deep capability in big data technologies and data science across verticals  The Value You Deliver  Delivering data science and big data projects across verticals  The Skills that are Key to this role  Technical / Behavioral  Should have working knowledge experience with NO-SQL and Graph databases and good knowledge with relational database or flat file manipulations on Unix or with data wrangling tools  Candidate should be expert in handling various data types and structures: structured, unstructured, voice, image and video data, static versus streaming data. Extensive prior experience in integrating data, profiling, validating and cleansing data in Big Data platforms is a must.  The candidate should possess knowledge of and experience in applying statistics, data mining, machine learning and deep learning techniques in a professional context  Working proficiency in statistical tools and programming environments like Python, R, SAS, Big Data platforms like Hadoop, Spark is a must.  Candidate will be expected to communicate analytical results and developed solutions in a way that is meaningful for business stakeholders and provides actionable insights.  The Skills that are Good To Have for this role  Must possess good programming languages skill in Python  Exposure to Deep Learning applications and tools like TensorFlow, Theano, Torch, Caffe is preferred  Exposure to Graph Databases like GraphX, Neo4j and semantic web applications will be preferred  Effective communication and excellent “story-telling from data” abilities  Ability to influence stakeholders and provide thought leadership  Have the ability to discover new opportunities where analytical techniques can be leveraged for solving business problems.  How your work Impacts the Organization  EP[Data CoE] stays abreast of emerging data technology and collaborates with multiple business units in handling and delivering projects to provide end-to-end data services in traditional and new data technologies also develop and deliver deep capability in big data technologies and data science  The Expertise we’re looking For  4+ years of relevant experience with organizations known for cutting edge/ best-in-class applications of Advanced Analytics, Predictive Modeling and Artificial Intelligence.  Bachelor’s / Master’s Degree in a quantitative field (e.g., Computer Science, Economics, Engineering, Statistics, Mathematics, Finance, Operations Research)  Fidelity Investments is one of the world's largest providers of financial services. Headquartered in Boston, US, Fidelity's goal is to make financial expertise broadly accessible and effective in helping people live the lives they want. Privately held for nearly 70 years, Fidelity employs 45,000 associates who are focused on the long-term success of our customers. FMR (Fidelity Management & Research) India is the Global Inhouse Center of Fidelity Investments. Headquartered at Bangalore, where operations commenced in 2003, FMR India has another fully-functional unit at Chennai. To know more visit: FMR India Location: Bangalore – Manyata Shift timings: 11:00 am - 8:00pm  Technology  Primary LocationIN-KRN-Bangalore  Job LevelIndividual Contributor  Education LevelBachelor's Degree (±16 years)  FMR India Business UnitTechnology Services  OrganizationIndia BG  Job Posting DateMar 11, 2019, 7:13:36 AM"
65,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2916&ao=389996&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9a68e927&cb=1562003887224&jobListingId=3036802163,"Software Engineer, Data Services",Grab, – Bengaluru,"Job Description:Get to know our Team: GrabPay (digital payment wallet for SEA) and GFSA – Grab Financial Services Asia is a recent addition to Grab’s array of product and service offerings focused on the extension of Microcredit to drivers, agents, and merchants in Grab’s ecosystem. GFSA team is a combination of a strong talent pool and deep local market operators across its focus markets. We are incredibly excited about the opportunity ahead of us. We are looking to put together the best possible combination of business build drive, industry expertise, and local market depth as part of our team. GFSA team is responsible for end to end conceptualization, design, development, execution and ongoing management of all lending activities in its focus markets and segments.Get to know the Role:As the Software Engineer, Data Services role, you will be working on all aspects of Data, from Platform and Infra build out to pipeline engineering and writing tooling/services for augmenting and fronting the core platform. You will be responsible for building and maintaining the state-of-the-art data Life Cycle management, including acquisition, storage, processing and consumption channels. The team works closely with Data scientists, Product Managers, Legal, Compliance and business stakeholders across the SEA in understanding and tailoring the offerings to their needs. As a member of the Data Services, GrabPay, you will be an early adopter and contributor to various open source big data technologies and you are encouraged to think out of the box and have fun exploring the latest patterns and designs in the fields of Software and Data Engineering.The day-to-day activities:- Build and manage Grab’s largest data asset using some of the most scalable and resilient open source big data technologies like Kafka, Yarn, HDFS, ElasticSearch, Presto, HDF and similar- Design and deliver a next-gen data lifecycle management suite of tools/frameworks, including ingestion and consumption on the top of the data lake to support real-time, API-based and serverless use-cases, along with batch (mini/micro) as relevant- Liaise with Product, BD and other relevant stakeholders in identifying and coding for various data related quirks like regional legal and regulatory requirements, metadata unification, securing the access and storage through right access control frameworks- Build and expose metadata catalog for the Data Lake for easy exploration, profiling as well as lineage requirements- Enable Data Science teams to test and productionize various ML models, including propensity, risk and fraud models to better understand, serve and protect our customers- Lead technical discussions across the organization through collaboration, including running RFC and architecture review sessions, tech talks on new technologies as well as retrospectives- Apply core software engineering and design concepts in creating operational as well as strategic technical roadmaps for business problems that are vague/not fully understood - Obsess security by ensuring all the components, from the platform, frameworks to the applications are fully secure and are compliant by the group’s infosec policies. The must haves:- At least 3 to 8 years of relevant application and/or platform development experience of mission-critical systems on Hadoop, Mesos, Kubernetes, Kafka or similar. Candidates will be aligned appropriately within the organization depending on experience and depth of knowledge- Should be familiar with all Hadoop Ecosystem components and Hadoop Administration Fundamentals- Good knowledge of Complex Event Processing (CEP) systems like Spark Streaming, Kafka etc- Strong software engineering background, with good knowledge of algorithms, distributed systems, databases and software engineering.- Strong hands-on experience in at least one of the programming languages used at Grab - Java, Scala, Python or Go along with a fair understanding of runtime complexities.- Experience with NoSQL databases – KV/Document/Graph and similar.- Proven Ability to contribute to open source community and up-to-date with the latest trends in the Big Data Space.- Good understanding and hands-on OS knowledge especially Linux flavor.- “Educated” on latest developments in the areas of dev-ops and CI/CD, including containerization, blue-green deployments, 12-factor apps, secrets management etc - Good understanding of Machine Learning models and efficiently support them is a plus."
66,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2007&ao=14295&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_33718cf0&cb=1562003813146&jobListingId=3236552132,"Software Engineer, Data Services",Grab, – Bengaluru,"Job Description:Get to know our Team: GrabPay (digital payment wallet for SEA) and GFSA – Grab Financial Services Asia is a recent addition to Grab’s array of product and service offerings focused on the extension of Microcredit to drivers, agents, and merchants in Grab’s ecosystem. GFSA team is a combination of a strong talent pool and deep local market operators across its focus markets. We are incredibly excited about the opportunity ahead of us. We are looking to put together the best possible combination of business build drive, industry expertise, and local market depth as part of our team. GFSA team is responsible for end to end conceptualization, design, development, execution and ongoing management of all lending activities in its focus markets and segments.Get to know the Role:As the Software Engineer, Data Services role, you will be working on all aspects of Data, from Platform and Infra build out to pipeline engineering and writing tooling/services for augmenting and fronting the core platform. You will be responsible for building and maintaining the state-of-the-art data Life Cycle management, including acquisition, storage, processing and consumption channels. The team works closely with Data scientists, Product Managers, Legal, Compliance and business stakeholders across the SEA in understanding and tailoring the offerings to their needs. As a member of the Data Services, GrabPay, you will be an early adopter and contributor to various open source big data technologies and you are encouraged to think out of the box and have fun exploring the latest patterns and designs in the fields of Software and Data Engineering.The day-to-day activities:- Build and manage Grab’s largest data asset using some of the most scalable and resilient open source big data technologies like Kafka, Yarn, HDFS, ElasticSearch, Presto, HDF and similar- Design and deliver a next-gen data lifecycle management suite of tools/frameworks, including ingestion and consumption on the top of the data lake to support real-time, API-based and serverless use-cases, along with batch (mini/micro) as relevant- Liaise with Product, BD and other relevant stakeholders in identifying and coding for various data related quirks like regional legal and regulatory requirements, metadata unification, securing the access and storage through right access control frameworks- Build and expose metadata catalog for the Data Lake for easy exploration, profiling as well as lineage requirements- Enable Data Science teams to test and productionize various ML models, including propensity, risk and fraud models to better understand, serve and protect our customers- Lead technical discussions across the organization through collaboration, including running RFC and architecture review sessions, tech talks on new technologies as well as retrospectives- Apply core software engineering and design concepts in creating operational as well as strategic technical roadmaps for business problems that are vague/not fully understood - Obsess security by ensuring all the components, from the platform, frameworks to the applications are fully secure and are compliant by the group’s infosec policies. The must haves:- At least 3 to 8 years of relevant application and/or platform development experience of mission-critical systems on Hadoop, Mesos, Kubernetes, Kafka or similar. Candidates will be aligned appropriately within the organization depending on experience and depth of knowledge- Should be familiar with all Hadoop Ecosystem components and Hadoop Administration Fundamentals- Good knowledge of Complex Event Processing (CEP) systems like Spark Streaming, Kafka etc- Strong software engineering background, with good knowledge of algorithms, distributed systems, databases and software engineering.- Strong hands-on experience in at least one of the programming languages used at Grab - Java, Scala, Python or Go along with a fair understanding of runtime complexities.- Experience with NoSQL databases – KV/Document/Graph and similar.- Proven Ability to contribute to open source community and up-to-date with the latest trends in the Big Data Space.- Good understanding and hands-on OS knowledge especially Linux flavor.- “Educated” on latest developments in the areas of dev-ops and CI/CD, including containerization, blue-green deployments, 12-factor apps, secrets management etc - Good understanding of Machine Learning models and efficiently support them is a plus."
67,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1230&ao=437149&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_13217ea8&cb=1562003730787&jobListingId=3281819371,Data Engineer,TiVo, – Bengaluru,"Responsibilities: Design a multi-tier data pipeline to feed data into an OLTP & OLAP applications for building a full featured analytics environment.  Design and build database schemas to handle large scale data migration & transformation.  Design and build ETL/ELT process to move data through the data processing pipeline. Requirements: Experience in spark and Java/Scala/Python. Working experience with one or more of the tech stacks: Hadoop/MPP/Presto.  Extensive experience SQL query optimization/tuning and debugging SQL performance issues.  Unix shell, ETL and scheduling tools.  Firm understanding of database systems - Data Warehouse, Data modeling, SQL Query.  Processing and Transactions Know how to scale systems and make them fast.  Large scale DW, MPP, Redshift, or similar technologies, AWS."
68,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2309&ao=437149&s=58&guid=0000016baeaf02b2ab5fbd2932bb3fa0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_380bd71b&cb=1562003834796&jobListingId=3248908426,Data Visualization Expert,Educational Initiatives, – Bengaluru," Role and Responsibilities  Develop dashboards for the internal reporting of data from our products across the organization  Translating business analytics needs into data visualization and semantic data access requirements  Work with data engineers to facilitate the technical design of complex data sourcing, transformation and aggregation logic, ensuring business analytics requirements are met  Collaborate with data scientists and subject matter experts to identify useful and strategically relevant insights  Leverage enterprise standard tools and platforms to visualize analytics insights, typically working with and/or leading a small team.  Help drive business stakeholder adoption of insights-driven decision making and/or business process innovation.  Drive the development of and adherence to data visualization standards  Conceptualize, design and develop data visualization solutions that synthesize data concepts into clear communications for key business stakeholders.  Reduce data to the bare minimum of what is needed to optimally communicate a message. Opportunities you will have : Flat organizational structure  Meritocracy-driven, candid culture  Very high visibility  Opportunity to work with leading machine learning experts and education leaders  Must have  A broad level of understanding surrounding business information systems  Demonstrated ability to analyze and interpret complex problems or processes that span multiple business areas, identify and understand requirements, and develop alternative solutions  Demonstrated a strong sense of visual design and interest in creative visualization work  Develop dashboards for the internal reporting of data from our products across the organization  Translating business analytics needs into data visualization and semantic data access requirements  Work with data engineers to facilitate the technical design of complex data sourcing, transformation and aggregation logic, ensuring business analytics requirements are met  Collaborate with data scientists and subject matter experts to identify useful and strategically relevant insights  Leverage enterprise standard tools and platforms to visualize analytics insights, typically working with and/or leading a small team.  Help drive business stakeholder adoption of insights-driven decision making and/or business process innovation.  Drive the development of and adherence to data visualization standards  Conceptualize, design and develop data visualization solutions that synthesize data concepts into clear communications for key business stakeholders.  Reduce data to the bare minimum of what is needed to optimally communicate a message. Opportunities you will have : Flat organizational structure  Meritocracy-driven, candid culture  Very high visibility  Opportunity to work with leading machine learning experts and Education leaders  Any course in Data Science  Experience  3 5 years of experience in developing business analytics solutions, focusing on requirements gathering and effective visualization of insights.  2+ years of experience with data visualization/BI tools, preferably Qlik Sense. Experience in tools such as Tableau, PowerBI, SQL and semantic data access mechanisms is also relevant.  Experience in MySQL, Redshift, HTML, PHP."
69,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2217&ao=4120&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_bd50c4fc&cb=1562003826202&jobListingId=3147904793,Big Data Engineer,AutoGrid, – Bengaluru,"Company Overview AutoGrid builds software applications that enable a smarter Energy Internet. The company’s suite of Energy Internet applications allows utilities, electricity retailers, renewable energy project developers and energy service providers to deliver cheap, clean & reliable energy by managing networked distributed energy resources (DERs) in real time and at scale. AutoGrid applications are all built on the AutoGrid Energy Internet Platform (EIP), with patented Predictive Controls™ technology that leverages petabytes of smart meter, sensor & third-party data, along with powerful data science & high-performance computing algorithms, to monitor, predict, optimize and control the operations of millions of assets connected across global energy networks.  The world’s leading energy companies, including E.ON, Bonneville Power Administration, Florida Power & Light, Southern California Edison, Eneco, Portland General Electric, CPS Energy, New Hampshire Electric Cooperative, NextEra Energy, Xcel Energy & CLEAResult, are using AutoGrid’s software to improve their operations, integrate renewables and drive deeper engagement with their customers. The Cleantech Group has recognized AutoGrid with several prestigious industry awards including Greentech Media’s Grid Edge Award 2016, Bloomberg New Energy Pioneer 2016, World Economic Forum Technology Pioneer 2015, Red Herring Top 100 North America 2015, Cleantech Global 100 for 2015 and 2014, and Industrial Innovation Company of the Year 2014.  AutoGrid India Pvt. Ltd. is a 100% subsidiary of AutoGrid Systems, Inc., setup in Bangalore in Q4 2016 with a focus on Internet/big data/analytics product engineering and business activities in the smart energy domain. Job DescriptionResponsibilities and DutiesDesign and develop Big Data architecture and server-side components that drive AutoGrid’s Energy Data PlatformBenchmark and debug critical issues with algorithms and software as they ariseWork closely with application development and product management teams to understand application requirementsAssist DevOps in troubleshooting product issues in production and demo systemsQualifications and SkillsEducation: B.Tech/BE/BS in Computer Science or equivalent degree (Electrical/Electronics/etc. Eng)Experience: 2-4 years at any leading SaaS firm, startup firm, or energy/product software firmDeep understanding and experience with Big Data (specifically in Hadoop, Map Reduce, Spark, HBase, etc.) frameworksExperienced in following technologies:Application development in Python and Java programing languagesDistributed system deploymentsServer-side caching (e.g. Redis)Web services (REST and SOAP)SQL (MySQL, PostgreSQL)Experience in designing and architecting enterprise application platform a plusExcellent verbal and written communication skillsAbility to lead technical projects and code at the same timeExperience with Agile / SCRUM methodology for product developmentProven ability and desire to deliver projects on time with high qualityAble to cope with and thrive in fast paced, dynamic work environment with evolving project requirementsStart-up experience, entrepreneurial spirit, energetic!Nice to Have SkillsExperience with JRuby programming skillsExperience with Tusker frameworkExperience with Cloud technologies e.g. Amazon AWS or Microsoft AzureCloudera experience and trainingExperience with horizontally scaling web tools (HAProxy, Unicorn)Exposure to ETL tools, and proprietary platforms such as Greenplum, Teradata, SAP HANA, SplunkData warehouse / BI tools experienceBenefits and PerksAttractive MNC-standards CTC - based on skills, education, experience and past CTCCollaborative, close-knit, informal & open environment with a strong leadership teamOpportunity to be working with a really smart and fun group of people on solving BIG problems in CUTTING-EDGE technology domains for a HUGE EMERGING global industryPremium office on Outer Ring Road in Tier 1 business center with good connectivityMedical & accident insurance coverage, travel support, and free home broadbandHigh-end MacBookPro office & home computerHigh quality company-funded lunch… everydayFlexibility in working hours and working locations"
70,https://www.glassdoor.co.in/partner/jobListing.htm?pos=625&ao=4120&s=58&guid=0000016baeacb2b0969190d7bbef71ae&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_139aed1a&cb=1562003682572&jobListingId=3167079886,Data Analyst, – Bengaluru, – Bengaluru,"Company Overview AutoGrid builds software applications that enable a smarter Energy Internet. The company’s suite of Energy Internet applications allows utilities, electricity retailers, renewable energy project developers and energy service providers to deliver cheap, clean & reliable energy by managing networked distributed energy resources (DERs) in real time and at scale. AutoGrid applications are all built on the AutoGrid Energy Internet Platform (EIP), with patented Predictive Controls™ technology that leverages petabytes of smart meter, sensor & third-party data, along with powerful data science & high-performance computing algorithms, to monitor, predict, optimize and control the operations of millions of assets connected across global energy networks.  The world’s leading energy companies, including E.ON, Bonneville Power Administration, Florida Power & Light, Southern California Edison, Eneco, Portland General Electric, CPS Energy, New Hampshire Electric Cooperative, NextEra Energy, Xcel Energy & CLEAResult, are using AutoGrid’s software to improve their operations, integrate renewables and drive deeper engagement with their customers. The Cleantech Group has recognized AutoGrid with several prestigious industry awards including Greentech Media’s Grid Edge Award 2016, Bloomberg New Energy Pioneer 2016, World Economic Forum Technology Pioneer 2015, Red Herring Top 100 North America 2015, Cleantech Global 100 for 2015 and 2014, and Industrial Innovation Company of the Year 2014.  AutoGrid India Pvt. Ltd. is a 100% subsidiary of AutoGrid Systems, Inc., setup in Bangalore in Q4 2016 with a focus on Internet/big data/analytics product engineering and business activities in the smart energy domain. Job DescriptionResponsibilities and DutiesDesign and develop Big Data architecture and server-side components that drive AutoGrid’s Energy Data PlatformBenchmark and debug critical issues with algorithms and software as they ariseWork closely with application development and product management teams to understand application requirementsAssist DevOps in troubleshooting product issues in production and demo systemsQualifications and SkillsEducation: B.Tech/BE/BS in Computer Science or equivalent degree (Electrical/Electronics/etc. Eng)Experience: 2-4 years at any leading SaaS firm, startup firm, or energy/product software firmDeep understanding and experience with Big Data (specifically in Hadoop, Map Reduce, Spark, HBase, etc.) frameworksExperienced in following technologies:Application development in Python and Java programing languagesDistributed system deploymentsServer-side caching (e.g. Redis)Web services (REST and SOAP)SQL (MySQL, PostgreSQL)Experience in designing and architecting enterprise application platform a plusExcellent verbal and written communication skillsAbility to lead technical projects and code at the same timeExperience with Agile / SCRUM methodology for product developmentProven ability and desire to deliver projects on time with high qualityAble to cope with and thrive in fast paced, dynamic work environment with evolving project requirementsStart-up experience, entrepreneurial spirit, energetic!Nice to Have SkillsExperience with JRuby programming skillsExperience with Tusker frameworkExperience with Cloud technologies e.g. Amazon AWS or Microsoft AzureCloudera experience and trainingExperience with horizontally scaling web tools (HAProxy, Unicorn)Exposure to ETL tools, and proprietary platforms such as Greenplum, Teradata, SAP HANA, SplunkData warehouse / BI tools experienceBenefits and PerksAttractive MNC-standards CTC - based on skills, education, experience and past CTCCollaborative, close-knit, informal & open environment with a strong leadership teamOpportunity to be working with a really smart and fun group of people on solving BIG problems in CUTTING-EDGE technology domains for a HUGE EMERGING global industryPremium office on Outer Ring Road in Tier 1 business center with good connectivityMedical & accident insurance coverage, travel support, and free home broadbandHigh-end MacBookPro office & home computerHigh quality company-funded lunch… everydayFlexibility in working hours and working locations"
71,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2623&ao=37049&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1deb5f4d&cb=1562003857984&jobListingId=2781184476,Specialized Analytics Manager- SBS,Citibank, – Bengaluru,"Primary Location: India,Karnataka,BangaloreEducation: Master's DegreeJob Function: Decision ManagementSchedule: Full-timeShift: Day JobEmployee Status: RegularTravel Time: Yes, 10 % of the TimeJob ID: 18032985 DescriptionAbout us:Global Decision Management is a global community that is driving data driven transformation across Citi in multiple functions with the objective to create actionable intelligence for our business leaders. We are a fast growing organization working with Citi businesses and functions across the world.What do we offer:As GDM we support analytical functions across all geographies and businesses. Few notables among the multiple areas that we work in:Customer lifecycle management: Design and implement strategies to improve customer experience and drive revenue, spanning across all 3 stages of customer lifecycle acquisition, ECM and RetentionOffer optimization: Design, test and implement innovative and customer-centric offers tailored to drive customer delight and grow engagementProduct & Pricing: Deep-dive into product features, analyze product effectiveness and price products intelligently to create innovative products at attractive prices thatll keep Citi ahead of its competitionDigital: Trace customers digital journey with Citi, design strategies to make digital experience more engaging and drive revenue through low cost digital channelsRevenue/Financial forecasting: Design, maintain and enhance P&L forecasting for all products & portfolios, ensure strict adherence to accounting standards and accurate forecasting techniques to help product managers plan betterIn order to achieve the best in class analytical solutions across business units we use the best in class tools and technology.Expertise Required:Programming SAS, Unix, SQL, R, PythonDatabases: Teradata Good understanding of the Banking and Lending business along with strong understanding of customer life cycleKnow-how of Modelling techniques traditional and Machine Learning Algorithms is a good to have  Learn and follow industry best practices Ability to work well with a variety of people and to show team-player attitude regardless the scope of responsibilitiesAbility to identify, clearly articulate and solve complex business problems and present them to the management in a structured and simpler formIndependently work on projects end-to-end, manage stakeholder expectations and timelinesContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.Questioning the status quo QualificationsEducational and Experience:MBA / Master degree in Economics / Statistics / Mathematics / Information Technology / Computer Applications / Engineering from a premier institute. BTech / B.E in Information Technology / Information Systems / Computer Applications (Preferred) Post Graduate in Computer Science, Mathematics, Operations Research, Statistics, Econometrics, Management Science and related fields2 to 8 years of hands on experience in delivering Analytical solutions, Banking Industry Exposure would be good to haveExcellent Communication and Inter-personal skillsStrong process/project management skills"
72,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2518&ao=437149&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c79a2352&cb=1562003849874&jobListingId=3264204519,Specialized Analytics Manager- SBS,Citibank, – Bengaluru,"Primary Location: India,Karnataka,BangaloreEducation: Master's DegreeJob Function: Decision ManagementSchedule: Full-timeShift: Day JobEmployee Status: RegularTravel Time: Yes, 10 % of the TimeJob ID: 18032985 DescriptionAbout us:Global Decision Management is a global community that is driving data driven transformation across Citi in multiple functions with the objective to create actionable intelligence for our business leaders. We are a fast growing organization working with Citi businesses and functions across the world.What do we offer:As GDM we support analytical functions across all geographies and businesses. Few notables among the multiple areas that we work in:Customer lifecycle management: Design and implement strategies to improve customer experience and drive revenue, spanning across all 3 stages of customer lifecycle acquisition, ECM and RetentionOffer optimization: Design, test and implement innovative and customer-centric offers tailored to drive customer delight and grow engagementProduct & Pricing: Deep-dive into product features, analyze product effectiveness and price products intelligently to create innovative products at attractive prices thatll keep Citi ahead of its competitionDigital: Trace customers digital journey with Citi, design strategies to make digital experience more engaging and drive revenue through low cost digital channelsRevenue/Financial forecasting: Design, maintain and enhance P&L forecasting for all products & portfolios, ensure strict adherence to accounting standards and accurate forecasting techniques to help product managers plan betterIn order to achieve the best in class analytical solutions across business units we use the best in class tools and technology.Expertise Required:Programming SAS, Unix, SQL, R, PythonDatabases: Teradata Good understanding of the Banking and Lending business along with strong understanding of customer life cycleKnow-how of Modelling techniques traditional and Machine Learning Algorithms is a good to have  Learn and follow industry best practices Ability to work well with a variety of people and to show team-player attitude regardless the scope of responsibilitiesAbility to identify, clearly articulate and solve complex business problems and present them to the management in a structured and simpler formIndependently work on projects end-to-end, manage stakeholder expectations and timelinesContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.Questioning the status quo QualificationsEducational and Experience:MBA / Master degree in Economics / Statistics / Mathematics / Information Technology / Computer Applications / Engineering from a premier institute. BTech / B.E in Information Technology / Information Systems / Computer Applications (Preferred) Post Graduate in Computer Science, Mathematics, Operations Research, Statistics, Econometrics, Management Science and related fields2 to 8 years of hands on experience in delivering Analytical solutions, Banking Industry Exposure would be good to haveExcellent Communication and Inter-personal skillsStrong process/project management skills"
73,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2411&ao=444227&s=58&guid=0000016baeaf24ef886cc75aedc25f50&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a16a0e1d&cb=1562003842914&jobListingId=3279056318,"Staff Engineer, Data Engineering",Western Digital, – Bengaluru,"Job Description Staff Engineer, Data EngineeringBangalore, IndiaSNDK BigData & IIoT-IndiaSanDisk India DDC Pvt LtdJR-0000043039Western Digital®The next big thing in data is you!ESSENTIALS DUTIES AND RESPONSIBILITIES:•	Meeting users, gathering user requirements and communicating requirements to technical team member for technical solution design, feasibility study & planning.•	Designing, developing and maintaining business intelligence solutions•	Translate User Request into Analytics Solution from system perspective. Translate business needs to technical specifications.•	Mocking up visualization for user review•	Design, develop, deploy and maintain Analytics solutions independently.•	Delivered/completed tasks within the plan timeline. Provide accurate plan to deliver tasks•	Ability to communicate/collaborate to all parties within department and inter-department.•	Participating in Analytics System Implementation. Provide alternative / innovative solution on system issue / implementation.•	Database Admin, ETL, Data Preparation, Web App Development, Visualization development, DevOps, SAS Programming and Analytics.•	Create and maintain optimal data pipeline architecture,•	Assemble large, complex data sets that meet functional / non-functional business requirements.•	Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.•	Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.•	Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.•	Work with data and analytics experts to strive for greater functionalityQUALIFICATIONSEducational Required: •	Minimum a degree in Information Technology, Computer Science or other related fields.Skills Required : •	Data Technology: Databases (MSSQL), MPP Platform (PDW & RedShift), Big data tools (Hive, Spark, Impala, Cassandra, Presto, Kafka etc.), ETL Tool (SSIS, SAS DI & etc.), SQL, Scripting and SAS programming.•	Web App Development: Web Application Architecture,UI/UX Design, Front-end Development, HTML, PHP, Javascript, AngularJS/ReactJS, Dockerization, bitbucket.•	Data Visualization/BI Platform: Spotfire, Tableau and SAS Visual Analytics.•	Scripting: Java, Powershell, Python, Scala & SAS Programing•	Edge Computing/Streaming: Apache Spark, Kafka, or related Streaming Analytics technologies•	Analytics Tool : SAS, JMP and R•	AWS cloud services: EC2, EMR, RDS, Redshift Experience: •	6 to 10 years of experience in related IT, Data Analytics and/or Engineering/ Manufacturing Industries.•	Profound analytical, logical thinking, and problem solving skills.•	Implementing Big Data and Analytics system.•	Working Knowledge & Experience in AWS Cloud environment and SAS platform will be added advantages.•	In this role, you should have a background in data and business analysis. You should be analytical and an excellent communicator. If you also have a business acumen and problem-solving aptitude•	Proven abilities to take initiative and be innovative•	Analytical mind with a problem-solving aptitude•	Excellent analytical, mathematical, and creative problem-solving skills.•	Understanding of the organizations goals and objectives.•	Self-motivated and directed. Ability to prioritize and execute tasks while under pressure.•	Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.•	Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.•	Build processes supporting data transformation, data structures, metadata, dependency and workload management.•	A successful history of manipulating, processing and extracting value from large disconnected datasets.ABOUT WESTERN DIGITAL The future. It’s on you. You & Western Digital.We’ve been storing the world’s data for more than 50 years. Once, it was the most important thing we could do for data. Now we’re helping the world capture, preserve, access and transform data in a way only we can.The most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data.But we can’t do it alone. Today’s exceptional data challenges require your exceptional skills. It’s You & Us. Together, we’re the next big thing in data. Western Digital® data-centric solutions are found under the G-Technology™, HGST, SanDisk®, Tegile™, Upthere™, and WD® brands.






"
74,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1601&ao=354908&s=58&guid=0000016baeae10d6a5800c7f504ba34c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_895c6fcb&cb=1562003772038&jobListingId=3279843046,Sr Data Engineer - Python Developer,Cisco Systems, – Bengaluru,"Business purpose:

Today’s enterprises are leveraging data lake architectures to enable new ways to empower analytics, business intelligence, and new product features. We’re leveraging the latest GCP and AWS services to build a cutting-edge, highly scalable and cost-effective platform.

An immediate opportunity exists for a Senior level Engineer with a passion for creating outstanding products to help take Cloud calling Analytics team to the next level. We need someone who is passionate about leading change, exploiting and optimizing customer engagement, driving experiences across our Cloud collaboration stakeholders, growing our platform, incorporating new workloads and expanding our capabilities.What You’ll Do:

Be a key leader and contributor to the design and development of a scalable and cost-effective cloud-based data platform based on a data lake design.Be collaborative with team members, Product Management, Architects, data producers and data consumers throughout the company.Develop data platform components in a cloud environment to ingest data and events from cloud and on-premises environments as well as third parties Build automated pipelines and data services to validate, catalog, aggregate and transform ingested data.Build automated data delivery pipelines and services to integrate data from the data lake to internal and external consuming applications and servicesBuild and deliver cloud-based deployment and monitoring capabilities consistent with DevOps modelsKeep knowledge and skills current with the latest cloud services, features and best practices

Who You Are:

Extensive experience in designing and delivering enterprise-grade, high transaction volume, Data Platform as a Services (dPaaS) and experience with Data Lakes, Analysis Services, SQL, Cosmos or an equivalent set of cloud capabilities.6 to 8 year’s experience working with data: querying it, wrangling it, moving it, parsing it, cleaning it, transforming it, performing computations on it, securing it, archiving it, and serving it for analysis and visualization – there’s nothing about data and data management you haven’t seen or done.3 ++ years hands-on experience developing data lake solutions operating on cloud-native infrastructure in public and/or private cloud environments such as AWS, GCP, or Azure.Advanced experience in scalable data and full text indexing solutions such as Elastic Search/Logstash/Kibana (ELK stack) Experience with data streaming technologies and real time analytics Familiar data serialization formats such as JSON, Parquet, and ORC and have an experience-based opinion on when one should be used over another.Working experience and detailed knowledge in Python, Java, JavaScript, and/or Perl.Knowledge of ETL, Map Reduce and pipeline tools (Glue, EMR, Spark)Experience with large or partitioned relational databases (Aurora, MySQL, SQL Server) Experience with NoSQL databasesAgile development (Scrum) experienceOther preferred experience includes working with DevOps practices, SaaS, IaaS, code management (git), deployment tools (CodeBuild, CodeDeploy, Jenkins, Shell scripting), and Continuous Delivery


Why Cisco

● We connect everything: people, processes, data, and things. We innovate everywhere, taking bold risks to shape the technologies that give us smart cities, connected cars, and handheld hospitals. And we do it in style with unique personalities who aren’t afraid to change the way the world works, lives, plays and learns.

● We are thought leaders, tech geeks, pop culture aficionados, and we even have a few purple haired rock stars. We celebrate the creativity and diversity that fuels our innovation. We are dreamers and we are doers.

● We Are Cisco."
75,https://www.glassdoor.co.in/partner/jobListing.htm?pos=711&ao=437149&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_cc22d8d2&cb=1562003690284&jobListingId=3201508873,Data Scientist, – Bengaluru, – Bengaluru,"Business purpose:

Today’s enterprises are leveraging data lake architectures to enable new ways to empower analytics, business intelligence, and new product features. We’re leveraging the latest GCP and AWS services to build a cutting-edge, highly scalable and cost-effective platform.

An immediate opportunity exists for a Senior level Engineer with a passion for creating outstanding products to help take Cloud calling Analytics team to the next level. We need someone who is passionate about leading change, exploiting and optimizing customer engagement, driving experiences across our Cloud collaboration stakeholders, growing our platform, incorporating new workloads and expanding our capabilities.What You’ll Do:

Be a key leader and contributor to the design and development of a scalable and cost-effective cloud-based data platform based on a data lake design.Be collaborative with team members, Product Management, Architects, data producers and data consumers throughout the company.Develop data platform components in a cloud environment to ingest data and events from cloud and on-premises environments as well as third parties Build automated pipelines and data services to validate, catalog, aggregate and transform ingested data.Build automated data delivery pipelines and services to integrate data from the data lake to internal and external consuming applications and servicesBuild and deliver cloud-based deployment and monitoring capabilities consistent with DevOps modelsKeep knowledge and skills current with the latest cloud services, features and best practices

Who You Are:

Extensive experience in designing and delivering enterprise-grade, high transaction volume, Data Platform as a Services (dPaaS) and experience with Data Lakes, Analysis Services, SQL, Cosmos or an equivalent set of cloud capabilities.6 to 8 year’s experience working with data: querying it, wrangling it, moving it, parsing it, cleaning it, transforming it, performing computations on it, securing it, archiving it, and serving it for analysis and visualization – there’s nothing about data and data management you haven’t seen or done.3 ++ years hands-on experience developing data lake solutions operating on cloud-native infrastructure in public and/or private cloud environments such as AWS, GCP, or Azure.Advanced experience in scalable data and full text indexing solutions such as Elastic Search/Logstash/Kibana (ELK stack) Experience with data streaming technologies and real time analytics Familiar data serialization formats such as JSON, Parquet, and ORC and have an experience-based opinion on when one should be used over another.Working experience and detailed knowledge in Python, Java, JavaScript, and/or Perl.Knowledge of ETL, Map Reduce and pipeline tools (Glue, EMR, Spark)Experience with large or partitioned relational databases (Aurora, MySQL, SQL Server) Experience with NoSQL databasesAgile development (Scrum) experienceOther preferred experience includes working with DevOps practices, SaaS, IaaS, code management (git), deployment tools (CodeBuild, CodeDeploy, Jenkins, Shell scripting), and Continuous Delivery


Why Cisco

● We connect everything: people, processes, data, and things. We innovate everywhere, taking bold risks to shape the technologies that give us smart cities, connected cars, and handheld hospitals. And we do it in style with unique personalities who aren’t afraid to change the way the world works, lives, plays and learns.

● We are thought leaders, tech geeks, pop culture aficionados, and we even have a few purple haired rock stars. We celebrate the creativity and diversity that fuels our innovation. We are dreamers and we are doers.

● We Are Cisco."
76,https://www.glassdoor.co.in/partner/jobListing.htm?pos=724&ao=437149&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_dcb84e6c&cb=1562003690301&jobListingId=3273087650,Data Scientist, – Bengaluru, – Bengaluru,"Business purpose:

Today’s enterprises are leveraging data lake architectures to enable new ways to empower analytics, business intelligence, and new product features. We’re leveraging the latest GCP and AWS services to build a cutting-edge, highly scalable and cost-effective platform.

An immediate opportunity exists for a Senior level Engineer with a passion for creating outstanding products to help take Cloud calling Analytics team to the next level. We need someone who is passionate about leading change, exploiting and optimizing customer engagement, driving experiences across our Cloud collaboration stakeholders, growing our platform, incorporating new workloads and expanding our capabilities.What You’ll Do:

Be a key leader and contributor to the design and development of a scalable and cost-effective cloud-based data platform based on a data lake design.Be collaborative with team members, Product Management, Architects, data producers and data consumers throughout the company.Develop data platform components in a cloud environment to ingest data and events from cloud and on-premises environments as well as third parties Build automated pipelines and data services to validate, catalog, aggregate and transform ingested data.Build automated data delivery pipelines and services to integrate data from the data lake to internal and external consuming applications and servicesBuild and deliver cloud-based deployment and monitoring capabilities consistent with DevOps modelsKeep knowledge and skills current with the latest cloud services, features and best practices

Who You Are:

Extensive experience in designing and delivering enterprise-grade, high transaction volume, Data Platform as a Services (dPaaS) and experience with Data Lakes, Analysis Services, SQL, Cosmos or an equivalent set of cloud capabilities.6 to 8 year’s experience working with data: querying it, wrangling it, moving it, parsing it, cleaning it, transforming it, performing computations on it, securing it, archiving it, and serving it for analysis and visualization – there’s nothing about data and data management you haven’t seen or done.3 ++ years hands-on experience developing data lake solutions operating on cloud-native infrastructure in public and/or private cloud environments such as AWS, GCP, or Azure.Advanced experience in scalable data and full text indexing solutions such as Elastic Search/Logstash/Kibana (ELK stack) Experience with data streaming technologies and real time analytics Familiar data serialization formats such as JSON, Parquet, and ORC and have an experience-based opinion on when one should be used over another.Working experience and detailed knowledge in Python, Java, JavaScript, and/or Perl.Knowledge of ETL, Map Reduce and pipeline tools (Glue, EMR, Spark)Experience with large or partitioned relational databases (Aurora, MySQL, SQL Server) Experience with NoSQL databasesAgile development (Scrum) experienceOther preferred experience includes working with DevOps practices, SaaS, IaaS, code management (git), deployment tools (CodeBuild, CodeDeploy, Jenkins, Shell scripting), and Continuous Delivery


Why Cisco

● We connect everything: people, processes, data, and things. We innovate everywhere, taking bold risks to shape the technologies that give us smart cities, connected cars, and handheld hospitals. And we do it in style with unique personalities who aren’t afraid to change the way the world works, lives, plays and learns.

● We are thought leaders, tech geeks, pop culture aficionados, and we even have a few purple haired rock stars. We celebrate the creativity and diversity that fuels our innovation. We are dreamers and we are doers.

● We Are Cisco."
77,https://www.glassdoor.co.in/partner/jobListing.htm?pos=626&ao=437149&s=58&guid=0000016baeacb2b0969190d7bbef71ae&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_14e0c64b&cb=1562003682573&jobListingId=3267628957,Machine Learning Engineer,GO-JEK, – Bengaluru,"Responsibilities:

Work as part of a product team in defining, prototyping and implementing machine learning models/algorithms as part of the product.

Take ownership of the ML model end-to-end - from data collection to model building to scaling out the prototype to very large datasets and building tools to monitor the model in production.

Work with the engineering team to define best practices for ML model building, testing and deployment.

Mentor junior colleagues, conduct internal workshops and external meetups, participate in external conferences and give talks.

Requirements:

Solid understanding of the machine learning methods, models and related mathematics.

Ability to understand business concerns and formulate them as technical problems that can be solved using data and ML.

Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the machine learning solution.

Experience working with large data sets, coming from varied sources.

Experience with deep learning and associated tools and technologies.

Familiarity with data engineering technologies (Kafka/Flink/Spark etc).

Masters in a computer science with 4 - 6 years experience working as a Research Engineer or Machine Learning Engineer in a product company."
78,https://www.glassdoor.co.in/partner/jobListing.htm?pos=230&ao=140609&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d9dd059c&cb=1562003628533&jobListingId=1996429935,Data Scientist,Data Semantics, – Bengaluru,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/PythonShould have at least working knowledge of SQL and RDBMSShould have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.Should have experience in working with clients in gathering the requirements and handling client queriesShould have a knack for Problem Solving using technologyShould be capable of working under tight deadlines independently"
79,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1827&ao=437149&s=58&guid=0000016baeae7564a2953d77b61044d8&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ec88f245&cb=1562003797819&jobListingId=3239624660,Data Scientist,Data Semantics, – Bengaluru,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/PythonShould have at least working knowledge of SQL and RDBMSShould have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.Should have experience in working with clients in gathering the requirements and handling client queriesShould have a knack for Problem Solving using technologyShould be capable of working under tight deadlines independently"
80,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2829&ao=437149&s=58&guid=0000016baeafa65a98836b4f5999adf7&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f095f760&cb=1562003875893&jobListingId=3200584554,DATA ANALYST - EQUITIES, – Bengaluru, – Bengaluru,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/PythonShould have at least working knowledge of SQL and RDBMSShould have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.Should have experience in working with clients in gathering the requirements and handling client queriesShould have a knack for Problem Solving using technologyShould be capable of working under tight deadlines independently"
81,https://www.glassdoor.co.in/partner/jobListing.htm?pos=130&ao=4120&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a08af072&cb=1562003586344&jobListingId=3178930909,Data Scientist,HackerRank, – Bengaluru,"HackerRank is a Y Combinator alumnus backed by tier one Silicon Valley VCs. We are a skills-based hiring platform that helps companies evaluate technical skills, better. We’re driving a new paradigm shift by eliminating resumes and creating opportunities for hundreds of thousands of programmers worldwide. We have a community of 5M+ developers and 1,000+ customers across industries, and the best part is we are just getting started. Our customers - including VMware, Twitter, Capital One and many other Fortune 100 companies - rely on HackerRank to build strong engineering teams.

We've assembled an amazing team that’s passionate about creating more opportunities for people by changing the way companies hire. We are ambitious, data-driven givers, and we love delighting customers. If you're interested in scaling HackerRank by working with some of the largest companies in the world, let’s talk.

HackerRank is growing its Data Science capabilities in Bangalore. As a Data Scientist, you will build data products that augment our product offerings. In addition to our community and customers, we have approximately 100 million challenge submissions on our platform. You will be leveraging this data to help us understand our developers better and how we can use this knowledge to help match them to the jobs that are a good fit for them. This position offers great opportunities for impact and growth as you will be part of the building this team from the early days.

WHAT YOU’LL LOVE TO DO…

Understand developers: use our data on their interactions with our platform, cluster them, categorize them, match them to jobs they would be a good fit for
Interpret data, analyze results, identify patterns and trends using statistical techniques
Evangelize data best practices as they relate to experimentation, forecasting, and analytics
Communicate results back to the relevant members of the business through reports and dashboards
Defining new data collection and analysis processes
Empowering and guiding others to work effectively and efficiently with data are part of your role
Work towards creating a data-informed culture

WHAT YOU’VE ALREADY DONE…

Degree in Computer Science / Statistics/Operations Research / Mathematics or related fields
Bachelor degree with 3+ years of work experience or a Masters/PhD degree with 1+ years of work experience as a Data Analyst/Product Analyst/Statistician/Data Scientist/ML engineer/Applied Scientist
You are obsessed with data: You love understanding data, cleaning it, transforming it, merging it with third-party data, making it provide knowledge and insights
Fluency in SQL, as well as a deep understanding of statistical analysis, experiment design, forecasting, and common pitfalls of data analysis
You are a self-starter: You drive projects with minimal guidance and focus on high impact work. You have shown impact in your prior jobs
Strong communicator: You effectively synthesize, visualize, and communicate your ideas to others. You have shown that you help in decision-making
You are a critical thinker: You are thoughtful, self-aware, and use the available evidence to make decisions. You have shown that you can influence leadership with data
You work effectively with teammates and win credibility quickly
Strong background in areas such as statistics, math, computer science and other quantitative fields

GET EXCITED. Because you're about to have a huge impact.

HackerRank is growing fast and we're having a great time working together as we build! We're a fun, friendly, passionate bunch. We’re a team of teams and we’re looking for more smiling faces to come join us! The position is full-time and based in the heart of Bangalore.

PERKS & BENEFITS. “As if working alongside the smartest brains wasn’t enough!”

We have a full package of competitive benefits and perks available for you and your dependents:


Insurance to all Employees (term life, personal accident, medical, gratuity) along with insurance to their dependents(medical).
Employee stock options, flexible work hours and time off.
Employee Reimbursements on gym, telephone, internet etc.
Our pantry is stocked with healthy snacks, fruits, Coffee and free catered lunch every day.
Ping pong, hoverboard, foosball, PS4 and many office celebrations like Mafia games, outings, movie evenings to name a few!
"
82,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1027&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_fc506c78&cb=1562003715356&jobListingId=3265566530,Senior Data Scientist,Treebo, – Bengaluru,"We are looking for our first data scientist, who would help us build out the Data Sciences team under him and also deliver great business impact by solving these complex problems. This role would give successful candidates an opportunity to own and build out end to end data science products - from translating business problems to their mathematical equivalent, selecting the relevant feature sets, building required ML models and taking them to implementation.

Requirements:

Have solved large scale Business problems using data and have experience of owning end to end data science projects.

Should be able to work with minimal instruction and oversight, conduct multiple tasks and projects simultaneously, maintain relationships with senior leaders, and own deliverables end to end.Overall experience: 4-8 years."
83,https://www.glassdoor.co.in/partner/jobListing.htm?pos=823&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_134a0a4e&cb=1562003698149&jobListingId=3200278025,Senior Data Scientist,Treebo, – Bengaluru,"We are looking for our first data scientist, who would help us build out the Data Sciences team under him and also deliver great business impact by solving these complex problems. This role would give successful candidates an opportunity to own and build out end to end data science products - from translating business problems to their mathematical equivalent, selecting the relevant feature sets, building required ML models and taking them to implementation.

Requirements:

Have solved large scale Business problems using data and have experience of owning end to end data science projects.

Should be able to work with minimal instruction and oversight, conduct multiple tasks and projects simultaneously, maintain relationships with senior leaders, and own deliverables end to end.Overall experience: 4-8 years."
84,https://www.glassdoor.co.in/partner/jobListing.htm?pos=404&ao=437149&s=58&guid=0000016baeac7587be95eddabde7cc60&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_4a2299f8&cb=1562003666769&jobListingId=3206938085,Data Scientist,ITC Infotech India Ltd, – Bengaluru,"Requirements:

Must be able to clearly understand and articulate a data science problem and work on it independently.

Experience in implementing and optimizing various algorithms of big data analytics, machine learning and statistical algorithms using computer languages such as SQL, R, Python, Machine Learning Studio, SAS, SPSS, Spark, Hadoop, F#, C/C++, C#, VB, Java, JavaScript or HTML.

Extensive background in data mining and statistical analysis.

Able to understand various data structures and common methods in data transformation.

Excellent pattern recognition and predictive modeling skills."
85,https://www.glassdoor.co.in/partner/jobListing.htm?pos=911&ao=437149&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_da50cb7c&cb=1562003705654&jobListingId=3201402543,Lead Data Scientist,Sigmoid, – Bengaluru,"Responsibilities:

Hypothesis testing, insights generation, root casue analysis, factor analysis.

Statistical model (predictive & prescriptive) development using various statistical & machine learning techniques/algorithms.

Test/train the model, Improve Model accuracy, Monitor model performance.

Data Extraction from EDW/Big Data Platform, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA.

Requirements:

Experience: 4 - 6 years

Strong learning acumen.

Team Player.

High sense of ownership.

Ability to work in a fast-paced and deadline driven environment.

Loves technology.

Highly skilled at Data Interpretation.

Problem solver.

2+ years of experience with data analysis/Modelling.

BE/BTech from a Tier 1 college (IIT/ISI/NIT/BITS/BIT/IIIT).

Good exposure of machine learning concepts and algorithms.

Must be fluent with any one of Python, R, Java.

Strong in statistical & machine learning concepts.

Knowledge of Python Libraries - Scipy, Numpy, Pandas, IPython, Scikit-learn.

Strong Python skills for data wrangling / analysis / visualization / modeling.

Experience with distributed big data processing (PySpark, Jupyter, Linux, AWS).

Deployed at least one industrial project using supervised / unsupervised machine learning."
86,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2608&ao=437149&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1a851889&cb=1562003857968&jobListingId=3201145095,Product Owner - Data Sciences,Bosch Group, – Bengaluru,"Job Description

Has experience in working with data sciences that includes AI/ML, Robotics etc. Holds the product vision, represents customer needs, works closely with stakeholders (end users, customers, and the business) and aligns team towards the product vision to ensure fulfillment of business needs. Responsible for breakdown of the product vision into epics and user stories, prioritization and approval of product increments by business value.

A product is any deliverable (e.g. soft-, hardware or services) which creates business value (customer + knowledge value) including platform as a product.

Value contribution:

Ensure effectiveness for business value and economic success through:

Deep understanding and representing of customer needs (intimacy, centricity, empathy)

Fulfilment of business needs (integrating marketability and feasibility)

Continuous alignment of team and organization towards product* vision

Authority:

Single person responsible for the product vision

Full entrepreneurship regarding the product, i.e. take decisions on what product to develop

Approve or reject deliverables/ product increments

Responsibilities:

Part of Innovation team to derive ideas and concepts

Responsible for the economic success of the product

Communication and continued development of the clear product vision and determination of major product characteristics

Breakdown of product vision into understandable epics, user stories and a product roadmap (customer and internal)

Develop and maintain product backlog (decides what’s in and what’s out)

Frequent interaction with customer and other stakeholders to understand their needs to deduct prioritization of increments by business value

Approval of product increments per sprint according to customer expectations

External communication & representation of project

Lead the team in agile way for realization of products in the area of AI/ML, computer vision, Robotics

Exposure and experience in design thinking

Qualifications

B Tech/ M Tech in Electronics &Communication/ Computer Science

6 to 10 years of overall experience

Professional Program Management Certifications like PMP, CSM, PMI-ACP is desirable

At least 3 years of experience in product management/ owner role

Demonstrated ability to work in Agile environment

Demonstrated ability to learn new technologies /skills

Well aware of latest technology and market trends

MBA or equivalent business degree is desirable

Additional Information

Selected person will join the prestigious Innovation and Incubation team of Bosch in the area of Technology Strategy Team. He / She will work on latest upcoming technologies related to the world of data sciences, Help build new businesses thru' assets"
87,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1526&ao=437149&s=58&guid=0000016baeade353b462a8951a2c366c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_252bcb7e&cb=1562003760390&jobListingId=3213973944,E2E Data Science Expert,SuccessFactors, – Bengaluru," SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.  SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives. PURPOSE AND OBJECTIVES Technology & Innovation (T&I) is responsible for SAP’s overall platform and technology development such as SAP Cloud Platform and SAP HANA. In addition, T&I drives the incubation and adoption of intelligent technologies like Analytics, SAP Leonardo Machine Learning and IoT across SAP’s product portfolio. The T&I board area is also in charge of SAP’s global innovation agenda and builds new business model- and market driven innovations to help customers realize the most business value.  SAP Leonardo Machine Learning is part of SAP’s intelligent technologies portfolio and one of the key drivers of the Intelligent Enterprise. It is our mission to infuse all enterprise applications with machine learning and to empower our customers to make the most of their business data. Our team is located in Germany, France, Singapore, India, and the US and exemplifies a start-up like, innovative work environment EXPECTATIONS AND TASKS You will work together with the partner and customer ecosystem focusing on machine learning and data intelligence projects along with a team of dedicated ML experts including data scientist, researchers, business developers, developers and dev-ops engineers with the single goal of building the best machine learning and data intelligence solution for successful realization of customer / partner use case / POCs.  You will belong to the Data Intelligence team and team’s responsibility it is to provide a foundation for services offering machine learning functionality. As a development team responsible for building a new product, Team’s responsibility includes ensuring the following: Create an environment of effective Partner Ecosystem Enablement for various activities such as Implementation, reselling, integration, OEM channels and enabling technology partners.Ensure partner success by working on active customer/partner Projects, Content creation for education, training etc. on the machine learning/AI topics.Work in a diverse team applying Scrum and agile development.Collaborate with remote location teams and partner with customer and partner executives. You will be part of Partner Ecosystem Enablement team taking care of end-to-end responsibilities of executing on the partner/customer projects as a Data Scientist ranging from POCs to implementation handholding in the Machine Learning or Artificial Intelligence areas. Your responsibilities include end to end responsibilities on the following: Developing ML models in order to solve specific business scenarios / situations.Working with Machine / Deep Learning software packages such as TensorFlow/MXNet/SparkML.Working with machine learning languages such as Python, Java, R etc.Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy to solve a business situation.Working with variety of data sources with specific focus on volume and variety of data.Analyze data for trends and patterns and Interpret data with a clear objective in mind.Ability to visualize data and present core insights in a clear and compelling way.Working with integration with Data orchestration tools and corresponding stakeholders.Training, re-training, configuration and deployment as a process of constant improvement.Working on various tools and open sources helping the development of models.EDUCATION AND QUALIFICATIONS / SKILLS AND COMPETENCIES You are a self-starter, goal-oriented, striving for perfection engineer. As an ideal candidate you will demonstrate a proven track record in development of large-scale machine learning pipelines and combine it with curiosity for exploring of new use case and applications of machine learning to domains spanning processing of video, structured, and other unstructured data. Ideally you bring breadth across all verticals (image, text, structured / time series data) with a depth in one of them. Your main focus will be on the Data Science aspects related to customer’s business scenario and delivering better than before models improving the accuracy to realize the customer use cases / business scenarios/POCs.  Required Master degree in Computer Science, Mathematics, Statistics, Operations Research or related fieldTrack record of developing novel learning algorithms and/or systemsProficiency in handling of multi-terabyte datasets in distributed Linux/Unix environments.Solid knowledge on any of the machine leaning languages such as Python, Java, R etc.Knowledge on Data Orchestration, persistence, streamlining and its associated tools.Experience with Machine / Deep Learning software packages such as TensorFlow/MXNet/SparkML.Solid understanding of the variety of data models with focus on business data / industrial data.Good knowledge on Statistics, Linear Algebra, data wrangling and Data Visualization.Understanding of Big data concepts and tools.Excellent English language skills Preferred Publication track record on deep learning / machine learning.PhD degree in Computer Science, Mathematics, Statistics, Operations Research or related field.Understanding on project delivery management is desired.Knowledge on Kubernetes, dockers would be necessary.WORK EXPERIENCE Preferably 6+ years of experience including working on real implementations. WHAT YOU GET FROM US Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now. SAP'S DIVERSITY COMMITMENT To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.  SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com).  Successful candidates might be required to undergo a background verification with an external vendor. Additional Locations:"
88,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1928&ao=437149&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c1d4e239&cb=1562003805572&jobListingId=3200326790,Big Data Engineer,Unbxd, – Bengaluru,"Responsibilities:

In this role, you will play as the chief catalyst who can get on the ground floor and design, implement systems from scratch and that they work quickly (in real time), accurately, and at scale.

Design and implement distributed applications collecting event data while creating, analysing & reporting on different behaviour patterns for multiple e-commerce companies.

Research and prototype ideas for analytics and machine learning-based product features.

You will be developing practical, robust & high-performance distributed systems and play an innovator role in creating the next generation shopping experience.

Requirements:

Experience of 5 Years in distributed systems design and development using LISP/Scala/Java/C++.

Proficiency in Map-Reduce concepts and experience with Kafka /Spark or relative technologies.

Working experience in data modelling in non-relational databases, such as Cassandra, Storm, HBase, MongoDB, etc.

Working experience of building applications on GNU/Linux.

Master's degree in Computer Science or equivalent."
89,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2516&ao=132976&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_670d16f6&cb=1562003849872&jobListingId=3242192515,Finance Engineering - Finance Platforms & Data - Finance Data Engineer - Team Lead,Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBIn Finance Engineering, you’ll find an exciting confluence of computer science, finance and mathematics being used to solve for what our shareholders would like from us – a high return for the right risk taken.Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• The team lead role requires strong project management, technical design, and coding skills to help teams deliver solutions to multiple stakeholders.• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance• Build strong relationships with business partners• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenanceSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team• Excellent communication skills including experience speaking to technical and business audiences and working globally• Expertise in Java development & Relational Databases• Can apply an entrepreneurial approach and passion to problem solving and product development• Strong problem solving and analytical skillsPreferred Qualifications• Strong programming experience in at least one compiled language (e.g. C, C++, Java)• In-depth knowledge of relational and columnar SQL databases, including database design• Experience with continuous delivery and deployment• Proficient at working with large and complex code bases• Comfortable working in highly dynamic and rapid development environment (Agile development experience)• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON• Technologies: o Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, TableauABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
90,https://www.glassdoor.co.in/partner/jobListing.htm?pos=124&ao=452401&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_15b598c0&cb=1562003586338&jobListingId=3279226617,Data Scientist,Akamai, – Bengaluru,"About the Job

If you have a deep passion for data and security, love handling massive data sets, and get excited from solving hard problems, Akamai is the place for you. We are seeking a highly motivated Threat Operations Analyst who will work with Engineering and Product Management teams to quickly resolve highly technical, complex issues, and advocate for real-world customer use cases, features, and functionality. You will apply your practical analytical skills and your experience with statistical analysis to derive actionable insights from large volumes of data.

Join a fast-paced team in Akamai’s Security Unit charged with protecting the largest brands against the unpredictable landscape of evolving botnets and malware. Bad actors might build massive botnets or new automated attack systems; you’ll help dismantle and cripple them in real, internet time.

About the Team

The web security team is focused on leveraging Akamai's core strengths of its highly distributed cloud-based platform that already serves up to 30% of the traffic on the web and the massive amount of HTTP data it has access to as a result to define industry leading web security products that provide rapid visibility and control for protection against constantly changing attack profiles.

Responsibilities



● Investigate the most sophisticated bots from across the Akamai’s customer base

● Tuning detection algorithms for best fit for a particular customer traffic pattern.

● On-going monitoring and measurement of the effectiveness of bot detection algorithms

● Build tools for automated analysis

● Keep abreast of current malware, botnets, or other automated agent trends and provide insights for further product enhancements
Required Education and Experience:

*BS or MS in Computer Science, Applied Math, Statistics, Data Science or relevant subject.

*Overall of 6+ years of expereince.

*3 years experience in Data analysis

*3 years experience in Python programming

*3 years experience in SQL.

*3 years experience working on Unix platform

*2 years experience with various open source data analytic packages such as Pandas, numPy, Matplotlib, etc

Desired Qualifications:

*Experience presenting complex technical information, succinctly, to technical and business audiences.

*Data visualization skills to translate complex models and analysis results into layman terms

*Experience, familiarity and ease with handling large, messy data sets. Prior experience with AWS Athena is a plus, but not required.

*Experience in Javascript debugging.

*Understanding of Proxies, DNS, HTTP protocol, Browser Rendering engines.

*Familiarity with AWS and Big Data Technologies like EMR or Spark is a plus, but not required.

*Bot detection experience is a plus

*Interest in Machine Learning, specifically anomaly detection and data mining

*Interest in Web Application security






"
91,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2116&ao=437149&s=58&guid=0000016baeaed05a9c74761e75f813aa&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5056207a&cb=1562003821205&jobListingId=3201236160,Data Engineer,AI Enterprise, – Bengaluru,"i)Should be a strong individual contributor in a complex data warehousing project.

ii)Should highlight and resolves issues in the current data models and design

iii)Very good understanding of relational databases with ability to write/ modify complex SQL queries to generate required datasets and tune query performance.

iv)Advanced ETL writing and performance tuning experience in Scala & Python. Knowledge of data integration tools like Pentaho, etc.

v)Experience with using big data technologies like Spark, Map-Reduce, Hive, Kafka

vi)Experience with using NoSQL databases such as MongoDB, Cassandra, Hbase, etc.

vii)Experience with using GCP / AWS cloud services

viii)Experience with using stream processing systems like Storm, Spark-streaming, etc.

ix)Experience with using OOPs languages like Java, Scala, Python, etc.

x)Knowledge of Pig, Shell Scripting and familiarity with Unix/Linux OS a strong plus.

xi) Strong analytical and problem solving skills. Should provide solutions to complex problems without known solutions.

xii)Excellent communication skills and capability to effectively work with both Business and Technology teams.

xiii)Qualification - BE / BTECH in MIS, CS or related field. 1+ years of technology experience as a Data Engineer"
92,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2225&ao=455101&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f099208c&cb=1562003826212&jobListingId=3249730889,Software Development Engineer III - Data Platform,Groupon, – Bengaluru,"Take care of petabytes of data to help local businesses grow

Groupon’s mission is to become the daily habit in local commerce and fulfill our purpose of building strong communities through fast-growing small businesses by connecting people to a dynamic, global marketplace for local services, experiences and goods. In the process, we’re positively impacting the lives of millions of customers and merchants globally. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. If you want to take more ownership of your career, then you're ready to be part of Groupon.

As a global company that works with both local businesses and consumers, Groupon has a wealth of data, which is stored and processed on our ever-evolving data platform. As a Data Engineer, you will handle the full development life-cycle of Groupon data applications. Our Data Engineers collaborate with data scientists, product managers and other engineering teams to design and build streaming and batch data applications for the business to enable consistently informed management decisions and also provide customers and merchants with personalized experience. You will work closely with data scientists to develop models using Machine Learning and data mining techniques.

We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a significant impact. We're curious, fun, a little intense, and kind of passionate about helping local businesses thrive. Does that sound like a compelling place to work?You’ll spend time on the following:

Work with data scientists, analytics experts and product managers to strive for greater functionality in our data systems.
Analyze & translate functional specifications & change requests into technical designs.
Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.
Develop scalable, maintainable and reusable code with unit tests and integration testing
Ensure accuracy & integrity of data & applications through analysis, coding, writing clear documentation and problem resolution.
Troubleshoot and remediate issues impacting data pipelines.
Keep tabs on the tools, techniques and components being used in the industry through research and apply this knowledge to the system(s) being developed.
Mentoring junior engineers


Requirements

Hands-on experience with all aspects of designing, developing, testing and implementing streaming, near real time and batch data pipelines
Expertise in functional and object oriented programming paradigms.
Hands on experience on Scala, Java
Experience working with distributed computing frameworks, preferably Spark
Working knowledge of message queuing, stream processing using Kafka/ Kinesis, and highly scalable big data stores
Good coding skills in at least one modern scripting language, preferably Python
Experience working on MPP systems
Experience and working knowledge of Lambda and Kappa architecture in AWS cloud environment
Solid understanding of SDLC, software standard methodologies and development methodologies
Excellent verbal and written communication, analytical, and problem solving skills.
Experience working with big data tools such as - Kafka, Hadoop, hive, Hbase etc. a big plus.
Experience with data warehousing and star-schema (dimensional) data models and strong hands-on SQL knowledge a big plus
Experience working with relational databases a plus.

#IND"
93,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2527&ao=437149&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_6d13d9b6&cb=1562003849887&jobListingId=3261969616,Software Development Engineer III - Data Platform,Groupon, – Bengaluru,"Take care of petabytes of data to help local businesses grow

Groupon’s mission is to become the daily habit in local commerce and fulfill our purpose of building strong communities through fast-growing small businesses by connecting people to a dynamic, global marketplace for local services, experiences and goods. In the process, we’re positively impacting the lives of millions of customers and merchants globally. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. If you want to take more ownership of your career, then you're ready to be part of Groupon.

As a global company that works with both local businesses and consumers, Groupon has a wealth of data, which is stored and processed on our ever-evolving data platform. As a Data Engineer, you will handle the full development life-cycle of Groupon data applications. Our Data Engineers collaborate with data scientists, product managers and other engineering teams to design and build streaming and batch data applications for the business to enable consistently informed management decisions and also provide customers and merchants with personalized experience. You will work closely with data scientists to develop models using Machine Learning and data mining techniques.

We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a significant impact. We're curious, fun, a little intense, and kind of passionate about helping local businesses thrive. Does that sound like a compelling place to work?You’ll spend time on the following:

Work with data scientists, analytics experts and product managers to strive for greater functionality in our data systems.
Analyze & translate functional specifications & change requests into technical designs.
Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.
Develop scalable, maintainable and reusable code with unit tests and integration testing
Ensure accuracy & integrity of data & applications through analysis, coding, writing clear documentation and problem resolution.
Troubleshoot and remediate issues impacting data pipelines.
Keep tabs on the tools, techniques and components being used in the industry through research and apply this knowledge to the system(s) being developed.
Mentoring junior engineers


Requirements

Hands-on experience with all aspects of designing, developing, testing and implementing streaming, near real time and batch data pipelines
Expertise in functional and object oriented programming paradigms.
Hands on experience on Scala, Java
Experience working with distributed computing frameworks, preferably Spark
Working knowledge of message queuing, stream processing using Kafka/ Kinesis, and highly scalable big data stores
Good coding skills in at least one modern scripting language, preferably Python
Experience working on MPP systems
Experience and working knowledge of Lambda and Kappa architecture in AWS cloud environment
Solid understanding of SDLC, software standard methodologies and development methodologies
Excellent verbal and written communication, analytical, and problem solving skills.
Experience working with big data tools such as - Kafka, Hadoop, hive, Hbase etc. a big plus.
Experience with data warehousing and star-schema (dimensional) data models and strong hands-on SQL knowledge a big plus
Experience working with relational databases a plus.

#IND"
94,https://www.glassdoor.co.in/partner/jobListing.htm?pos=721&ao=133266&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f07270fa&cb=1562003690298&jobListingId=2771441669,Data Scientist,Citi, – Bengaluru,"
Primary Location: India,Karnataka,BangaloreEducation: Master's DegreeJob Function: Decision ManagementSchedule: Full-timeShift: Day JobEmployee Status: RegularTravel Time: NoJob ID: 18030804


DescriptionAbout us:

Global Decision Management (GDM) has a rich history of accelerating data-driven decision-making for Citi® businesses across geographies and functions. We are a rapidly growing organization focused on pioneering the adoption of state-of-the-art analytical techniques with the objective of transforming business practices for Citi globally.

Citi® and the overall banking & financial services industry is on the cusp of a revolution in terms of how we interact with our customers and meet their expectations. And GDM strives to be at the forefront of this wave, by harnessing the power of cutting-edge algorithms to solve various challenging problems for our business stakeholders:

Automating Customer Servicing:

Chatbots, Speech- and gesture-based authentication and transactions

AI based Advisory and Recommendation Systems:

Personalized Investment, News Articles, Offers (Web-scraping, NLP/NLU)

Real Time fraud detection and mitigation:

(Probabilistic Graph modeling, Rare-event modeling, Bayesian techniques 

Intelligent Operations - Automatic Form Readers (OCR), Interactive FAQ systems, Complaints identification and resolution (Topic & Sentiment Mining)
Customer Experience:

Improving customer experience on Mobile and Digital banking (Real-time propensity scoring & offer placement)

Pattern Mining:

Advanced ML algorithms to predict customer journeys and actions using sequential and geospatial data

What do we offer:

The key requirement for the role is the ability to work directly or handle teams which work on large scale data, tools/techniques to build strong capabilities in Advanced Analytics, Big Data, Machine Learning, Deep Learning, Digital & FinTech to solve key business challenges, propose solutions and build products.

Expertise Required:

Expertise with Big Data technologies (Hive/Impala, Spark/Scala, H2O) and databases (Oracle, Dbase, MongoDB) 

Experience with Programming languages R, Java, Python 

Highly proficient with Deep Learning and Machine Learning Algorithms, Pattern Mining / Detection 

Very good written and verbal communication ability in an educational style. Ability to express thoughts and concepts clearly 

Ability to work well with a variety of people and to show team-player attitude regardless the scope of responsibilities 

Provide input into the innovation of new and enhanced approaches. Having initiative and a proactive attitude is desirable

QualificationsEducational and Experience:

(Preferred) Post Graduate in Computer Science, Mathematics, Operations Research, Statistics, Econometrics, Management Science and related fields 

Could be any graduate degree holder with relevant experience 

Strong academic record and publications in reputed journals or conferences 

5 to 12 years of experience in the field of advanced quantitative techniques, data sciences and large scale machine learning while working for leading global academic institutes or corporate innovation research labs or analytics organizations of large corporates or in consulting companies in analytics roles


"
95,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1106&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b8672b3d&cb=1562003722964&jobListingId=3225949565,Senior Data Scientist - Product Development (GAIA India),Ericsson, – Bengaluru,"Date: May 7, 2019

Ericsson Overview:

Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Senior Data Scientists to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericsson’s global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Senior Data Scientist, you will need to have strong programming skills and deep understanding of data science and Machine Learning tools. Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:

Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities

Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems

Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.

Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents

Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.

Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units

Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives

Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs

Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.

Key Qualifications:

Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.

Applied experience: 5+ years of ML and/or AI production level experience

Proven skills of implementing a variety of Machine Learning techniques

Strong skills in the use of current machine learning frameworks such as H2O, Keras, TensorFlow, Spark ML etc.

Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability

Experience with Big Data technologies such as Hadoop, Cassandra etc.

Strong grounding in math and statistics.

Proven ability of leading projects end-to-end.

Proven experience writing production-grade software

Extensive experience in model development and life-cycle-management in one or more industry/application domain

Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++

Good communication skills in written and spoken English

Creativity and ability to formulate problems and solve them independently

Ability to build and nurture internal and external communities

Experience in writing and presenting white papers, journal articles and technical blogs on the results

Additional Requirements:

Certifying MI MOOCS, a plus

Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.

Experience with data visualization and dashboard creation is a plus

Ability to work independently with high energy, enthusiasm and persistence

Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

Location: Bangalore (or) Chennai

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics.

Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.

Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.

Primary country and city: India (IN) || || Bangalore || R&D

Req ID: 277723"
96,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1209&ao=148364&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_017ca9a5&cb=1562003730765&jobListingId=3239326540,Senior Data Scientist,UiPath, – Bengaluru,"Accelerate Human Achievement: that is UiPath's purpose. We are the leader in Robotic Process Automation (RPA) and the highest-valued AI enterprise software company in the world. With over $568 million in funding from top venture capital firms like Accel, CapitalG, Kleiner Perkins, Sequoia, IVP, Madrona Venture Group, Meritech Capital & Coatue, we are on an unprecedented trajectory of growth. With this funding, we have an incredible opportunity to improve the way people work globally. Our award-winning company culture values humility, and leaders who know how to listen. CEO Daniel Dines primary goal was to build a company where he would love to work, and even now, with thousands of employees in tens of countries, that remains our top priority. We trust and empower our colleagues, and together we make sure we have everything we need to do our best work, from the support of strong leaders to awesome perks and benefits.Here's what you would be doing at UiPath:Execution of Partner/Channel Program strategies to ensure over-achievement of our business objectivesWork with Partner/Channel Account Executives/Managers to define and execute the territory channel recruitment and enablement strategy Drive coordination of technical resources both internally and externally as needed to close prospective opportunitiesAssist in increasing Partner/Channel and end-user adoption of UiPaths products through events and training, seminars, webinars, technical training's, and other activities as appropriate.Create development plans for all partner-based technical resources within territory to enable partner autonomyUp to 50% travel may be requiredActively participate in Partner/Channel QBR and Partner Plan reviews with Territory teamDevelop and maintain strong contacts and relationships with corporate resources that can assist in driving partner autonomyDevelop synergies between the partner organization and corporate resources that can support the over-achievement of partner business objectives and initiativesAnalyze partners business objectives by asking probing questions that are relevant to partner and prospects markets and industries.Attend partner meetings to assess partner capabilities and their customers satisfaction.Track and document partner technical capabilities for inclusion in planning and managementIdentify gaps in partner tactics as they relate to customer requirements to ensure customer satisfaction and provide tools and solutions to address the gaps.Reporting on pre-determined intervalPresent and market the design and value of proposed solutions to partners and their prospectsDelivering Pre-sales support, and ensure partners can deliver custom made industry/function specific demos for new prospects and clients;Enabling and ensuring that partner organization can create powerful POCs (Proof Of Concepts) for prospects and customers, and providing specific POC assistance where needed by partnersEnsuring partners are able to identify customer needs and showcase the best of UiPaths solutionOrganize Knowledge Sharing sessions with partners to support sharing of best practicesEnabling partners to learn the benefits of new exciting technologies and how to integrate with UiPathWork with Partners and gather project requirement for integration with different partner productsWork with Partners to develop workflows and projects for specific use cases by integrating with different application and products;Maintain knowledge of competitive products to enable the capability to effectively address and dispel partner objections to UiPaths solutionsWork with the UiPath Partner/Channel Sales Team(s) and partners to formulate and implement both tactical and strategic sales initiatives within their assigned territoryIdentify and present training that accelerates the development of Partner technical resourcesConduct on-going meetings with corporate resources to keep current on UiPaths direction and productsDemonstrate ability to relate Partner business challenges to UiPath solutionsDeliver UiPaths value proposition in a persuasive and accurate mannerPerform other duties as required.What you will bring:Ability to gain the confidence of both Senior Management and Technical Staff of PartnersBuild and maintain Partner relationships to be significantly leveraged into driving additional Sophos businessGraduates in Computer Science with minimum 3 years experience in programming .NET (C# or VB), Java + node based programming perfect match);Previous experience in application or implementation domain is a must;Previous experience in working on different types of servers (IIS, Apache, Linux, different types of cloud environment, SAP servers, database servers) is a plus;Previous experience in industry specific tools and applications is a plus;Skills required: process minded, good presentation and communication skills;Prior Channel/partner experienceAbility to travel 30-50% of the time as neededWhy to work with us?We are offering the possibility to work from home or flexible working hours, a competitive salary package, a Stock Options/Rsus Plan and the unique opportunity of working with us to develop state-of-the-art robotics technology are just a few of the pluses.We must have caught your attention if you've read so far, so we should talk.** At UiPath, we value a range of diverse backgrounds experiences and ideas. We pride ourselves on our diversity and inclusive workplace that provides equal opportunities to all persons regardless of race, color, religion, sex, sexual orientation, gender identity and expression, national origin, disability, military and/or veteran status, or any other protected classes.At UiPath, we value a range of diverse backgrounds experiences and ideas. We pride ourselves on our diversity and inclusive workplace that provides equal opportunities to all persons regardless of race, color, religion, sex, sexual orientation, gender identity and expression, national origin, disability, military and/or veteran status, or any other protected classes."
97,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1215&ao=116277&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9a13bc4b&cb=1562003730775&jobListingId=1286365856,Sr. Data Scientist (5+ Years) for a leading behavioural ad Solution provider,Zyoin, – Bengaluru,"We are looking for a Sr. Data Scientist for one of our esteemed Clients for Bangalore Location.

RESPONSIBILITIES:

Conduct data science research on cognitive computation, deep learning and natural language question answering to deliver richer product experience.
Drive algorithm, technology and product innovation to create new features and functionalities that delivers better data democracy.
Mentor A+ research team.
Coordinate and collaborate with cross-functional teams including product management, customer support & operations, sales, marketing and management.
Be a thought leader and technology evangelist and collaborate with marketing to promote technology leadership in creative ways in online and offline channels.
Develop product and technology showcases.

REQUIREMENT:

Advanced degree (MS or PhD) in Computer Science, Statistics, Applied Mathematics, Machine Learning. PhD would be a plus, though not mandatory.
5+ years of total experience, out of which 3+ years of relevant industrial experience in applying data mining techniques.
Broad knowledge of existing data mining algorithms and technologies.
Experience working with large data sets and developing scalable algorithms.
Demonstrated ability in developing and deploying data-driven product.
Deep understanding and hands-on experience of machine learning and data mining algorithms such as decision trees, classifiers, clustering, and regression.
Experience with big data techniques Pig/Hive/Mahout is a plus.
Experience with statistical environment R/Matlab is a plus.
Proficient in scripting languages Python/Java.
Excellent presentation and communication skills.
Strong analytical and problem solving skills.
Prior experience in online advertising a plus.
Demonstrated experience in leading programs and team.
Ability to work independently and deal with ambiguity.
"
98,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2827&ao=37049&s=58&guid=0000016baeafa65a98836b4f5999adf7&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_835f6020&cb=1562003875886&jobListingId=2781184476,Specialized Analytics Manager- SBS,Citibank, – Bengaluru,"Primary Location: India,Karnataka,BangaloreEducation: Master's DegreeJob Function: Decision ManagementSchedule: Full-timeShift: Day JobEmployee Status: RegularTravel Time: Yes, 10 % of the TimeJob ID: 18032985 DescriptionAbout us:Global Decision Management is a global community that is driving data driven transformation across Citi in multiple functions with the objective to create actionable intelligence for our business leaders. We are a fast growing organization working with Citi businesses and functions across the world.What do we offer:As GDM we support analytical functions across all geographies and businesses. Few notables among the multiple areas that we work in:Customer lifecycle management: Design and implement strategies to improve customer experience and drive revenue, spanning across all 3 stages of customer lifecycle acquisition, ECM and RetentionOffer optimization: Design, test and implement innovative and customer-centric offers tailored to drive customer delight and grow engagementProduct & Pricing: Deep-dive into product features, analyze product effectiveness and price products intelligently to create innovative products at attractive prices thatll keep Citi ahead of its competitionDigital: Trace customers digital journey with Citi, design strategies to make digital experience more engaging and drive revenue through low cost digital channelsRevenue/Financial forecasting: Design, maintain and enhance P&L forecasting for all products & portfolios, ensure strict adherence to accounting standards and accurate forecasting techniques to help product managers plan betterIn order to achieve the best in class analytical solutions across business units we use the best in class tools and technology.Expertise Required:Programming SAS, Unix, SQL, R, PythonDatabases: Teradata Good understanding of the Banking and Lending business along with strong understanding of customer life cycleKnow-how of Modelling techniques traditional and Machine Learning Algorithms is a good to have  Learn and follow industry best practices Ability to work well with a variety of people and to show team-player attitude regardless the scope of responsibilitiesAbility to identify, clearly articulate and solve complex business problems and present them to the management in a structured and simpler formIndependently work on projects end-to-end, manage stakeholder expectations and timelinesContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.Questioning the status quo QualificationsEducational and Experience:MBA / Master degree in Economics / Statistics / Mathematics / Information Technology / Computer Applications / Engineering from a premier institute. BTech / B.E in Information Technology / Information Systems / Computer Applications (Preferred) Post Graduate in Computer Science, Mathematics, Operations Research, Statistics, Econometrics, Management Science and related fields2 to 8 years of hands on experience in delivering Analytical solutions, Banking Industry Exposure would be good to haveExcellent Communication and Inter-personal skillsStrong process/project management skills"
99,https://www.glassdoor.co.in/partner/jobListing.htm?pos=306&ao=437149&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e1123ba6&cb=1562003656969&jobListingId=3201182971,Data Scientist,Bidgely, – Bengaluru," Bidgely is looking for extraordinary and dynamic Data Scientists to be part of its core team in Bangalore. You must have delivered advanced statistical and machine learning models as part of commercial products and created substantial intellectual property with business impact. You must enjoy working with large data and finding interesting patterns in the data through analytics experiments in a methodical and data driven scientific way. Be part of a highly energetic and innovative team that believes nothing is impossible with some creativity and hard work. Responsibilities Research and develop advanced statistical and machine learning models for analysis of large-scale, high-dimensional data.  Dig deeper into data, understand characteristics of data, evaluate alternate models and validate hypothesis through theoretical and empirical approaches.  Productize proven or working models into production quality code.  Collaborate with product management, marketing and engineering teams in Business Units to elicit & understand their requirements & challenges and develop potential solutions  Stay current with latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.  File patents for innovative solutions that add to company's IP portfolio Requirements 2 to 5 years of strong experience in data mining, machine learning and statistical analysis.  BS/MS/PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)  Experience in productizing models to code in fast paced start-up environment.  Fluency in analytical tools such as Matlab, R, Weka etc.  Strong intuition for data and Keen aptitude on large scale data analysis  Strong communication and collaboration skills."
100,https://www.glassdoor.co.in/partner/jobListing.htm?pos=418&ao=437149&s=58&guid=0000016baeac7587be95eddabde7cc60&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_017b2e99&cb=1562003666782&jobListingId=3206943919,"Data Scientist, Lead",Epsilon, – Bengaluru," Description  As a Data Scientist in our Analytic Technology Practice, you will be responsible for researching and building data automation and machine learning processes to expand Epsilon’s analytic capabilities. You will work on real-world marketing problems as part of our highly collaborative Analytic Consulting Group to develop solutions that will directly impact our business. RESPONSIBILITIESDevelop an understanding of Epsilon’s current analytic capabilities and proprietary datasetsUse your machine learning expertise to research and recommend the best analytic approaches to solving the most difficult marketing problems facing our clientsIdentify new analytic capabilities and compare/contrast with existing methodsDesign, implement, and validate your analytic pipelines in Apache Spark, Apache HDFS, Apache Kafka, AWS S3, using Python / R on a state-of-the-art clusterDevelop analytic requirements and collaborate with Engineering teams to integrate analytic solutions into Epsilon’s product platformsQualificationsREQUIREMENTSA Ph.D., (or Master’s degree plus at least 3 years’ relevant experience), in Computer Science, Statistics, Electrical Engineering, Mathematics, Economics, Physics, or a related scientific disciplineResearch experience and coursework in Machine LearningMastery of the following programming languages: Python, R, SQLExperience manipulating large data sets, both structured & unstructuredExperience with distributed computing, such as Hadoop, Spark, or related technologiesStrong understanding of statistics and modeling techniquesNatural curiosity for exploring data and finding the untold storyDesire to work in a highly collaborative environmentAbility to simplify complexity, communicate clearly and teach othersManage multiple data science projects concurrentlyADDITIONAL USEFUL BUT NOT REQUIRED SKILLSFamiliarity with SAS, Scala or Java programming languagesExperience in marketing analytics, especially digital analyticsFamiliarity with Scrum development methodologyExperience with data visualization"
101,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2509&ao=132930&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_30972ce1&cb=1562003849864&jobListingId=3160785887,Architecture Research Scientist,Intel, – Bengaluru,"Job DescriptionArchitecture and Design Research (ADR)-India is a world-class research lab that excels at novel product development through fundamental architecture research. We are looking for highly qualified, dynamic researchers in a) Microprocessor architecture for breakthrough general purpose performance, b) Accelerator-based architectures for Artificial Intelligence with focus on Machine Learning and Computer Vision use cases, c) research into cache and memory hierarchies for highly heterogeneous architectures that employ futuristic memory technologies. Research Scientists will advance the state-of-the-art in deep collaboration with product architecture/design teams while also contributing to scientific literature/conferences and developing Intellectual Property. QualificationsAdvanced degrees in EE/CS are required, PhD is preferred. Solid background in architecture and microarchitecture is necessary. Expertise in algorithms, hardware and software for Machine Learning will be very useful. VLSI design and ASIC flow expertise can be quite valuable to the role. Inside this Business GroupIntel Labs is the company's world-class, industry leading research organization, responsible for driving Intel's technology pipeline and creating new opportunities. The mission of Intel Labs is to deliver breakthrough technologies to fuel Intel's growth. This includes identifying and exploring compelling new technologies and high risk opportunities ahead of business unit investment and demonstrating first-to-market technologies and innovative new usages for computing technology. Intel Labs engages the leading thinkers in academia and industry in addition to partnering closely with Intel business units. Legal Disclaimer: Intel prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.  It has come to our notice that some people have received fake job interview letters ostensibly issued by Intel, inviting them to attend interviews in Intel’s offices for various positions and further requiring them to deposit money to be eligible for the interviews. We wish to bring to your notice that these letters are not issued by Intel or any of its authorized representatives. Hiring at Intel is based purely on merit and Intel does not ask or require candidates to deposit any money. We would urge people interested in working for Intel, to apply directly at www.jobs.intel.comand not fall prey to unscrupulous elements."
102,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2223&ao=437149&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f56df968&cb=1562003826210&jobListingId=3250533018,Technical Product Manager (Data Science),HealthPlix, – Bengaluru,"The Technical Product Manager joining our team will play a central role in driving our product vision. Further, the candidate will get a ringside view of building a world class Saas product for healthcare space.

Requirements:

Bachelors degree in CS/IS only and an MBA from tier-1 Indian B-school.

3-6 years of work experience building successful SaaS products.

Knowledge of math, probability, statistics and algorithms or inclination to learn.

Proven experience as a Machine Learning expert or similar role.

Experience with Pharma or Healthcare space is a big plus but not mandatory.

Ability to experiment with data in Python, Java and R.

We look for individuals with excellent clarity in thinking, superb communication skills and a natural willingness to travel and meet customers across India to understand first hand their stated and unstated needs from our product.

Deep understanding of customer experience & requirements - Good client skills.

Ability to identify current gaps in the product, prioritize them and work cross-functionally with UX, Engineering, Marketing and Sales teams to get them implemented and released to the market.

Own the vision for the product, and devise a roadmap to get there.

Ability to think creatively and independently on product design for a brand new market.

Track record of creating AI analytics products while also investigating data and algorithms hands on.

Ability to translate the roadmap into actionable requirements and specifications.

Assess the competition, and devise strategies to continue to lead the market.

Evangelise and create awareness among the users about the product.

Define key metrics for the product with a passion for assessing progress quantitatively."
103,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1317&ao=433326&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b6f48da3&cb=1562003740658&jobListingId=3252670976,Data Engineer,QuEST Global, – Bengaluru,"Title Data Engineer  23-May-2019 Job DescriptionQuEST Global is a diversified global engineering services company with elite Fortune 500 OEM customers in the hi-tech sectors of Aero Engines, Aerospace & Defense, Transportation, Oil & Gas, Power & Smart Grid, Healthcare and Communication. QuEST Global has around 10000 professional’s turbo charging our 40+ global delivery centers spread across in continents like - APAC, North America and Europe.  The Transportation domain at QuEST Global takes pride of its unique delivery model that helps customers in reducing development costs, shortening lead times, extending capacity and maximizing engineering resource availability. The group focuses in creating an ecosystem of solutions uniting ports, rail and transportation system yards, terminals and all their connection points to enable the most optimized, cost-efficient and environmentally sustainable transportation network. There is a strong emphasis on bringing modern technologies or innovative ways to use technologies to solve the immediate challenges in these markets. Since the globalization process has raised a series of challenges for companies around the world, our management practices are firmly anchored on the cultural pillars that include accountability and ownership, continuous development, customer focus, being intrapreneurial, openness and transparency, passion for engineering, team work and speed.  The Transportation team works to strengthen the depth and breadth of engineering service offerings to our customers in terms of engineering software and embedded systems being offered so far. We work to emerge as the most trusted and long-term engineering solutions providers for our customers, we are constantly on the lookout for assets with outstanding engineering capability. Skills/Requirements:Hands-on experience with requirements analysis, design, coding and testing patternsHas experience in engineering (commercial and open source) software platforms, Micro Service Architectures, Data Modeling, large-scale data infrastructures.Hands-on experience building data solutions using Kafka/Spark, Elastic Search, EMR, HDFS/Cassandra/NoSQL/SQL or comparable technologies and Queries.Messaging Systems - RabbitMQ, AWS SNS, SQSExperience working with cloud computing environments, preferably AWS, EC2, S3, BOTO, AWS CLIExceptionally strong in Java-Spring Boot and Python/Scala/Node.js.Good hands-on experience with Talend toolMin. Qualification:B.E/B. Tech/M. C. AYears of Experience – 3-5 YearsWork Location:BangaloreAuto req ID9152BRJob Type Full Time-Regular Assignment Country India Total Years of Exp5Education Type B.E/B.Tech/BS-Computer Science Assignment State Karnataka Assignment Location Bangalore (Bengaluru) Experience Level Mid Level "
104,https://www.glassdoor.co.in/partner/jobListing.htm?pos=3012&ao=437149&s=58&guid=0000016baeafe7388a34bfd62b4e5a9a&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_04d795cb&cb=1562003892499&jobListingId=3201568947,Data Engineer,QuEST Global, – Bengaluru,"Title Data Engineer  23-May-2019 Job DescriptionQuEST Global is a diversified global engineering services company with elite Fortune 500 OEM customers in the hi-tech sectors of Aero Engines, Aerospace & Defense, Transportation, Oil & Gas, Power & Smart Grid, Healthcare and Communication. QuEST Global has around 10000 professional’s turbo charging our 40+ global delivery centers spread across in continents like - APAC, North America and Europe.  The Transportation domain at QuEST Global takes pride of its unique delivery model that helps customers in reducing development costs, shortening lead times, extending capacity and maximizing engineering resource availability. The group focuses in creating an ecosystem of solutions uniting ports, rail and transportation system yards, terminals and all their connection points to enable the most optimized, cost-efficient and environmentally sustainable transportation network. There is a strong emphasis on bringing modern technologies or innovative ways to use technologies to solve the immediate challenges in these markets. Since the globalization process has raised a series of challenges for companies around the world, our management practices are firmly anchored on the cultural pillars that include accountability and ownership, continuous development, customer focus, being intrapreneurial, openness and transparency, passion for engineering, team work and speed.  The Transportation team works to strengthen the depth and breadth of engineering service offerings to our customers in terms of engineering software and embedded systems being offered so far. We work to emerge as the most trusted and long-term engineering solutions providers for our customers, we are constantly on the lookout for assets with outstanding engineering capability. Skills/Requirements:Hands-on experience with requirements analysis, design, coding and testing patternsHas experience in engineering (commercial and open source) software platforms, Micro Service Architectures, Data Modeling, large-scale data infrastructures.Hands-on experience building data solutions using Kafka/Spark, Elastic Search, EMR, HDFS/Cassandra/NoSQL/SQL or comparable technologies and Queries.Messaging Systems - RabbitMQ, AWS SNS, SQSExperience working with cloud computing environments, preferably AWS, EC2, S3, BOTO, AWS CLIExceptionally strong in Java-Spring Boot and Python/Scala/Node.js.Good hands-on experience with Talend toolMin. Qualification:B.E/B. Tech/M. C. AYears of Experience – 3-5 YearsWork Location:BangaloreAuto req ID9152BRJob Type Full Time-Regular Assignment Country India Total Years of Exp5Education Type B.E/B.Tech/BS-Computer Science Assignment State Karnataka Assignment Location Bangalore (Bengaluru) Experience Level Mid Level "
105,https://www.glassdoor.co.in/partner/jobListing.htm?pos=802&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_0efd4b31&cb=1562003698133&jobListingId=3282893247,Senior Data Scientist,DirecTech Labs, – Bengaluru,"DirecTech Labs is hiring a Senior Data Scientist to join its team! This role will play an integral part in the building, growing and nurturing of our new predictive analytics startup. You'll have a chance to drive the implementation and rollout of our data analytics platform to the $186B Direct Selling Industry. You will be a key member on our team of data scientists and will own a portion of our product to deliver our data analytics platform.

We are looking for a mixture between a statistician, machine learning expert and engineer with an interest in predictive analytics and an ability to communicate their ideas and findings in a comprehensive and digestible way to business persons and IT alike: someone who has passion for building data products and services. The ideal candidate understands human behavior and knows what to look for in the data.

If you're a scrappy builder backed by deep data analytics experience and looking to play a pivotal role within a startup, this one is for you.

About You:

You have a MS in Statistics, Machine Learning, or Predictive Analytics from a Tier 1 University

What You'll Get:

An amazing company culture that encourages creativity, personal growth, work/life balance, fun and teamwork.

The chance to work for a “data” company building “data” products.

Working with ""A Players"" across the organization.

A stocked fridge with a bounty of snacks and drinks.

Huge opportunity to build something from the ground up for an industry who is begging for a solution.

Competitive salary, fully paid health benefits and paid vacation in the business you help create!

You have a MS in Statistics, Machine Learning, or Predictive Analytics from a Tier 1 University

You have 5-8+ years creating predictive models using advance machine learning techniques

You have proven work examples of turning significant amounts of data into informative/insightful actions through various statistical techniques that turn into explosive business results

You have an expert command of statistical analysis, algorithm development, and state-of-the-art tools and methodologies for data science

You have an expert command of SQL and Python as applied to data science

You have excellent communication and presentation skills with founders, developers and big corporate partners

You don't shy away from a challenge, are curious and looking to make a big impact

You are comfortable wearing multiple hats and aren’t afraid to get your hands dirty

You know how to spot an issue (technical or interpersonal) and can tactfully and effectively resolve it before pressure starts to build

DirecTech Labs is an Equal Opportunity, Affirmative Action Employer. Minorities, women, veterans, and individuals with disabilities are encouraged to apply. We provide equal opportunity in all employment matters without regard to race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, marital status, national origin, ancestry, mental and physical disability, medical condition, age, genetic information, national origin, veteran status or any other status protected by federal, state, or local law, for all qualified applicants."
106,https://www.glassdoor.co.in/partner/jobListing.htm?pos=211&ao=457171&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_49ae62aa&cb=1562003628513&jobListingId=3208166269,Data Scientist II,Amazon, – Bengaluru," Amazon Music is awash in data and data will fuel our organizations growth. To enable this, the Music Data Quality team ensures the quality of our largest and most important dataset, behavioral events. They build prevention, detection, mitigation, and recovery capabilities in our real time and batch data services. This is a new cross-functional team which will use analysis, data science, data engineering, and services to drive significant business impact. Our goal is to empower all teams at Amazon Music to make high confidence data driven strategic decisions, effectively measure results of feature launches, and improve capabilities in automated product features decision making (like ML).  If you love the challenges that come with big data and relish data science modeling and anomoly detection problems then this role is for you. We collect billions of events a day, manage petabyte scale data on Redshift and S3, and develop data pipelines using Spark/Scala EMR, SQL based ETL, and Java services.  You are a talented, enthusiastic, and detail-oriented Data Scientist who wants to take on big data challenges in an agile way. Duties include developing analysis, data pipelines, and models to detect and prevent data quality issues of our most important behavioral dataset. You will work on high impact projects to analyze anomalies and design detection capabilities, create automated mitigation of downs stream impacts, provide analysis and recovery tools, and increase the overall quality and availability SLAs of our behavioral data.  You have a deep understanding of data, analytical techniques, and statistical modeling or ML, and know how to connect insights to the business. You also have practical experience in insisting on the highest standards on operations in ETL and big data pipelines or services. With our Amazon Music Unlimited and Prime Music services, and our top music provider spot on the Alexa platform, providing high quality, high availability data to our internal customers is critical to our customer experiences.  In 2019 you will be one of the founding members of your team, build detection and mitigation capabilities, invest in modeling and anomoly detection, and work on automation and tooling for data quality. Your efforts will have direct impacts on our key stakeholders across Royalties, Personalization, ML, Search, and Marketing. This is a high visibility, high impact position.  Amazon Music  Imagine being a part of an agile team where your ideas have the potential to reach millions. Picture working on cutting-edge consumer-facing products, where every single team member is a critical voice in the decision-making process. Envision being able to leverage the resources of a Fortune-500 company within the atmosphere of a start-up. Welcome to Amazon Music, where ideas are born and come to life as Amazon Music Unlimited, Prime Music, and so much more.  Everyone on our team has a meaningful impact on product features, new directions in music streaming, and customer engagement. We are looking for new team members across a variety of job functions including software engineering/development, marketing, design, ops and more. Come join us as we make history by launching exciting new projects in the coming year.  Our team is focused on building a personalized, curated, and seamless music experience. We want to help our customers discover up-and-coming artists, while also having access to their favorite established musicians. We build systems that are distributed on a large scale, spanning our music apps, web player, and voice-forward audio engagement on mobile and Amazon Echo devices, powered by Alexa to support our customer base. Amazon Music offerings are available in countries around the world, and our applications support our mission of delivering music to customers in new and exciting ways that enhance their day-to-day lives.  Come innovate with the Amazon Music team! Basic Qualifications · Bachelors degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline  · 5+ years of experience as a data/software/scientist or related technical job  · Experience developing and executing a data/software roadmap  · Experience building/managing big data or traditional DW platform components Preferred Qualifications · Experience with Agile Development  · Experience with Machine Learning (Classification, Collaborative Filtering)  · A love of music!  Amazon.com is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation. "
107,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1010&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_09d80870&cb=1562003715331&jobListingId=3200823628,Data Scientist II,Amazon, – Bengaluru," Amazon Music is awash in data and data will fuel our organizations growth. To enable this, the Music Data Quality team ensures the quality of our largest and most important dataset, behavioral events. They build prevention, detection, mitigation, and recovery capabilities in our real time and batch data services. This is a new cross-functional team which will use analysis, data science, data engineering, and services to drive significant business impact. Our goal is to empower all teams at Amazon Music to make high confidence data driven strategic decisions, effectively measure results of feature launches, and improve capabilities in automated product features decision making (like ML).  If you love the challenges that come with big data and relish data science modeling and anomoly detection problems then this role is for you. We collect billions of events a day, manage petabyte scale data on Redshift and S3, and develop data pipelines using Spark/Scala EMR, SQL based ETL, and Java services.  You are a talented, enthusiastic, and detail-oriented Data Scientist who wants to take on big data challenges in an agile way. Duties include developing analysis, data pipelines, and models to detect and prevent data quality issues of our most important behavioral dataset. You will work on high impact projects to analyze anomalies and design detection capabilities, create automated mitigation of downs stream impacts, provide analysis and recovery tools, and increase the overall quality and availability SLAs of our behavioral data.  You have a deep understanding of data, analytical techniques, and statistical modeling or ML, and know how to connect insights to the business. You also have practical experience in insisting on the highest standards on operations in ETL and big data pipelines or services. With our Amazon Music Unlimited and Prime Music services, and our top music provider spot on the Alexa platform, providing high quality, high availability data to our internal customers is critical to our customer experiences.  In 2019 you will be one of the founding members of your team, build detection and mitigation capabilities, invest in modeling and anomoly detection, and work on automation and tooling for data quality. Your efforts will have direct impacts on our key stakeholders across Royalties, Personalization, ML, Search, and Marketing. This is a high visibility, high impact position.  Amazon Music  Imagine being a part of an agile team where your ideas have the potential to reach millions. Picture working on cutting-edge consumer-facing products, where every single team member is a critical voice in the decision-making process. Envision being able to leverage the resources of a Fortune-500 company within the atmosphere of a start-up. Welcome to Amazon Music, where ideas are born and come to life as Amazon Music Unlimited, Prime Music, and so much more.  Everyone on our team has a meaningful impact on product features, new directions in music streaming, and customer engagement. We are looking for new team members across a variety of job functions including software engineering/development, marketing, design, ops and more. Come join us as we make history by launching exciting new projects in the coming year.  Our team is focused on building a personalized, curated, and seamless music experience. We want to help our customers discover up-and-coming artists, while also having access to their favorite established musicians. We build systems that are distributed on a large scale, spanning our music apps, web player, and voice-forward audio engagement on mobile and Amazon Echo devices, powered by Alexa to support our customer base. Amazon Music offerings are available in countries around the world, and our applications support our mission of delivering music to customers in new and exciting ways that enhance their day-to-day lives.  Come innovate with the Amazon Music team! Basic Qualifications · Bachelors degree in Data Science, Applied Science, Computer Science, Computer Engineering or related technical discipline  · 5+ years of experience as a data/software/scientist or related technical job  · Experience developing and executing a data/software roadmap  · Experience building/managing big data or traditional DW platform components Preferred Qualifications · Experience with Agile Development  · Experience with Machine Learning (Classification, Collaborative Filtering)  · A love of music!  Amazon.com is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation. "
108,https://www.glassdoor.co.in/partner/jobListing.htm?pos=327&ao=477713&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c1bf63ee&cb=1562003656991&jobListingId=3219089219,Manager - Data Scientist,Genpact, – Bengaluru,"Manager - Data scientist

Function: Digital

Bangalore, India

With a

startup spirit and 80,000 curious and courageous minds, we have the expertise

to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re

calling all you rule-breakers and risk-takers who see the world differently,

and are bold enough to reinvent it. Come, transform with us.

Inviting applications for the role of Manager,

Data scientist

Role involves

to think strategically about data as a core enterprise asset and assist in all

phases of the advanced analytic development process

Support advanced analytical and data mining

efforts which could include but not limited to clustering, segmentation,

logistic and multivariate regression, decision/CART trees, neural networks,

time-series analysis, sentiment analysis, topic modeling, random forests, and

Bayesian analysis

Responsibilities

The

scope of work includes Forecast, Prediction Models, Outlier Reporting, Payment

Integrity violation identification, 

Adhoc analysis
Implementation

of Supervised and Unsupervised model development techniques
Work

with Data engineers to supervise and help institutionalize models and

dashboards for Analytics team of leading Healthcare client
Develops

ML models using identified features and packages
Responsible

for maintenance and performance monitoring of the production environment for

the Advanced Analytics team
Lead

the design of complex and large-scale datasets to be used for statistical

modeling and data mining.
Slice

and dice through the database and come up with actionable analytical insights
Facility with one or more quantitative data

analysis languages such as R, SciPy, NumPy, SQL, Python, SAS, SPSS
Experience with relational database management

systems (Oracle, Teradata, SQL Server, DB2..)
Works with key stakeholders to generate and test

hypotheses
Experience with contemporary big data technologies

(Hadoop, HIVE, PIG, MapReduce)
Facility with one or more data analytical methods

such as regression, decision trees, experimental designs, support vector

machines, machine learning and text mining
Proficiency with Microsoft Office Suite
Work in a dynamic and fast-paced environment

without compromising the quality
Conduct explanatory data analysis and prepare data

sources to be analyzed.
Strong domain knowledge on US Healthcare is must

Qualifications

Minimum qualifications

Bachelors or Master’s degree with specialization

in statistics, applied mathematics, economics, finance, computer science or Information

systems/science; Preference given to candidates with demonstrated academic

achievement in core subjects and proficiency in quantitative subject matter

(Advanced Statistics coursework, Predictive Modeling projects). Familiarity

with PBM or Healthcare industry.
Relevant Healthcare domain experience


Preferred qualifications

Solid communication skills with

exposure to direct client communication is preferred

Genpact is an Equal Opportunity

Employer and considers applicants for all positions without regard to race,

color, religion or belief, sex, age, national origin, citizenship status,

marital status, military/veteran status, genetic information, sexual orientation,

gender identity, physical or mental disability or any other characteristic

protected by applicable laws. Genpact is committed to creating a dynamic work environment that values

diversity and inclusion, respect and integrity, customer focus, and innovation. For more information,

visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube."
109,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2005&ao=437149&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e1ddc874&cb=1562003813144&jobListingId=3201441647,Senior Data Analyst,Indegene, – Bengaluru,"A Senior Data Analyst needs to discover, explore, analyze, and document data from all sources and target systems to better understand the total scope of data availability. He or she also coordinates with the internal and external stakeholders. The role of the Senior Data Analyst also involves understanding the complete requirement of the project, as well as documenting as per companys requirement.

Job Description:

The roles and responsibilities of the Senior Data Analyst include the following:

Analyzing and debugging/rectifying the bugs identified

Synthesizing the data into information consumable by senior business decision makers

Being responsible for developing programs within the timelines assigned

Participating in the project review processes

Interacting with different stakeholders

Performing requirement analysis to strategize further action points

Adhering to compliance procedures and internal/operational risk controls in accordance with any and all applicable regulatory standards, requirements, and policies

Desired Skills and Experience:

EducationBSc/MSc
Experience5-8 years of relevant experience, with minimum 1-2 years of experience in managing a team of data analysts and 3-5 years of experience in developing back-end SQL procedures using MS SQL
Data management, clinical, and/or research experience, with solid understanding of clinical trials methodology and terminology
Understanding of the best practices followed in the department regarding processes, communication (internal and external), project management, documentation, and technical requirements of the project
Experience in developing stored procedures, triggers, and complex SQL queries
Exposure to VB and .Net is mandatory as the role involves building an engine to read data from MS Excel files and create SQL queries dynamically
Exposure to data warehousing/ETL
Should be a self-starter and capable of operating on minimal management oversight
Ability to work under pressure to meet agreed deadlines
Passion, energy, and enthusiasm to drive results
Passion to design artistically and a keen interest to learn new concepts and technologies
"
110,https://www.glassdoor.co.in/partner/jobListing.htm?pos=119&ao=452401&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_97ce683c&cb=1562003586332&jobListingId=3279226647,Data Scientist..,Akamai, – Bengaluru,"About the Job

If you have a deep passion for data and security, love handling massive data sets, and get excited from solving hard problems, Akamai is the place for you. We are seeking a highly motivated Threat Operations Analyst who will work with Engineering and Product Management teams to quickly resolve highly technical, complex issues, and advocate for real-world customer use cases, features, and functionality. You will apply your practical analytical skills and your experience with statistical analysis to derive actionable insights from large volumes of data.

Join a fast-paced team in Akamai’s Security Unit charged with protecting the largest brands against the unpredictable landscape of evolving botnets and malware. Bad actors might build massive botnets or new automated attack systems; you’ll help dismantle and cripple them in real, internet time.

About the Team

The web security team is focused on leveraging Akamai's core strengths of its highly distributed cloud-based platform that already serves up to 30% of the traffic on the web and the massive amount of HTTP data it has access to as a result to define industry leading web security products that provide rapid visibility and control for protection against constantly changing attack profiles.

Responsibilities



● Investigate the most sophisticated bots from across the Akamai’s customer base

● Tuning detection algorithms for best fit for a particular customer traffic pattern.

● On-going monitoring and measurement of the effectiveness of bot detection algorithms

● Build tools for automated analysis

● Keep abreast of current malware, botnets, or other automated agent trends and provide insights for further product enhancements
Required Education and Experience:

● BS or MS in Computer Science, Applied Math, Statistics, Data Science or relevant subject

● 3 years experience in Data analysis

● 3 years experience in Python programming

● 3 years experience in SQL.

● 3 years experience working on Unix platform

● 2 years experience with various open source data analytic packages such as Pandas, numPy, Matplotlib, etc

Desired Qualifications:

● Strong verbal and written communications skills; experience presenting complex technical information, succinctly, to technical and business audiences.

● Data visualization skills to translate complex models and analysis results into layman terms.

● Experience, familiarity and ease with handling large, messy data sets. Prior experience with AWS Athena is a plus, but not required.

● Experience in Javascript debugging.

● Understanding of Proxies, DNS, HTTP protocol, Browser Rendering engines.

● Familiarity with AWS and Big Data Technologies like EMR or Spark is a plus, but not required.

● Bot detection experience is a plus

● Interest in Machine Learning, specifically anomaly detection and data mining

● Interest in Web Application security

"
111,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2513&ao=437149&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9334d3bd&cb=1562003849869&jobListingId=3203987158,Data Science Machine Learning Engineering Manager, – Bengaluru, – Bengaluru,"About the Job

If you have a deep passion for data and security, love handling massive data sets, and get excited from solving hard problems, Akamai is the place for you. We are seeking a highly motivated Threat Operations Analyst who will work with Engineering and Product Management teams to quickly resolve highly technical, complex issues, and advocate for real-world customer use cases, features, and functionality. You will apply your practical analytical skills and your experience with statistical analysis to derive actionable insights from large volumes of data.

Join a fast-paced team in Akamai’s Security Unit charged with protecting the largest brands against the unpredictable landscape of evolving botnets and malware. Bad actors might build massive botnets or new automated attack systems; you’ll help dismantle and cripple them in real, internet time.

About the Team

The web security team is focused on leveraging Akamai's core strengths of its highly distributed cloud-based platform that already serves up to 30% of the traffic on the web and the massive amount of HTTP data it has access to as a result to define industry leading web security products that provide rapid visibility and control for protection against constantly changing attack profiles.

Responsibilities



● Investigate the most sophisticated bots from across the Akamai’s customer base

● Tuning detection algorithms for best fit for a particular customer traffic pattern.

● On-going monitoring and measurement of the effectiveness of bot detection algorithms

● Build tools for automated analysis

● Keep abreast of current malware, botnets, or other automated agent trends and provide insights for further product enhancements
Required Education and Experience:

● BS or MS in Computer Science, Applied Math, Statistics, Data Science or relevant subject

● 3 years experience in Data analysis

● 3 years experience in Python programming

● 3 years experience in SQL.

● 3 years experience working on Unix platform

● 2 years experience with various open source data analytic packages such as Pandas, numPy, Matplotlib, etc

Desired Qualifications:

● Strong verbal and written communications skills; experience presenting complex technical information, succinctly, to technical and business audiences.

● Data visualization skills to translate complex models and analysis results into layman terms.

● Experience, familiarity and ease with handling large, messy data sets. Prior experience with AWS Athena is a plus, but not required.

● Experience in Javascript debugging.

● Understanding of Proxies, DNS, HTTP protocol, Browser Rendering engines.

● Familiarity with AWS and Big Data Technologies like EMR or Spark is a plus, but not required.

● Bot detection experience is a plus

● Interest in Machine Learning, specifically anomaly detection and data mining

● Interest in Web Application security

"
112,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1826&ao=4120&s=58&guid=0000016baeae7564a2953d77b61044d8&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_349b9155&cb=1562003797818&jobListingId=3139847193,Data Science Machine Learning Engineering Manager, – Bengaluru, – Bengaluru,"About the Job

If you have a deep passion for data and security, love handling massive data sets, and get excited from solving hard problems, Akamai is the place for you. We are seeking a highly motivated Threat Operations Analyst who will work with Engineering and Product Management teams to quickly resolve highly technical, complex issues, and advocate for real-world customer use cases, features, and functionality. You will apply your practical analytical skills and your experience with statistical analysis to derive actionable insights from large volumes of data.

Join a fast-paced team in Akamai’s Security Unit charged with protecting the largest brands against the unpredictable landscape of evolving botnets and malware. Bad actors might build massive botnets or new automated attack systems; you’ll help dismantle and cripple them in real, internet time.

About the Team

The web security team is focused on leveraging Akamai's core strengths of its highly distributed cloud-based platform that already serves up to 30% of the traffic on the web and the massive amount of HTTP data it has access to as a result to define industry leading web security products that provide rapid visibility and control for protection against constantly changing attack profiles.

Responsibilities



● Investigate the most sophisticated bots from across the Akamai’s customer base

● Tuning detection algorithms for best fit for a particular customer traffic pattern.

● On-going monitoring and measurement of the effectiveness of bot detection algorithms

● Build tools for automated analysis

● Keep abreast of current malware, botnets, or other automated agent trends and provide insights for further product enhancements
Required Education and Experience:

● BS or MS in Computer Science, Applied Math, Statistics, Data Science or relevant subject

● 3 years experience in Data analysis

● 3 years experience in Python programming

● 3 years experience in SQL.

● 3 years experience working on Unix platform

● 2 years experience with various open source data analytic packages such as Pandas, numPy, Matplotlib, etc

Desired Qualifications:

● Strong verbal and written communications skills; experience presenting complex technical information, succinctly, to technical and business audiences.

● Data visualization skills to translate complex models and analysis results into layman terms.

● Experience, familiarity and ease with handling large, messy data sets. Prior experience with AWS Athena is a plus, but not required.

● Experience in Javascript debugging.

● Understanding of Proxies, DNS, HTTP protocol, Browser Rendering engines.

● Familiarity with AWS and Big Data Technologies like EMR or Spark is a plus, but not required.

● Bot detection experience is a plus

● Interest in Machine Learning, specifically anomaly detection and data mining

● Interest in Web Application security

"
113,https://www.glassdoor.co.in/partner/jobListing.htm?pos=217&ao=457171&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d35d5ff8&cb=1562003628519&jobListingId=2883011861,Applied Scientist - Intern,Amazon, – Bengaluru,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?

At Amazon Bangalore, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.

Major responsibilities

· Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems

· Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes

· Design, develop and evaluate highly innovative models for predictive learning

· Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation

· Research and implement novel machine learning and statistical approaches

Basic Qualifications

Basic Qualifications

· A Masters and/or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field.

· Experience in predictive modelling and analysis, predictive software development.

· Strong problem-solving ability

· Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)

· Experience in using R, Matlab, or any other statistical software

· Strong communication and data presentation skills

Preferred Qualifications

Preferred Qualifications

· Experience handling gigabyte and terabyte size datasets

· Experience working with distributed systems and grid computing

· Knowledge of the latest and state of the art ML technology.

· Publications or presentation in recognized Machine Learning and Data Mining journals/conferences"
114,https://www.glassdoor.co.in/partner/jobListing.htm?pos=717&ao=7438&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_59fe898a&cb=1562003690289&jobListingId=2950003332,Data Engineer,Simpl, – Bengaluru,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things.

Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”.

Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

Responsibilities

You will be focused on making sure of data correctness and accessibility, and building scalable systems to access/process it. Another major responsibility is helping AI/ML Engineers write better code. You will also build scalable, high performance data intensive services.

Examples:

- We have data pipelines processing aggregate and statistical data. Should we store this

in Redshift, in flat files in S3, or somewhere else?

- How should we structure our data pipelines?

- We need to track various data points to identify our customers in various locations, including from different devices, and determine that two seemingly disparate users are actually the same. How can we do this efficiently and effectively?

Your job is to understand what we’re trying to build, make informed choices about this and then get us going.

Example interview questions:

- Consider the query `SELECT * FROM foo INNER JOIN bar ON foo.x = bar.x WHERE foo.primary_key = ?`. What happens if you run this in Postgres? How does that differ if you run it in Redshift, or SparkSQL?

- Suppose we store a table in flat CSV files on S3. What kinds of jobs is this good for, and bad for? How is Parquet or BerkeleyDB different?

- What data structures are good for storing a graph, assuming the common query is finding a connected component?

On these questions, we’re primarily interested in computer science fundamentals. A good answer might be “a B-Tree, with keys structured as ...”. A bad answer might be be “use Neo4J, I don’t know how it works but it’s fast”."
115,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2710&ao=437149&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9e30eb84&cb=1562003865831&jobListingId=3265294459,Machine Learning Engineer (Contract Role),LogMeIn, – Bengaluru,"Requirements: Graduate in computer science/ Information systems Engg with min 3 years of product development experience.  Candidates having experience in ML / ML Classification would be preferred.  Hands-on knowledge on Python-flask, C#, ASP.NET Core MVC, Entity Framework.  Experience in NodeJS, SQL DB, Azure storage would be a plus.  Knowledge of cloud deployment, docker, Azure DevOps would be added advantage.  Excellent skills in communication and collaboration."
116,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1301&ao=140609&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e7aabd90&cb=1562003740643&jobListingId=3164788933,"Hiring for Lead Data Engineer, TVS Next",TVS NEXT, – Bengaluru,"Experience with Apache Spark, Hadoop, YarnFamiliarity with SQL and NoSQL technologiesExcellent programming skills in Scala or PythonMust have experience in designing and building large-scale data  applications and data pipelines in productionExperience with tools and technologies like Gradle, Maven,  Jenkins, Airflow, git, IntelliJ, Eclipse, Jupyter, Docker to support end to end  software developmentExperience with Cloud AWSWell versed in software development principlesCapable of mentoring and managing junior engineersMust be self-organized and focused on continues improvements of the  platform and the teamMust be a self-starter and a team player with great communication  skillsHighly motivated to add value to the team and platform using  innovations around data and data applications"
117,https://www.glassdoor.co.in/partner/jobListing.htm?pos=206&ao=457171&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b3eee3da&cb=1562003628508&jobListingId=3276505185,Data Analyst,Amazon, – Bengaluru," Through the Amazon Marketplace, Amazon provides individuals or enterprises the opportunity to sell their goods on the Amazon platform. Worldwide, more than a million sellers use this Marketplace and thereby contribute to the success of Amazon. Amazon is growing its Marketplace aggressively worldwide. In this context, Amazon India Seller Services is setting up a new service to help with driving selection improvement on Amazon.  In order to drive improvement in the Amazon selection, this program will contribute in identification and on-boarding of new selection and drive efficiency of the existing selection.  About the Role: We are looking for a hands-on, detail oriented and highly motivated data analyst to help create data backed insights that will drive selection improvement . The candidate should be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions. Operating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations. The candidate will be comfortable in executing repeatable processes. Basic Qualifications · Bachelor's degree in Computer Science, Engineering, Operations Research, Math, or related discipline.  · Minimum 2+ years of experience as an Analyst role preferred.  · Highly proficient in Microsoft Office and Windows based applications.  · SQL Knowledge and Hands-on experience is a must.  · Demonstrated Analytical ability, results-oriented environment with external customer interaction.  · Excellent written and verbal communication and presentation skills and the ability to express thoughts logically and succinctly.  · Entrepreneurial drive and demonstrated ability to achieve stretch goals in an innovative and fast-paced environment. Preferred Qualifications · Experience with E-Commerce, Retail and Business Analytics would be an advantage.  · Understanding of data warehousing, data modeling concept and building new DW tables  · Advanced SQL skills, fluent in R and/or Python, advanced Microsoft Office skills, particularly Excel and analytical platforms"
118,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1303&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b70c925e&cb=1562003740645&jobListingId=3279149634,Data Engineer,Dunzo, – Bengaluru," As a team, we believe that the best idea wins - no matter where the idea comes from. We tackle problems that have existed for years - through technology  and data. You'll be joining a vibrant, young team who are passionate about giving our users time back, provide flexible earning opportunities for our Partners and enhance local businesses. Requirements: 3-8 years of experience.  Proficient in Python/Java/Scala.  Good understanding of design patterns and software engineering principles.  Good understanding of Databases - SQL, NoSQL, OLAP, Data Warehouses and Data Lakes.  Strong experience in managing DWs and DLs.  Strong experience in managing ETLs especially Engagement data.  Hands-on experience with Big-data ecosystem technologies like Hive, Spark, MR, Presto, HBase, Kafka.  Hands-on experience in deploying Data-science models in production and designing production pipelines to measure KPIs of Models.  Experience in handling visualization tools whether Open source or third-party services.  Hands-on with SQL.  Hands-on with working on AWS, GitHub, Git.  Experience on working with Open source ML frameworks like TensorFlow, PyTorch, Caff2 etc would be a plus.  Experience in working on Recommendation problems.  Contribution to Open source.  Experience on working with Workflow management tools like Apache Airflow, Azkaban, Luigi etc."
119,https://www.glassdoor.co.in/partner/jobListing.htm?pos=507&ao=457171&s=58&guid=0000016baeac946289d87fba82cd68ad&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_950e20cd&cb=1562003674683&jobListingId=3223465172,Data Engineer,Amazon, – Bengaluru," Amazon.com operates in a virtual, global e-commerce environment without boundaries, and operates a diverse set of businesses, including retail, third party marketplaces, e-commerce platforms, web services for developers. Amazon's mission is to be earth's most customer-centric company.  Compliance Operations (C-Ops) is part of Health Safety Sustainability Security and Compliance (HSSSC) organization within Amazon. C-Ops ensures that Amazon transactions satisfy legal and safety requirements in compliance with guidelines set by regulatory bodies. We coordinate with aspects of identifying the risk involved in handling a hazardous product while storage and transport and classifying products with appropriate hazmat attributes. This team also review aspects of product transactions that are regulated (distribution, shipping, sale, and import/export). This involves analyzing product import documentation. We focus on product testing, certification, and regulatory permitting to ensure customer safety and protect Amazon in a constantly changing global environment.  As a Data Engineer, you should be an expert in the architecture of DW solutions for the Enterprise using multiple platforms. You should excel in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business analysts and engineers to determine how best to design the data warehouse for reporting and analytics. You will be responsible for designing and implementing scalable ETL processes in the data warehouse platform to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making. You should have the ability to develop and tune SQL to provide optimized solutions to the business. Basic Qualifications · Experience writing high quality, maintainable SQL on large datasets.  · Ability to write code in Python, Ruby, Scala or other platform-related Big data technology.  · Expertise in Star Schema data modelling  · Exposure/Experience in Big data Technologies (hadoop, spark, etc.).  · Strong analytical and problem solving skills  · Expertise in the design, creation and management of large datasets/data models  · Experience working on building /optimizing logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs  · Experience with AWS services including S3, Redshift, EMR and RDS  · Excellent verbal and written communication skills  · Ability to work with business owners to define key business requirements and convert to technical specifications Preferred Qualifications · Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy  · Experience working with other engineers in defining data engineering best practices and leveraging software development life cycle best practices such as agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.  · Knowledge of software engineering best practices across the development life cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations"
120,https://www.glassdoor.co.in/partner/jobListing.htm?pos=919&ao=437149&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_7ac095a2&cb=1562003705660&jobListingId=3201235944,Data Scientist,AI Enterprise, – Bengaluru,"Requirements:

Expert in cleansing data, removing anomalies, selecting features, reducing dimensions, building/optimizing classifiers, correlating hard business / technology generated data with social media data (like tweets / blogs / posts / etc.) to discover hidden or unseen data or trend from vast amounts of data by applying various data mining techniques, statistical analysis and thus building high quality prediction systems.

Excellent understanding of machine and deep learning concepts / techniques like k-NN, SVM, Decision Forests, linear regression models, gradient descent, etc.

Experience in using data science tools like R, Python, Matlab / Octave (at least one of them)

Knowledge of NoSQL databases such as MongoDB, Cassandra, Hbase, etc.

Knowledge of Hadoop stack, Spark, Map-Reduce, Hive, Pig, Shell Scripting and familiarity Unix/Linux OS.

Good understanding of relational databases with ability to write/ modify complex SQL queries to generate required datasets and tune query performance.

Understands dimensional data model, logical data model and physical data model for analytics and reporting. Understands data design that supports integration of data and information flow across various applications, systems and platforms.

Strong analytical and problem solving skills. Should provide solutions to complex problems without known solutions.

Excellent communication skills and capability to effectively work with both Business and Technology teams.

Qualification - Degree in applied math, statistics, engineering, computer science or other quantitative field required. PhD or MS/MTech preferred.

BE / BTECH in MIS, CS or related field. 1+ years of technology experience as a Data Scientist"
121,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2928&ao=437149&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_51f7a730&cb=1562003887240&jobListingId=3200912520,Data Analyst | MIS Executive,Corporate Resources, – Bengaluru,"Corporate Resources

Location : Bengaluru / Bangalore

Experience : 1 to 4 Year(s)

₹ Not Disclosed by Recruiter

Tweet

Job Description Send me jobs like this

Immediate Openings for Data Analytics / MIS Executive/ Operations Exe. Should be able to speak English & Hindi. Gradution is a MUST with minimum 1 yr experience CTC: 24K wit quarterly Bonus 3k Day Shift.

Industry

BPO / Call Centre / ITES

functional Area

ITES, BPO, KPO, LPO, Customer Service, Operations

Job Role

Assistant Manager/Manager-(Technical)

Keyword

Data Analysis operations, management bpo operations, mis, mis preparation, database analyst

Job Type

Permanent

Qualification

UG Qualification

Any Graduate - Any Specialization

PG Qualification

Any Post Graduate - Any Specialization

Doctorate

Doctorate Not Required - None

Desired Candidate Profile

Please refer to the Job description above

Company Profile

Company Name

Corporate Resources

Website

www.crplindia.com

About Company

Corporate Resources is a national HR service provider servicing world class companies across the globe. Started in 2004, the company has grown into a full spectrum HR services provider for clients worldwide. It has helped generate career opportunities for thousands of individuals in the countries, and has worked for over Fortune 500 organizations.

Contact Information

Recruiter Name

Subhashree

Phone No

+91 7205050084

Email ID

resume@crplindia.co.in

Address

Plot No. : N-6/9, I.R.C. Village, Nayapally, Bhubaneswar, Odisha - 751015"
122,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2724&ao=4120&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a2da18a8&cb=1562003865842&jobListingId=2619100978,Computer Vision/Deep Learning Research Scientist, – Bengaluru, – Bengaluru,"Corporate Resources

Location : Bengaluru / Bangalore

Experience : 1 to 4 Year(s)

₹ Not Disclosed by Recruiter

Tweet

Job Description Send me jobs like this

Immediate Openings for Data Analytics / MIS Executive/ Operations Exe. Should be able to speak English & Hindi. Gradution is a MUST with minimum 1 yr experience CTC: 24K wit quarterly Bonus 3k Day Shift.

Industry

BPO / Call Centre / ITES

functional Area

ITES, BPO, KPO, LPO, Customer Service, Operations

Job Role

Assistant Manager/Manager-(Technical)

Keyword

Data Analysis operations, management bpo operations, mis, mis preparation, database analyst

Job Type

Permanent

Qualification

UG Qualification

Any Graduate - Any Specialization

PG Qualification

Any Post Graduate - Any Specialization

Doctorate

Doctorate Not Required - None

Desired Candidate Profile

Please refer to the Job description above

Company Profile

Company Name

Corporate Resources

Website

www.crplindia.com

About Company

Corporate Resources is a national HR service provider servicing world class companies across the globe. Started in 2004, the company has grown into a full spectrum HR services provider for clients worldwide. It has helped generate career opportunities for thousands of individuals in the countries, and has worked for over Fortune 500 organizations.

Contact Information

Recruiter Name

Subhashree

Phone No

+91 7205050084

Email ID

resume@crplindia.co.in

Address

Plot No. : N-6/9, I.R.C. Village, Nayapally, Bhubaneswar, Odisha - 751015"
123,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2510&ao=437149&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_320b3c6e&cb=1562003849866&jobListingId=3200733638,Lead Computer Scientist, – Bengaluru, – Bengaluru,"Corporate Resources

Location : Bengaluru / Bangalore

Experience : 1 to 4 Year(s)

₹ Not Disclosed by Recruiter

Tweet

Job Description Send me jobs like this

Immediate Openings for Data Analytics / MIS Executive/ Operations Exe. Should be able to speak English & Hindi. Gradution is a MUST with minimum 1 yr experience CTC: 24K wit quarterly Bonus 3k Day Shift.

Industry

BPO / Call Centre / ITES

functional Area

ITES, BPO, KPO, LPO, Customer Service, Operations

Job Role

Assistant Manager/Manager-(Technical)

Keyword

Data Analysis operations, management bpo operations, mis, mis preparation, database analyst

Job Type

Permanent

Qualification

UG Qualification

Any Graduate - Any Specialization

PG Qualification

Any Post Graduate - Any Specialization

Doctorate

Doctorate Not Required - None

Desired Candidate Profile

Please refer to the Job description above

Company Profile

Company Name

Corporate Resources

Website

www.crplindia.com

About Company

Corporate Resources is a national HR service provider servicing world class companies across the globe. Started in 2004, the company has grown into a full spectrum HR services provider for clients worldwide. It has helped generate career opportunities for thousands of individuals in the countries, and has worked for over Fortune 500 organizations.

Contact Information

Recruiter Name

Subhashree

Phone No

+91 7205050084

Email ID

resume@crplindia.co.in

Address

Plot No. : N-6/9, I.R.C. Village, Nayapally, Bhubaneswar, Odisha - 751015"
124,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2606&ao=133824&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_7f1bf84e&cb=1562003857966&jobListingId=3257298765,BUSINESS INTELLIGENCE ANALYST II,TE Connectivity, – Bengaluru,"

 Apply now »

 

 Apply now
 
 

 
 
 Start apply with Xing
 
 
 
 
  
 
 Apply Now
 
 
 
 
  


 
 
 Start
 
 






Please wait...





 
 a.dialogApplyBtn {
 display: none;
 }
 
 





 

 BUSINESS INTELLIGENCE ANALYST II
 
 
 







Job Posting Title: BUSINESS INTELLIGENCE ANALYST II 
Job Code: 30003773 
Segment: TRANSPORTATION SOLUTIONS (50132248) 
Business Unit: GLOBAL AUTOMOTIVE (10002006) 
Building: TE ADC Shared Services Corporate (Q69) 
Band/Level: 5 
Hiring Manager: Ganesh Vijaya Kumar 
Recruiter: Prathibha Shankar 
Relocation:Yes - Domestic 
Travel: None 
Employee Referral Amount: 
Education Experience: Bachelors Degree (High School +4 years) 
Employment Experience: 3-5 years
 
Company Information
TE Automotive is one of the leading providers of advanced automobile connectivity solutions. We enable nearly every electronic function in the car -- from alternative power systems to infotainment and sensor technologies – all in a harsh environment. No matter which technology path OEMs choose to innovate for the connected car, we’re committed to helping our customers meet evolving challenges and requirements.
Job Overview
TE Connectivity’s Business Intelligence Teams are responsible for the processing, mining and delivery of data to their customer community through repositories, tools and services.
Responsibilities & Qualifications

Manage team of Reporting Analysts.
Liaison with Internal & External customers in acquiring best practices & competencies. 
Define Frameworks, Solution & Service definition around analytics.
 Pre-sales- custom solutioning.
Competency development on various data reporting tools Participate & lead customer presentations. 
Drive the development and analysis of data, Dash boarding and business intelligence programs primarily leveraging Tableau, Power BI and Microsoft SQL Server toolset.
Should be able to understand business and create visuals to empower users with information. 
Should able work with agile working methodologies. 
Should be able handle the projects with less dependencies.
Knowledge of data analytics principles is a must.
Knowledge about SQL and database concepts is a must.
Experience working with huge datasets is a must.
Experience with Big data, Cloud database.

Competencies
Values: Integrity, Accountability,Teamwork, Innovation























 Location: 
 

 
 

 Bangalore, KA, IN, 560070
 
 

 
 #job-location.job-location-inline {
 display: inline;
 }
 
 
 







 Alternative Locations: 
 

 
 
 







 Travel: 
 

 None
 
 







 Requisition ID: 
 

 46249
 
 








Job Segment: 
 Business Intelligence, Database, SQL, Pre-Sales, Technology, Automotive, Sales
 
 
 


 Apply now »

 

 Apply now
 
 

 
 
 Start apply with Xing
 
 
 
 
  
 
 Apply Now
 
 
 
 
  


 
 
 Start
 
 






Please wait...





 
 a.dialogApplyBtn {
 display: none;
 }
 
 




Find similar jobs: 
 
 エンジニア／技術職, 
 Engineering und Technologie, 
 Engineering & Technology_NL, 
 Engineering & Technology, 
 Engenharia e Tecnologia
 
Apply Now"
125,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1016&ao=463638&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_6b6966d5&cb=1562003715343&jobListingId=3276450804,Data Engineer - Big Data,J.P. Morgan, – Bengaluru," J.P. Morgan is a leading global financial services firm, established over 200 years ago:  o We are the leader in investment banking, financial services for consumers and small businesses, commercial banking,  financial transaction processing, and asset management.  o We have assets of $2.5 trillion and operations worldwide  o We operate in more than 100 markets.  o We have more than 243,000 employees globally.  Our wholesale businesses include J.P. Morgans Asset Management, Commercial Banking and the Corporate &  Investment Bank which provide products and services to corporations, governments, municipalities, non-profits,  institutions, financial intermediaries and high-net worth individuals and families.  Our corporate functions support the entire organization and include the following functions: Accounting, Audit, Finance,  Human Resources, Operations, and Technology.  J.P. Morgan in India provides a comprehensive range of Corporate & Investment Banking, Commercial Banking, Asset &  Wealth Management, and Corporate functions services and solutions to our clients, executing some of the most important  financial transactions and providing essential strategic advice to our clients such as the government, large domestic  and multi-national corporations, non-government organizations and financial institutions and investors. India is a key  market for JPMorgan Chase globally and our employees in India are a critical part of how we do business globally and are  integrated within our businesses. Our Global Service Centers (GSCs) are strategically positioned in Mumbai, Bangalore  and Hyderabad to support the firms operations regionally and globally. The centers provide comprehensive strategic  support across technology and business operations processing to all lines of business and the corporate functions.  The Technology team at our GSCs service all Lines of Business and Enterprise Technology in helping build and operate  innovative industry leading solutions. The breadth of capabilities within the Technology team at the GSC enables it to  support the firm in leading edge areas such as Digital, Big data analytics, Robotics & Machine Learning.  The Digital Technology supports public Internet sites & Mobile apps for all lines of business within J. P. Morgan Chase.  Digital Tech is comprised of over 400 professionals located in New York, Ohio, Texas and California. The group consists  of senior business strategists, developers, infrastructure and architecture specialists, information architects, usability  professionals, interactive designers, editors and other project support and operations staff. Digital Tech works closely with  all lines of business including: Auto Lending, Business Banking, Card Services, Commercial Banking, Education Finance,  Home Lending, Investing, Private Bank, Private Client Services, Retail and Treasury. JPMorgan Chase's online & Mobile  sites are currently among the top ranked in the industry. Digital Tech's goal is to provide consistent, integrated internet  applications that are intuitive, dependable and easy to use for all customers.  As an Applications Developer, you will provide high quality technology solutions that address business needs by  developing applications for the Chase Online customer base. This position requires a high level of development expertise  with Internet based programming architectures and Object Oriented principles. The ability to communicate effectively  is also required as you will work closely with other groups both within and outside of the organization to coordinate  design, development, and testing efforts of your assigned application components to ensure the successful delivery of the  project.  Responsibilities: Bachelors degree in Engineering, Computer Science, or Information Technology.10+ years of extensive experience in Big data background and basic tools under the umbrella such as Sqoop, Hive, Impala etc.Extensive working experience with ETL background, technically sound in SQL and all RDBMS databases.Extensive experience profiling, debugging, and performance tuning complex distributed systems.Should have experience working with any of the programming languages Python, Scala or R.Experience working in an Agile environment a plusWillingness to commit extra effort to meet deadlines as required on a high profile and business critical projectKnowledge of Messaging and Event Streaming (MQ, Kafka, etc.), Stream processing (Storm, Spark Streaming, etc.) is a plus.Consumer banking knowledge preferredExcellent written and verbal communication skillsAdvanced analytical thinking and problem solving skillsProven experience with data infrastructure initiatives, best practices and key componentsKnowledge of the Financial sector, Banking is a huge plus.Ability to Create conceptual & logical models to describe a particular domain of data and use these models to inform the physical design of data-related projects.QualificationsBachelors degree in Engineering, Computer Science, or Information Technology.10+ years of extensive experience in Big data background and basic tools under the umbrella such as Sqoop, Hive, Impala etc.Extensive working experience with ETL background, technically sound in SQL and all RDBMS databases.Extensive experience profiling, debugging, and performance tuning complex distributed systems.Should have experience working with any of the programming languages Python, Scala or R.Experience working in an Agile environment a plusWillingness to commit extra effort to meet deadlines as required on a high profile and business critical projectKnowledge of Messaging and Event Streaming (MQ, Kafka, etc.), Stream processing (Storm, Spark Streaming, etc.) is a plus.Consumer banking knowledge preferredExcellent written and verbal communication skillsAdvanced analytical thinking and problem solving skillsProven experience with data infrastructure initiatives, best practices and key componentsKnowledge of the Financial sector, Banking is a huge plus.Ability to Create conceptual & logical models to describe a particular domain of data and use these models to inform the physical design of data-related projects."
126,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2815&ao=132976&s=58&guid=0000016baeafa65a98836b4f5999adf7&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f50b650d&cb=1562003875872&jobListingId=3225837160,"Consumer Banking Technology - CCBD Tech Integrated Solutions - CCBD Tech, Data Engineer",Goldman Sachs, – Bengaluru," MORE ABOUT THIS JOBWhat We DoAt Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.Who We Look ForGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.  Consumer and Investment Management (CIMD)  The Consumer and Investment Management Division includes Goldman Sachs Asset Management (GSAM), Private Wealth Management (PWM) and our Consumer business (Marcus by Goldman Sachs). We provide asset management, wealth management and banking expertise to consumers and institutions around the world. CIMD partners with various teams across the firm to help individuals and institutions navigate changing markets and take control of their financial lives.  Consumer  Consumer, externally known as Marcus by Goldman Sachs, is comprised of the firm’s digitally-led consumer businesses, which include our deposits and lending businesses. It also includes our personal financial management app, Clarity Money. Consumer combines the strength and heritage of a 150-year-old financial institution with the agility and entrepreneurial spirit of a tech start-up. Through the use of insights and intuitive design, we provide customers with powerful tools that are grounded in value, transparency and simplicity to help them make smarter decisions about their money.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• Design and develop data ingest and transform processes• Develop data visualizations using BI tools and web-based technologies• Work as part of a global team using Agile software methodologies• Partner with Marcus risk, product, acquisition and servicing teams• Use Marcus data to drive change throughout the Marcus businessSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Minimum 3 years of relevant professional experience• Bachelor’s degree or equivalent required• Experience with SQL and relational databases• Proficient at Python, Spark and the Hadoop ecosystem• Self-starter, motivated, and good communication skills Strong sense of ownership and driven to manage tasks to completionPreferred QualificationsABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
127,https://www.glassdoor.co.in/partner/jobListing.htm?pos=921&ao=272234&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_01fbc46f&cb=1562003705662&jobListingId=3240242544,Data Analytics Manager,AIG, – Bengaluru,"Functional Area:IT - Information TechnologyEstimated Travel Percentage (%): Up to 25%Relocation Provided: YesAIG ANALYTICS & SERVICES PRIVATE LIMITEDJob Description

Job Title: Data Analytics Manager, Data Analytics and Monitoring – Global Compliance Group, Bangalore, India

Estimated Travel Percentage (%): Up to 25%

AIG’s Global Compliance Group’s (“GCG”) Data Analytics and Monitoring Team is seeking an individual to drive the implementation of Data Analytics and Automation solutions for the Compliance Department.

GCG is a centralized compliance function with oversight responsibility for managing compliance risks and sustaining compliance management across AIG’s businesses, functions, legal entities and countries of operation. The Compliance Data Analytics and Monitoring Program is one of the key functions of the GCG, and is aligned with the Compliance Risk Taxonomy with a focus on assessing compliance risks and related controls as they pertain to AIG and Business Policies and Standards, as well as key country and state laws and regulations.

As a Data Analyst/Scientist, you will have an exciting opportunity to learn about AIG’s products and services across multiple businesses, including General Insurance, Life & Retirement and Investments. In addition, you will be part of the Program’s transformation efforts in rolling out Data Analytics and Monitoring program, and supporting the use of automation across the department.

GCG is seeking candidates who have excelled in previous work experience, possess strong analytical, quantitative and interpersonal skills, and are enthusiastic about and committed to AIG to contribute to the firm’s strategic goals. You will be expected to bring an Analytical and Innovation mindset to a team-oriented environment.

Specific Responsibilities

Strong problem solving skills with emphasis on Data Analytics and Continuous Monitoring.Recruit, train and retain highly effective Analytics staff.Build and nurture positive working relationships with clients and other Analytics teams.Mine and analyze large amounts of data from multiple data sources to identify and interpret patterns that are applicable to the Compliance organization.Develop models using various industry standard tools to automate transaction testing and manual processes.Work with different stakeholders globally to identify opportunities for leveraging data and analytics to drive business solutions.Manage department Analytics Infrastructure and Data Warehouse.Good working knowledge of Robotic Process Automation and Machine Learning.Good understanding of Risk based Analytics with goal to provide assurance on Compliance Risks.Provide ongoing surveillance, review, and analysis of key risk indicators to identify red flags and potential compliance violations.Proven track record in Analytics Story-Telling and effectively communicating findings.Collaborate with the Compliance Testing team members and provide data analytics and automated testing support during the testing lifecycle, including planning, testing of controls and reporting.Train Compliance Testing team members on available automated tools and work to improve the overall testing review process, including full population testing.Build close working relationships with business and functional leaders, colleagues across other assurance functions, and fellow team members.Use predictive modeling to increase and optimize value of the Analytics SolutionsExperience using statistical languages (Python, R) to manipulate data and draw insights

Qualifications

7-10 years of relevant analytics experience. 1-3 years’ experience of managing Analytics resources.Bachelor’s or Master’s Degree, preferably in Data Analytics, Information Science, Computer Science, Data Science, Statistics, , and/or other related discipline.

Experience developing solutions utilizing Analytics, BI, database, and Visualization tools (e.g., SQL, KNIME, Rapid Miner, Alteryx, Power BI, Tableau, Python, UIPath, Netezza, and Hadoop).A strong drive to learn and master new technologies and techniques.Experience working in a multi-project environment and across multiple countries.Solid foundational knowledge of Compliance testing and/or insurance business processes, including the relevance of key applicable laws and regulations.Strong project management skills, including effective attention to detail.Strong interpersonal skills to establish effective working relationships with and provide constructive feedback to stakeholders, colleagues and reviewers.Strong verbal and written communication skill, including presentation skills.Effective time management skills; coordinate and prioritize competing initiatives while meeting deadlines.Ability to create Data Analytics and Monitoring Methodology and Best Practices.Ability to educate team members in Analytics and Automation best practices.Ability to identify process improvements and suggest efficiencies.Ability to document processes, and transfer knowledge to team members.

It has been and will continue to be the policy of American International Group, Inc., its subsidiaries and affiliates to be an Equal Opportunity Employer. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories.

At AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives."
128,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2619&ao=7438&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_f09c69b8&cb=1562003857980&jobListingId=2988678128,Data Engineer/ Senior Data Engineer,Razorpay, – Bengaluru,"Job OverviewWe are looking for a savvy Data Engineer to join our growing team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.Responsibilities for Data Engineer



Create and maintain optimal data pipeline architecture
Create and maintain events/streaming based architecture/design
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data scientists to strive for greater functionality in our data systems.


Qualifications for Data Engineer



Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Strong analytic skills related to working with structured/unstructured datasets.
Build processes supporting data transformation, data structures, dimensional modelling, metadata, dependency, schema registration/evolution and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 2+ years of experience in a Data Engineer role. They should also have experience using the following software/tools:

Experience with big data tools: HDFS/S3, Spark/Flink,Hive,Hbase, Kafka/kanisis, etc.
Experience with relational SQL and NoSQL databases, including Elasticsearch and Cassandra/Mongodb.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS /GCP cloud services
Experience with stream-processing systems: Spark-Streaming/Flink etc.
Experience with object-oriented/object function scripting languages: Java, Scala, etc.

"
129,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2030&ao=437149&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e60c41aa&cb=1562003813165&jobListingId=3201246666,Data Scientist - Retail Lending,Scienaptic Systems, – Bengaluru,"As our representative in front of the client, you will have the opportunity to construct and deliver high-end analytics solutions delivered from a cutting-edge big-data machine learning platform. We expect you to be proactive, high energy and detail oriented and to take total accountability for client delight and growth.

We are looking for an energetic and experienced person as Data Scientist. The chosen candidate will be responsible for developing all aspects of data mining, predictive analytics, solution development to name a few.

Experience in Financial services (Credit Risk, Cards, loans etc) on the Retail banking is a must.

Few expectations from the candidate are:

Focus on developing clear and concise analytical approach for problem-solving with client partnership

Strong understanding of ML libraries and applications e.g. Neural Net, SVMs, Boosting methods and implementation using R/Python. Should have the academic paper level understanding of math e.g. linear algebra, calculus etc.

Ability to code on SAS/R for data mining, analysis and insights and/or languages like Python for creating efficient production ready code

Managing the delivery of projects incl. timely communication, setting milestones and tracking

Generating actionable insights for business/KPI improvements

Rich experience in at least one production-ready deployment of Machine Learning algorithms is a plus.

Experience in working on the real-life large messy dataset to solve real business problems. Kaggle experience is a plus.

Desired Qualifications & Experience for Data Science role are:

Minimum 4 years of experience with machine learning and product development

Minimum 4 years hands-on coding experience with either of R/Python/Hive/Pig and demonstrated strong proficiency.

Ph.D., MS, Masters in Economics / Statistics / Mathematics is a must.

Should be comfortable working in a fast-paced startup / small office environment

Strong written and oral communication skills

Passionate about innovating, solving bigger picture problems, dealing with ambiguity

Strong presentation & data visualization skills using either of Tableau, QlikView, d3.js is a plus

Knowledge of Spark MLlib, h20 is a plus"
130,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1915&ao=136249&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1fd50a72&cb=1562003805561&jobListingId=3276495698,Senior Data Analyst,Capgemini, – Bengaluru,"Short Description

Qualifications

Job Responsibilities

"
131,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2218&ao=437149&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_3a548abf&cb=1562003826203&jobListingId=3201528785,Big Data Engineer,VMware, – Bengaluru,"Requirements:

Bachelor's degree or equivalent required with preference for Computer Science or Engineering. MS degree would be highly desirable.

Sr Big Data consultant or architect.

8+years of overall experience and hands-on experience in Hadoop - MapReduce, HDFS, Hbase, Hive, Sqoop, MongoDB, NoSQL or Cassandra.

Hands on Experience with Cloudera Distribution & expertise in Spark & Scala.

Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery.

Proven expertise in a wide variety of database technologies, from Postgres, SQLServer to NoSQL systems such as MongoDB, Cloudant, Cassandra, and/or Elasticsearch, and can explain their varied use cases.

Real-world practical experience with machine learning algorithms for classification, regression, clustering, reinforcement learning, dimensionality reduction with expertise one or more application domains of NLP, image processing, time series analysis.

Proficiency with several years' experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting.

5 to 6 +years' of implementation experience with data warehouse architecture & design, ETL design/development, and Analytics.

Experience with any of the database platforms (e.g. SAP HANA, Teradata, DB2, Vertica, Oracle)."
132,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1304&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_963a1e9f&cb=1562003740646&jobListingId=3201007862,Machine Learning Engineer,Ignitarium Technology Solutions, – Bengaluru,"Job Locations :

Bangalore, Kochi

Must have

3 - 10 years’ experience developing software for Computer Vision, Machine/Deep learning

Hands on with C, C++, Python, Linux, C#

Hands on with OpenCV, TensorFlow, Caffe, CUDA, OpenCL, OpenGL

Hands-on experience with internals of networks (CNN, RNN, LSTM, SSD etc). Customization of NN and improving performance

Experience with GPU/DSP/ISP/SoC architecture and system software.

Hands-on experience with one or more leading embedded SoC platforms (Nvidia, Qualcomm, NXP, Movidius, etc.)

Good analytical and problem-solving skills

Knowledge of computer architecture

Can build prototypes leading to production worthy solutions

Contribution in research communities, publishing papers or participation in Github projects related to machine learning would be a distinct advantage.

Education

Electronics/Electrical/Computer Science Graduate/Post Graduate/PhD"
133,https://www.glassdoor.co.in/partner/jobListing.htm?pos=512&ao=437149&s=58&guid=0000016baeac946289d87fba82cd68ad&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_013238b7&cb=1562003674687&jobListingId=3279149699,Senior Data Scientist,upGrad, – Bengaluru,"At upGrad the technology team enables all the facets of the business - whether it's bringing efficiency to our marketing and sales initiatives, to enhancing our student learning experience, to empowering our content, delivery and student success teams, to aiding our student's for their desired career outcomes. We play the part of bringing together data & tech to solve these business problems and opportunities at hand.

We are looking for an highly skilled, experienced and passionate data-scientist who can come on-board and help create the next generation of data-powered education tech product. The ideal candidate would be someone who has worked in a Data Science role before wherein he/she is comfortable working with unknowns, evaluating the data and the feasibility of applying scientific techniques to business problems and products, and have a track record of developing and deploying data-science models into live applications. Someone with a strong math, stats, data-science background, comfortable handling data (structured+unstructured) as well as strong engineering know-how to implement/support such data products in Production environment. Ours is a highly iterative and fast-paced environment, hence being flexible, communicating well and attention-to-detail are very important too. The ideal candidate should be passionate about the customer impact and comfortable working with multiple stakeholders across the company.

Requirements:

3+ years of experience in analytics, data science, machine learning or comparable role.

Bachelor's degree in Computer Science, Data Science/Data Analytics, Math/Statistics or related discipline.

Experience in building and deploying Machine Learning models in Production systems.

Strong analytical skills: ability to make sense out of a variety of data and its relation/applicability to the business problem or opportunity at hand.

Strong programming skills: comfortable with Python - pandas, numpy, scipy, matplotlib; Databases - SQL and noSQL.

Strong communication skills: ability to both formulate/understand the business problem at hand as well as ability to discuss with non data-science background stakeholders.

Comfortable dealing with ambiguity and competing objectives.

Preferred Qualifications:

Experience in Text Analytics, Natural Language Processing.

Advanced degree in Data Science/Data Analytics or Math/Statistics.

Comfortable with data-visualization tools and techniques.

Knowledge of AWS and Data Warehousing.

Passion for building data-products for Production systems - a strong desire to impact the product through data-science techniques."
134,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1507&ao=437149&s=58&guid=0000016baeade353b462a8951a2c366c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_6330262e&cb=1562003760373&jobListingId=3201128331,Lead Data Scientist / Machine Learning Expert,Bidgely, – Bengaluru,"Position

Bidgely is looking for extraordinary and dynamic Data Scientists to be part of its core team in Bangalore. You must have delivered advanced statistical and machine learning models as part of commercial products and created substantial intellectual property with business impact. You must enjoy working with large data and finding interesting patterns in the data through analytics experiments in a methodical and data driven scientific way. Be part of a highly energetic and

Responsibilities

Lead a team of data scientists to delivery energy analytics models and solutions from ideation to production quality code.

Provide technical direction and mentorship to the team, as well as hands-on management.

Research and develop advanced statistical and machine learning models for analysis of large-scale, high-dimensional data.

Dig deeper into data, understand characteristics of data, evaluate alternate models and validate hypothesis through theoretical and empirical approaches.

Collaborate with product management and engineering teams to elicit & understand their requirements & challenges and develop potential solutions

Stay current with the latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.

File patents for innovative solutions that add to the company portfolio.

Requirements

6-9 years of strong experience in data mining, machine learning and statistical analysis.

BS/MS/PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)

Ability to lead and deliver in a fast paced start-up environment.

Fluency in tools such as Matlab, Python etc.

Strong intuition for data and Keen aptitude on large scale data analysis

Excellent written and verbal communication skills.

Ability to collaborate across teams and strong interpersonal skills.

Email

To apply for this position, please email your resume to india-jobs@bidgely.com."
135,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2702&ao=478887&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d3c796bf&cb=1562003865825&jobListingId=3143395995,Principal Engineer (Al/ML/Data Science),Staffio HR, – Bengaluru,"Exp: 14 - 22 years

CTC: 50 - 63 LPA

Talents from Tier 1 Tech Schools

Should be from Product Dev Firms

This is in IC Role

Machine Learning:

Experience in ML techniques: SVM, boosting, K-means, KNN, HMM, GMM, Ensemble classifier, deep learning etc.

- International publications in relevant fields in top-tier conferences and journals.

- Strong mathematical understanding.

- Up-to-date knowledge and understanding of recent trends in machine learning

Computer Vision:

Experience with object detection, tracking, classification, recognition, scene understanding, facial expression analysis, - Sound background in one or more of Computer Vision like Scene Understanding, Recognition (Face, Iris, Finger, Gesture,)

Strong understanding of Machine Learning techniques

Programming in C / C++ Usage of Mat lab, Open CV toolkits. Experience on embedded / mobile platforms and real-time implementation of complex algorithms Speech Recognition

Should have good experience in speech technologies, ASR/TTS(Text to Speech).

Exposure to speech technology tools like, HTK, Kaldi, Festival

Prior experience in speech technologies (ASR or TTS) is required.

Strong understanding of Machine Learning techniques especially deep learning

Good Programming skills in C, Python & Shell scripting is desirable.

NLP/NLU

Experience with some of the NLP problems, like intent detection, sentiment analysis, NER etc

Strong understanding of Machine Learning techniques especially deep learning

Good Programming skills in C, Python & Shell scripting is desirable. Data Scientist

Experience in devising/enhancing machine learned algorithms and datamining techniques for solving complex Big Data analysis problems, data understanding, and standard tools/languages on machine learning.

Should have worked on standard machine learning and/or data mining techniques.

Hands-on experience in implementing algorithms and very conversant with standard tools/techniques for Big Data analytics —R, Spark/Hadoop etc"
136,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1107&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_620d54d6&cb=1562003722965&jobListingId=3277925290,Data Analyst,Knoema, – Bengaluru,"Responsibilities:

Interpret data, analyze results using statistical techniques and provide ongoing reports.

Locate and define new process improvement opportunities.

Work with management to prioritise business and information needs.

Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.

Filter and - clean- data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.

Acquire data from primary or secondary data sources and maintain databases/data systems.

Identify, analyze, and interpret trends or patterns in complex data sets."
137,https://www.glassdoor.co.in/partner/jobListing.htm?pos=405&ao=453084&s=58&guid=0000016baeac7587be95eddabde7cc60&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_cb4c4f29&cb=1562003666770&jobListingId=3252990320,Data Engineer,Société Générale, – Bengaluru,"
Environment
Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.
SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.
“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.


Mission
Responsibility & Missions

Ensure the proper integration of DFIN data source within the Group datalake according to the scheduled planned
Catch up treatments in case of an anomalies
Analyze feeding anomalies
Communicate on a regular basis production status and inform clients consuming datalake data of any anomaly and resolution
Measure production quality through dedicated KPIs
Participate to platform migration operations
Help new project indefining and setting up new controls
Participate in the enhancement of datalake monitoring tools and build new control capacities




Profile
Expected deliverables



Production process document
Production Dashboard
Production incident follow-up
Action Plan
Communication on production status


Expected skills



Trained on TALEND and the TAC
Notion of Big Data
SQL: medium
ETL: medium (it will help to navigate in TALEND
Linux: Notion
Be oriented toward serving clients



"
138,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2719&ao=437149&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5b904547&cb=1562003865838&jobListingId=3201404836,Solutions Architect - Big Data,Quaero, – Bengaluru,"Quaero: Mission Control for Customer Data

Quaero accelerates data driven teams as they transform disconnected customer data into energized assets.

Marketers and Data-As-A-Product teams use our platform to source and activate information from across their enterprise, turning their unique customer knowledge into bottom line outcomes. We release their data scientists, analysts, and engineers from time consuming data cleansing chores, enabling them to focus on delivering powerful segmentations, predictive models, and concrete additions to the company's data balance sheet. Quaero's customer data platform condenses the time, cost, and risk of building strategic assets while keeping fast moving teams compliant and in firm control of their proprietary data resources.

At Quaero, we consider ourselves business minded adventures. We are collaborative, empowered and accountable. We are driven by intellectual curiosity and the desire to deliver a best in class result.

Position Summary:

The Solution Architect is responsible for on-boarding and supporting our CDP across customers. This position requires strong data modelling and development skills

Integrate large datasets from multi-channel client data (e.g. web, ad delivery, email, app, ecommerce) into the database and make the data available for analytics and reporting. The CDP, once implemented, drives data driven marketing and personalization at scale for our customers

Work with advanced data management frameworks and utilities built on big data and open source technologies including Hadoop, Spark, Scala, Redshift, MS SQL Server. In addition, deploy and support the platform on AWS, GCS, Azure and hosted infrastructure

Ability to learn new database and cloud technologies quickly, analytical thinking, delivering quality results, excellent communication and ability to work in an Agile environment are fundamental to this role

Responsibilities:

Leverage Quaero's CDP to build operational marketing databases for customers across a range of verticals, with focus in retail, financial services and health care

Develop custom extensions to the standard data model where needed, to accommodate customer specific data sources that are not represented within the standard data model, to support analytics, reporting and marketing activation use cases

Productize custom-developed artifacts into the CDP standard data model, where applicable

Take lead role in creating and maintaining database artifacts, technical documents (functional specs, design document, data model) for all custom development

Participate in cross-functional team design and delivery processes with account mgmt., product mgmt., product development and project mgmt.

Provide feedback and ideas on improvements to the CDP feature set and usability- with the aim of continuously improving the implementation process and results.

Responsible for the overall implementation and deployment of Quaero CDP for the client

Experience:

8+ years of database development and support experience in database technologies (E.g. MS SQL Server, Oracle, Hadoop)

Experience in Data Modeling with domain expertise in Banking/Retail/Media

Hands on work in Big Data & Cloud platforms (Hadoop, EMR, Spark, Azure, AWS etc.) is must

Proven success leading end-to-end database solution implementations

Experience in scripting language (Python, Scala etc.) is a plus

Prior experience in Martech stack and working with digital data (E.g. Adobe Analytics) is a plus

Education

Bachelor's degree in technology (Computer Science, Information Science)"
139,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1109&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f702f81e&cb=1562003722966&jobListingId=3273087333,Data Science Researcher,Shell India, – Bengaluru,"Digitalization CoE is a part of Technology organization within Shell’s Projects and Technology, and has about 250 members. Data Science R&D team in India is part of the global Data Science team, and counts ~ 20 members from diverse background (Computer Science, Applied Mathematics/Statistics and different fields of Engineering), equipped with right set of skills to tackle most challenging data related problems in RDS. Our team delivers substantial cash to the RDS bottom line by driving number of successful projects that spans from Shell’s Upstream, Downstream, Chemicals, Integrated Gas business, as well as support to our Trading and Supply business



The position focuses on building capabilities and skills in Data Science R&D to solve targeted problems in Shell's businesses. · The successful candidate will be responsible for applying Data Science algorithms (existing in Linear Algebra, Statistics, Optimization, Machine Learning, Signal Processing, System Identification, etc.) and develop new algorithms while managing & delivering a portfolio of Data Science R&D projects. · The candidate should have demonstrated similar skills in the previous role with tangible publications, reports, presentations or deployed tools. · The candidate is expected to seek out, evaluate, discover and invent new data science methods relevant to above mentioned areas. · The responsibility is also to critically test ideas through the ""fastest route to failure"" and/or to champion & develop algorithms via proof on concept projects which can be executed in two or three months, need be with a synthetic data set. · The successful candidate will coordinate and liaise with different colleagues within Shell including other data science, data engineering teams, process engineering teams and asset / business / IT support teams. · Accountable for technical content and project management; responsible for stakeholder engagement, internal and external. · Research aptitude, including original thinking, capability of problem solving in applying specific tools for business problem solving, end-to-end delivery of technical services, flexibility and technical breadth in learning and applying appropriate tools (from Linear Algebra to Deep Learning, as required by the problem) and working collaboratively across various teams to identify opportunities, frame the right questions and timely delivery are key dimensions to this role. · Ensure Shell’s IP position is secured and extended.
"
140,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1427&ao=437149&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_cf711dc8&cb=1562003752630&jobListingId=3281818625,Specialist; Data Scientist,Merck Ltd, – Bengaluru,Specialist Data ScientistWe are looking for a great data scientist to drive Digital Analytics in our Life Science business You should be able to recommend design and develop state-of-the-art data-driven analysis using statistical advanced analytics methodologies to solve business problems This is a highly visible role within the group as well as across the department - You will be expected to balance strategic thinking with detailed execution and solid cross-functional collaborative results You should be able to thrive in ambiguity - this is a fast-paced environment where every day brings new
141,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2713&ao=140609&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_462869a6&cb=1562003865834&jobListingId=3257522626,Data Engineer(Azure Experience),Accion Labs, – Bengaluru,"Data Engineer Skills We need resources with below skills:1. Python2. Cloud : Microsoft Azure(Must),AWS (Plus to have) Google Cloud3. Spark using Python4. SQL Knowledge.5. Shell Scripting "
142,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1025&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_63507576&cb=1562003715353&jobListingId=3255464346,Data Analyst,Aryaka, – Bengaluru,"Title: Data Analyst / Business Analyst

Job Code: 2119

Location: Bangalore

JOB DESCRIPTION

We are seeking to add a passionate data analyst who would turn data into information, information into insight and insight into business decisions. This professional should have strong analytical skills and be able to think strategically and help the company make better data-driven decisions. If you are results-oriented and have experience working with large amounts of data, consider applying.

RESPONSIBILITIES

The Aryaka Data Analyst (DA) would be responsible for evaluating the performance of the Aryaka Service in every numeric way imaginable and reporting the same at three levels – externally to key customers, internally to Technical Management, and internally to Development and Operations personnel.

Evaluate and report all types of service performance viz. network uptime, downtime, latency, throughput and peak performance, for all kinds of services that Aryaka provides. The DA will work with multiple levels of the technical staff to understand cause and effect, report on network performance, and be a driver of CSI (Continual Service Improvement) in the delivery of the Aryaka Service to our customers.

Be an insightful statistician, work with teams across business functions to understand challenges, and design data driven solutions to optimize and improve performance.

Gather customer-related data viz. M&A, growth, funding, revenue, sales, profit, business needs, competitor offerings etc. from external sources and search engines and predict customer health and possible changes in their dynamics with Aryaka.

Perform ad-hoc analyses that translate into actionable insights. Work cross-functionally with marketing, customer support, delivery, CRM and finance teams to develop BI reports for key functions.

Develop reports and dashboards that would aid in eliminating errors, improving quality and enhancing performance. Visualize and develop BI solutions that help operational teams maximize efficiency and customer satisfaction in day-to-day operations.

Design, create and publish weekly, monthly & quarterly operational reports. Present analyses to the heads of each department periodically.

Contribute to creating quarterly QBR deck for all customers.

Provide research and analysis, strategic insights on key markets, competitors, threats and targets to support business development efforts.

Support the rest of the data team and work together to get the most accurate measurements possible; teach others how to effectively apply the collected data.

Perform market research to allow us to remain a relevant and constantly changing business. Analyse business metrics and trends and make recommendations for continual improvement.

PROFESSIONAL BACKGROUND:

Strong analytical skills, critical thinking, attention to detail, math and statistical skills

Advanced MS Excel (with Power Query and Power Pivot) and SQL

Knowledge of Python/SAS/R and web analytics

Basic programming skills in a compiling language such as Java or C++

Fundamentals of Networking

Excellent communication and presentation skills

3+ years in a statistics, data, or analytical position

MBA (2-5 years experience)/Bachelor’s Degree (5+ years experience) in Computer Science, Information Security, Risk Management, Information Systems, or a related field, or equivalent professional experience.

WHO IS ARYAKA?

Aryaka is the industry leader in managed SD-WAN partnering with global enterprises to spearhead their WAN transformation initiatives. We are growing fast and expanding rapidly both in terms of customer growth as well as employee headcount.

WHY ARYAKA?

Our global private network is transforming how enterprises connect worldwide to deliver enhanced performance for cloud and on-premises applications. Aryaka was named Leading Lights Company of the Year by Lightreading, recognized on LinkedIn’s Top 50 Industry Disruptors list and was named by IHS Markit as a top SD-WAN provider. Aryaka’s SD-WAN as a Service is deployed by more than 800 global enterprises in 63 countries, including the biggest names in almost every vertical, such as Cigna (healthcare), HMS Host (retail), Samsung (manufacturing), and Skullcandy (manufacturing). Aryaka is looking for experienced product marketing and product management professionals to capitalize on its recent momentum, expand market penetration, and drive enterprise sales in the next phase of growth.

HOW TO APPLY:

If interested, please click here to Easy Apply from LinkedIn.

Aryaka Networks, Inc. is an equal opportunity employer. All candidates for employment will be considered without regard to race, color, religion, sex, national origin, physical or mental disability, veteran status, or any other basis protected by applicable federal, state or local law."
143,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2014&ao=717145&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_3ef81642&cb=1562003813152&jobListingId=3143274895,Senior Data Analyst,GSN Games, – Bengaluru,"
GSN Games is looking for an outstanding Senior/Lead Data Analyst to join our team in

Bangalore! Jackpot! About the GSN Games Casino Studio:
Slots, bingo, cards, and more! Work on incredible games, including a top-10 grossing app, alongside the best in the business. 
Are you skilled at solving complex business problems using big data? Do you want to directly impact the strategy and game development of a best-in-class video game company? Would you like to be part of a fun, fast-paced team working in a strong data-driven culture? Then we are looking for you!
What Youll Do:

Work collaboratively with game teams to deliver actionable insights into our games to further increase user acquisition, engagement and monetization using statistical techniques & provide reports Develop data collection systems & strategies to optimize statistical efficiency & data quality/integrity Proactively perform a wide range of analyses to identify/analyse/interpret trends, issues, and opportunities across games and perform competitor analysis Answer business-related questions & generate business reports through exploratory data analyses and ad-hoc reporting Design and implement advanced statistical testing for specific problem-solving needs (e.g. A/B testing)
About You:
· BS in Computer Science, Statistics, Math, Physics or other quantitative discipline. Advanced degrees a plus 
· 6+ years of experience in a data analyst, financial analyst, scientist or similar role performing quantitative, statistical or financial analysis 
· 4+ years experience using SQL, including complex queries from multiple data sources. 
· SQL skills using columnar database like Vertica/Google Big Query/ Amazon redshift 
· 3+ years experience using Python to manage and/or analyse data 
· Experience creating, operating and analysing multiple simultaneous A/B tests 
· Excellent analytic and problem solving skills, including forecasting and performance marketing analysis 
· Strong communication and presentation skills, including extensive use of chart and table tools 
· 2+ years experience creating and writing reports using Tableau or a similar reporting system 
· Passion for speed and large data sets
Bonus Points:

2+ years within the mobile gaming domain. Experience with R, SAS, SPSS, Matlab or other statistical modelling package Experience using Source Control Systems such as SVN or GIT Strong statistical background Involved directly in analysing revenue and customer retention
"
144,https://www.glassdoor.co.in/partner/jobListing.htm?pos=113&ao=438575&s=58&guid=0000016baeab3b5d859691f01cba9a00&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_339c35ca&cb=1562003586325&jobListingId=3203420854,Data Scientist,HP Inc., – Bengaluru,"-Unique mastery and recognized authority on relevant subject matter knowledge including technologies, theories and techniques. Contributes to the development of innovative principles and ideas. Successfully operates in the most complex disciplines, in which the company must operate to be successful. Provides highly innovative solutions. Leads large, cross-division functional teams or projects that affect the organization?s long-term goals and objectives. May participate in cross-division, multi-function teams. Provides mentoring and guidance to lower level employees. Routinely exercises independent judgment in developing methods, techniques and criteria for achieving objectives. Develops strategy and sets functional policy and direction. Acts as a functional manager within area of expertise but does not manage other employees as a primary job function. (TCP review board required in TCP families)Responsibilities: Develops recommendation from complex data and business analyses and formulates them into business plans.Drives the construction of highly innovative statistical and financial models to analyze new aspects of business performance.Establishes the metrics required to measure business performance, and recommends the go-forward strategy to address performance gaps.Leads highly complex, time- sensitive market research projects and identifies compelling trends and opportunities for business leaders.Staffs and manages cross- functional teams across the entire span of business planning activities.Drives all aspects of priority projects and makes final team decisions.Develop business plans and proactively identify new opportunities as partners with client business leaders.Develops and drives comprehensive business plan recommendations, based on analysis, emerging trends, and experience.Identifies or develops cutting- edge analytical tools, models, and methods for making key business decisions.Counsels business leaders, recommends approaches for executing high-level strategies and develops creative solutionsEducation and Experience Required: Typically 10+ years total experience in strategy, planning, operations, finance, or related functional area. Advanced university degree required (e.g., MBA) or demonstrable equivalent experience.Knowledge and Skills: Extensive knowledge of research methodology for the most challenging business issues.Excellent analytical thinking, technical analysis, and data manipulation skills.Ability to leverage new analytical techniques to develop creative approaches and insights.Extensive knowledge of how to analyze business problems using Excel, Access, statistical analysis, and financial modeling.Superior business acumen and technical knowledge within area of responsibility.Excellent verbal and written communication skills, including negotiation and influence skills.Excellent project management skills, including leading large, cross-functional initiatives that impact the organization.Strong relationship management skills, including partnering and consulting.Strong leadership skills, including team-building, conflict resolution, and management.Ability to lead multiple, large, time sensitive projects or work streams.Ability to identify emerging trends from market and industry data, and make clear and compelling business planning recommendations.#LI-POST"
145,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2206&ao=409834&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c59dac03&cb=1562003826188&jobListingId=3143802890,Data Engineer - Sr Elastic Engineer,IBM, – Bengaluru,"Job Description

About IBM IndiaIBM's Purpose is to be essential to our clients, to the world and one another and we are confident that together as IBMers we will drive this purpose. When you join IBM you join a culture of openness, teamwork, trust, and the invitation and expectation to have a voice.

We are recognized gold standard for inclusion, reflected in winning, to name a few, the 2018 Catalyst Award for advancing women in business, the National Award 'Best Employer of People with Disabilities' and being named one of the top 5 2018 Top Companies for Women Technologists for building an inclusive workplace We advocate for fairness and equality as everyone is, and always has been, welcome at IBM.

Join a brand with a history of continuous re-invention, transforming itself throughout its 100-plus years. In the past five decades alone, IBM has ushered in the eras of the mainframe, the personal computer, IT services and enterprise software. In its current transformation, IBM is once again leading the reordering of the technology industry.Business Unit OverviewGlobal Technology Services (GTS) at IBM handles IT infrastructure for some of the worlds leading corporations and with that comes the responsibility of handling enormous amounts of IT data and the opportunity for making better decisions using that data. In GTS analytics team at IBM, Data Scientists, Data Engineers, and BigData IT Architects are developing novel models, cutting edge algorithms, custom analytics solutions to take on BigData challenges in the IT Infrastructure space.

ITOA / AIops provides real time machine-data (log, events, performance, capacity, ITIL data, wire data, etc) analytics solutions that helps customers handle Business Services and handle the quality of the end-user experience


It can tell a client in real time What happened, Why did it happen, Will it happen again and What to do if it happens again? etcKeeps everyone on the same page by looking at the same Business Transaction data and metrics.Keeps the focus on operational data that translate to the business value the application delivers; dive in deeper when appropriate.Identify resolution criteria, assign ownershipTake lessons learned to improve development, test, deployment, and production processesWhat differentiates us in the market place, is our dedication to service quality and customer success. Join us and Do your Best Work Ever


Who you areAs a Data Engineer, you are responsible to monitor and manage successful delivery of the Analytics workstream. You will work with several external clients to verify their capabilities to deliver both direct and indirect business benefits.

If you thrive in a dynamic, reciprocal workplace, IBM provides an environment which will challenge and inspire every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.What you will do


Deploy complex Analytics solutions using Elastic stack and develop machine learning models and convert them into enterprise code by storing the data in elastic search or similar repositories in both on-Premise as well as Cloud platformsWork on structured and unstructured data while deriving the main use case for such a platform for us would be Real-Time Anomaly Detection, Time Series models on IT operations data - logs, metrics, events, wired data, transaction flow, ITIL process related data, knowledge repositories, etcDevelop and deploy various machine learning jobs / models using Elastic ML and custom analytics using Python, Spark, Scala, etcLead end to end deployment for enterprise customersProvide engineering inputs to Architects and Data scientists on various stages of solution designPerform Integration and deployment solution as per design provided by Architects


How well help you grow


Youll have access to all the technical and management training courses to grow your expertise.Youll learn directly from skilled developers in the field; our team leads love to mentor.You will have the opportunity to work in many different areas to figure out really excites you.


We always believe that it is extremely important to have the right person for the right job and you are a perfect fit to this strategy. We want people with an openness and ability to learn and who are ready to put good ideas into action. So, go ahead, and grab the opportunities we wish you great success in your career and encourage you to bring your best self to IBM.


Please Beware...


Of misleading advertisements and fraudsters issuing 'Offer Letters', on behalf of IBM in exchange for a fee. We recommend you to Stay Alert. Read more here http://ibm.co/2fwBkyK. To avoid any instance of fraud, when receiving communication from IBM, look for this authentic IBM e-mail format: XYZ@in.ibm.com. EOM StatementIBM is committed to crafting a diverse environment and is proud to be an equal opportunity employer. You will receive consideration for employment without regard to your race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. We are committed to compliance with all fair employment practices regarding citizenship and immigration stat
Required Technical and Professional Expertise


Minimum 8+ years of experience working on the Elastic based products & distributions specifically used in Real Time ITOA or AIopsExperience in development & implementation of logging and metrics solutions, Real Time Anomaly Detection System & Time Series Modelling or similar solutions like SplunkProficient in IT support (Infrastructure / Application) and IT monitoring tools along with overall core Analytics experience in various domainsDemonstrated ability in Elastic ML & real-time operations analytics using Apache suit of products like Spark using Python or ScalaProven expertise on log analytics, time series data anomaly detection and correlation of events along with the knowledge on GO/grok/REGEX/Logstash/Fluentd to perform Extract, Transform and Load for IT operational data into big data repositories like Elasticsearch, Cassandra, HadoopCertifications showing proficiency in the Usage, design & deployment of ITOA / AIOps solutions like Elastic or Splunk


Preferred Tech and Prof Experience


Experience with DevOps projects, Github, Jira, Travis, etc with knowledge on Windows, Linux and AIX platformsProven ability in top commercial distributions of the above stack MapR; Cloudera; Hortonworks etcEstablished knowledge on other top level Apache Big Data technologies like Cassandra, NIFI, Fluentd, Drill, Sentry etcVerified ability on HDFS & other similar map/reduce paradigmsExpertise in LSTM, RNN, Tensorflow, H2O along with Kubernetes and Containerization, but not mandatoryYou love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologiesAmbitious individual who can work under their own direction towards agreed targets/goals and with creative approach to workIntuitive individual with an ability to manage change and proven time managementProven interpersonal skills while contributing to team effort by accomplishing related results as needed


EO Statement

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
"
146,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2922&ao=437149&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a2f35c67&cb=1562003887234&jobListingId=3201314060,Senior Data Engineer,zeotap, – Bengaluru,"What you'll do:

Create and maintain optimal data pipeline architecture

Assemble large, complex data sets that meet functional / non-functional business requirements

Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies.

Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics

Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs

Keep our data separated and secure across national boundaries through multiple data centers and AWS regions

Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader

Work with data and analytics experts to strive for greater functionality in our data systems

Mentor the team members

What you are:

You have 3+ years of experience in a Data Pipeline, Ingestion and data processing(Batch/Streaming)

You have experience in building and optimizing 'big data' data pipelines, architectures and data sets.

You have knowledge of message queuing, stream processing, and highly scalable 'big data' data stores

You have advanced working experience with SQL(Relational)/NoSQL Data-bases knowledge and experience working with relational/ databases,

You are strong in analytics related to working with unstructured datasets.

You have experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

You have built processes supporting data transformation, data structures, metadata, dependency and workload management.

You have worked with cross-functional teams in a dynamic environment."
147,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2923&ao=133122&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_2e4ea641&cb=1562003887235&jobListingId=3269599658,GCT - Data Engineering Java Developer,Chase, – Bengaluru," GCT Data Engineering

 Developer

Responsibilities

· Design and build scalable

 and resilient technical solutions using Java and BigData frameworks in the

 Hadoop ecosystem

· Work with data services

 team to identify sources of data (both internal and 3rd party) for data

 cleansing / enhancement / enrichment/ data warehouse

· Drive the delivery of

 business value via change programs/projects within the futures & options

 clearing technology group

· Create automated unit

 tests using a Test Driven Development approach

· Develop a strong

 understanding of key functions of clearing, margining & settlements

 within the F&O world.

· Partner with supporting

 tech leads to develop realistic and achievable project estimates

· Analysis and build within

 Control, Stability, Resiliency, Capacity & Performance areas.

· Testing: Unit, SIT &

 UAT planning and management.

· Robust delivery of code

 into the production environment with zero tolerance for post implementation

 issues

· Proactively look to

 develop, implement and further development best practices across the

 group.

· Contribute to quality

 improvement, code reviews, code/architecture standards, code reuse etc.

Qualifications and Skills (Required)

· Relevant University

 degree

· Very Strong problem

 solving, analytical and communication skills (both verbal and written)

· Expert level knowledge of

 core Java (atleast JDK 1.7) with clear understanding of advanced concepts in

 collection framework, garbage collection, multi threading etc.

· Ability to take on

 difficult and complex large scale problems and provide end to end

 solutions

· Ability to build and

 maintain strong relationships with stakeholders in business, operations,

 operate etc.

Qualifications and Skills(Nice to have but highly desirable)

· Hands-on experience

 working with BigData related technologies: Hadoop, HDFS, Map-Reduce, HBase,

 Hive, Spark, Kafka etc. with PROD implementation knowledge and

 troubleshooting experience

· Experience working with

 Maven, Jenkins, Git/Subversion etc.

· Solid understanding of

 database concepts and working knowledge with any of the vendors with atleast

 some exposure to performance tuning

· Experience working with

 related technical frameworks – Spring, JMS, JDBC etc.

· Some experience of

 providing production support in a Level2/Level3 capacity

Java,

 Spring. BigData suite (Hadoop, Kafka, Spark) will be a huge plus.
 Our

 Corporate & Investment Bank relies on innovators like you to build and

 maintain the technology that helps us safely service the world’s important

 corporations, governments and institutions. You’ll develop solutions for a

 bank entrusted with holding $18 trillion of assets and $393 billion in

 deposits. CIB provides strategic

 advice, raises capital, manages risk, and extends liquidity in markets

 spanning over 100 countries around the world.

When you work at JPMorgan Chase & Co., you’re not just working at a

 global financial institution. You’re an integral part of one of the world’s

 biggest tech companies. In 14 technology hubs worldwide, our team of 40,000 

 technologists design, build and deploy everything from enterprise technology

 initiatives to big data and mobile solutions, as well as innovations in

 electronic payments, cybersecurity, machine learning, and cloud development.

 Our $9.5B annual investment in technology enables us to hire people to

 create innovative solutions that will not only transform the financial

 services industry, but also change the world.

At JPMorgan Chase & Co. we value the unique skills of every employee,

 and we’re building a technology organization that thrives on diversity. We encourage professional growth and career

 development, and offer competitive benefits and compensation. If you’re looking to build your career as

 part of a global technology team tackling big challenges that impact the

 lives of people and companies all around the world, we want to meet you.

@2019 JPMorgan Chase & Co. JPMorgan Chase is an equal opportunity and

 affirmative action employer Disability/Veteran. "
148,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2601&ao=4120&s=58&guid=0000016baeaf6082944e1fea2ebd7e93&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_bc01a9d5&cb=1562003857963&jobListingId=2619100525,CPU Architecture Research Scientist, – Bengaluru, – Bengaluru," GCT Data Engineering

 Developer

Responsibilities

· Design and build scalable

 and resilient technical solutions using Java and BigData frameworks in the

 Hadoop ecosystem

· Work with data services

 team to identify sources of data (both internal and 3rd party) for data

 cleansing / enhancement / enrichment/ data warehouse

· Drive the delivery of

 business value via change programs/projects within the futures & options

 clearing technology group

· Create automated unit

 tests using a Test Driven Development approach

· Develop a strong

 understanding of key functions of clearing, margining & settlements

 within the F&O world.

· Partner with supporting

 tech leads to develop realistic and achievable project estimates

· Analysis and build within

 Control, Stability, Resiliency, Capacity & Performance areas.

· Testing: Unit, SIT &

 UAT planning and management.

· Robust delivery of code

 into the production environment with zero tolerance for post implementation

 issues

· Proactively look to

 develop, implement and further development best practices across the

 group.

· Contribute to quality

 improvement, code reviews, code/architecture standards, code reuse etc.

Qualifications and Skills (Required)

· Relevant University

 degree

· Very Strong problem

 solving, analytical and communication skills (both verbal and written)

· Expert level knowledge of

 core Java (atleast JDK 1.7) with clear understanding of advanced concepts in

 collection framework, garbage collection, multi threading etc.

· Ability to take on

 difficult and complex large scale problems and provide end to end

 solutions

· Ability to build and

 maintain strong relationships with stakeholders in business, operations,

 operate etc.

Qualifications and Skills(Nice to have but highly desirable)

· Hands-on experience

 working with BigData related technologies: Hadoop, HDFS, Map-Reduce, HBase,

 Hive, Spark, Kafka etc. with PROD implementation knowledge and

 troubleshooting experience

· Experience working with

 Maven, Jenkins, Git/Subversion etc.

· Solid understanding of

 database concepts and working knowledge with any of the vendors with atleast

 some exposure to performance tuning

· Experience working with

 related technical frameworks – Spring, JMS, JDBC etc.

· Some experience of

 providing production support in a Level2/Level3 capacity

Java,

 Spring. BigData suite (Hadoop, Kafka, Spark) will be a huge plus.
 Our

 Corporate & Investment Bank relies on innovators like you to build and

 maintain the technology that helps us safely service the world’s important

 corporations, governments and institutions. You’ll develop solutions for a

 bank entrusted with holding $18 trillion of assets and $393 billion in

 deposits. CIB provides strategic

 advice, raises capital, manages risk, and extends liquidity in markets

 spanning over 100 countries around the world.

When you work at JPMorgan Chase & Co., you’re not just working at a

 global financial institution. You’re an integral part of one of the world’s

 biggest tech companies. In 14 technology hubs worldwide, our team of 40,000 

 technologists design, build and deploy everything from enterprise technology

 initiatives to big data and mobile solutions, as well as innovations in

 electronic payments, cybersecurity, machine learning, and cloud development.

 Our $9.5B annual investment in technology enables us to hire people to

 create innovative solutions that will not only transform the financial

 services industry, but also change the world.

At JPMorgan Chase & Co. we value the unique skills of every employee,

 and we’re building a technology organization that thrives on diversity. We encourage professional growth and career

 development, and offer competitive benefits and compensation. If you’re looking to build your career as

 part of a global technology team tackling big challenges that impact the

 lives of people and companies all around the world, we want to meet you.

@2019 JPMorgan Chase & Co. JPMorgan Chase is an equal opportunity and

 affirmative action employer Disability/Veteran. "
149,https://www.glassdoor.co.in/partner/jobListing.htm?pos=422&ao=437149&s=58&guid=0000016baeac7587be95eddabde7cc60&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_2ba6b0df&cb=1562003666785&jobListingId=3280482614,Data Scientist,ZestMoney, – Bengaluru,"Responsibilities:

Use of cutting-edge data mining, machine learning techniques.

Use techniques from artificial intelligence/ machine learning to solve supervised & unsupervised learning problems.

Design solutions for complex business problems related to BIG Data by using NLP/ Machine Learning/ Text Mining techniques.

Recommend & implement best practices around application of statistical modelling.

Develop & implement solutions to fit business problems which may include applying algorithms from a standard statistical tool or custom algorithm development.

Requirements:

2 - 7 years of experience in a data scientist/ NLP expert role.

Good with programming languages (R/ SAS/ Python).

Outstanding expertise & research experience in machine learning/ NLP/ Information Retrieval/ Recommender Systems.

Experience with capturing, managing & processing Big Data will be an added advantage.

Familiarity with SQL & other database tools to store, organize, retrieve & manage data for doing analysis.

Experience using machine learning algorithms (for example: Generalized Linear Models, Boosting, Decision Trees, Neural Networks, SVM, Bayesian Methods, time series models, etc)."
150,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2105&ao=132976&s=58&guid=0000016baeaed05a9c74761e75f813aa&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d3613e2e&cb=1562003821196&jobListingId=3241165435,Data Intelligence - Edge Data Engineering - Data Engineer (DIO - Edge),Goldman Sachs, – Bengaluru,"MORE ABOUT THIS JOBThe Data Intelligence organization aims to make data a strategic asset for the enterprise by providing a platform that enables the structuring, management, integration, control, discovery, usage, and governance of our Data Assets. The team leverages a wide variety of cutting edge technologies including Hadoop, HBase, Spark, Apache Beam, Apache Flink, Kakfa, SQL, OLAP platforms, Presto, Hive, Java and Python. Your impact will be to Curate, design and catalog high quality data models to ensure that data is accessible and reliable. Build highly scalable data processing frameworks for use across a wide range of datasets and applications. Provide data-driven insight and decision-making critical to GS’s business processes, in order to expose data in a scalable and effective manner. Understanding existing and potential data sets in both an engineering and business context.RESPONSIBILITIES AND QUALIFICATIONSHOW YOU WILL FULFILL YOUR POTENTIAL• Deploy modern data management tools to curate our most important data sets, models and processes, while identifying areas for process automation and further efficiencies• Evaluate, select and acquire new internal & external data sets that contribute to business decision making• Engineer streaming data processing pipelines• Drive adoption of Cloud technology for data processing and warehousing• Engage with data consumers and producers in order to design appropriate models to suit all needsSKILLS AND EXPERIENCE WE ARE LOOKING FOR• 2-3 years of relevant work experience in a team-focused environment• A Bachelor’s degree (Masters preferred) in a computational field (Computer Science, Applied Mathematics, Engineering, or in a related quantitative discipline)• Working knowledge of more than one programming language (Python, Java, C++, C#, etc.)• Extensive knowledge and proven experience applying domain driven design to build complex business applications• Deep understanding of multidimensionality of data, data curation and data quality, such as traceability, security, performance latency and correctness across supply and demand processes• In-depth knowledge of relational and columnar SQL databases, including database design• General knowledge of business processes, data flows and the quantitative models that generate or consume data• Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts• Independent thinker, willing to engage, challenge or learn• Ability to stay commercially focused and to always push for quantifiable commercial impact• Strong work ethic, a sense of ownership and urgency• Strong analytical and problem solving skills• Ability to collaborate effectively across global teams and communicate complex ideas in a simple mannerPreferred Qualifications• Financial Services industry experience• Experience with the Hadoop eco-system (HDFS, Spark)ABOUT GOLDMAN SACHSThe Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.© The Goldman Sachs Group, Inc., 2019. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet."
151,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1013&ao=4120&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d74a092e&cb=1562003715339&jobListingId=3080076433,Data Engineer,ibibo, – Bengaluru," DescriptionResponsibilities:- Engineer data pipelines (Spark, Kafka-Streams, Flink, Scala) and build data-driven products.  Designing and implementing solutions using open source data engineering tools.  Devops work to keep the Data platform secure, reliable and fast.  Design and develop solutions using data science techniques ranging from statistics, ML and deep learning.  Fork open source projects and enhance them to suite our needs.RequirementsMust haves o 2+ year experience with any JVM functional programming language ( Scala/Clojure ).  o Atleast scripting language ( Python / Javascript ) is must  o Very strong Computer science and distributed computing fundamentals  o Experience with building real time systems using Flink/Kafka streams is must  o Experience with high performance Spark batch applications is must  o Understanding of Lambda architecture ( Connecting realtime with batch ) is must Nice to have Hands-on experience of any OLAP ( Redshift / Druid )  Experience in functional programming  Hands-on experience of Big-data technologies ( Spark, HDFS, S3, Dynamodb,HBase/Cassandra, Zookeeper, Kafka, Kafka connect, Kafka streams, SQS)  Experience of atleast one native language ( C / C++ / Go / Rust )  BenefitsWork with top-notch data team and cutting-edge technologies.  Flexible hours  Open leave policy  Transparent teams  Team Offsites"
152,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1023&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_faad4dcb&cb=1562003715351&jobListingId=3274341577,Analytic Consultant,Wells Fargo, – Bengaluru,"Wells Fargo & Company (NYSE: WFC) is a leading global financial services company with $2.0 trillion in assets and offices in over 37 countries. Founded in 1852 and headquartered in San Francisco, Wells Fargo provides asset management, capital raising and advisory, financing, foreign exchange, payments, risk management, and trade finance services to support customers who conduct business in the global economy. At Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We also value the viewpoints of our team members and encourage them to be their best. Join our diverse and inclusive team where you will feel valued and inspired to contribute your unique skills and experience. We are looking for talented people who will put our customers at the center of everything we do. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you. Learn more at our International Careers website.  Market Job Description  About Wells Fargo Enterprise Global Services  Wells Fargo Enterprise Global Services (WFEGS) enables global talent capabilities for Wells Fargo Bank NA., by supporting over half of Wells Fargo's business lines and staff functions across Technology, Business Services, Risk Services and Knowledge Services. WFEGS operates in Hyderabad, Bengaluru and Chennai in India and in Manila, Philippines. Learn more about WFEGS at our International Careers website.  Department Overview  Independent Risk Management (IRM) is Corporate Risk, which is responsible for independent oversight of risk-taking activities. Strategic enterprise function-aligned leaders in the Corporate Risk organization provide an independent view of horizontal, cross-business risks. Corporate Risk has the ability to stop or modify business activities that exceed our risk appetite, might create unacceptable risk or cause reputation damage, or are contrary to Wells Fargo’s values or expectations. The Wells Fargo EGS (WFEGS) IRM Team provides best in class risk management practices to enhance credit and market risk management, executing on key initiatives and processes across products and lines of business (LOBs). The team delivers increased operational efficiency through committed partnerships, clear communication and disciplined risk practices. The team is an ensemble of rich global talent with strong analytical and innovation capabilities that enables the team support critical company and business initiatives, projects, policies and processes.  Market and Counterparty Risk Management team (MCRM) provides company-wide leadership, support, and oversight for effective understanding and management of market risk across the company. In addition, MCRM is responsible for maintaining a company-wide view of market risk and independently reporting and monitoring market risk exposures against approved risk appetite levels. MCRM calculates, analyzes, and reports market risk regulatory capital; provides inputs for the calculation of counterparty risk capital; measures, monitors, and independently reports market risk; and develops and monitors market risk stress testing results. About the Role The analytics consultant role is responsible for ensuring that the Market Risk data is accurate, valid, received timely and fit for purpose. These goals are accomplished by the execution of a suite of data controls including data element quality checks, reconciliations, data processing exception reporting, and filter management and deep dive analysis. These controls measure, monitor, and report data quality across the data life cycle beginning with onboarding through provisioning to reporting teams. Responsibilities: Perform various activities related to market risk data validation, analysis and reconciliations; supporting key market risk systems, on a daily, weekly, monthly basis.  Perform reconciliations to source (or system of record) and highlight anomalies  Review, report and remediate overnight batch process issues  Issue management reporting and data lineage reporting and Ab Initio data quality reporting  Develop dynamic dashboards; analyze key risk factors to help monitor market and counterparty risk.  Support research, analysis and development of market risk data-fields, data-marts and meta-data  Support market risk data migrations, system transitions, data-mapping, data lineage, data reconciliation and documentation in alignment to policy and governance  Identify opportunities and deliver process improvements, standardization, rationalization and automations  Market Skills and Certifications Essential Qualifications: Over all experience around 4 years in similar role  Graduate degree or higher in a quantitative fields such as applied mathematics, statistics, engineering, finance, economics, econometrics or computer sciences  3+ years of SQL experience  3+ years of VBA experience  Ability to identify in efficiencies and opportunities to improve the process  Strong technical skills and problem solving skills  Strong project management skills with ability to prioritize work, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment  Excellent verbal, written, and interpersonal communication skills  Strong ability to develop partnerships and collaborate with other business and functional areas  Knowledge and understanding of issues or change management processes  Experience determining root cause analysis  Flexibility with changing priorities Desired Qualifications: 4+ years of analytics experience  Experience in gathering, analyzing and interpreting large datasets  Ability to work effectively in a team environment  Ability to communicate effectively with business partners and project managers  Strong analytical skills with high attention to detail and accuracy  Excellent verbal, written, and interpersonal communication skills  We Value Diversity  At Wells Fargo, we believe in diversity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national or ethnic origin, age, disability, religion, sexual orientation, gender identity or any other status protected by applicable law. We comply with all applicable laws in every jurisdiction in which we operate."
153,https://www.glassdoor.co.in/partner/jobListing.htm?pos=601&ao=437149&s=58&guid=0000016baeacb2b0969190d7bbef71ae&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a126ac5d&cb=1562003682447&jobListingId=3201586160,Data Scientist,IQLECT, – Bengaluru,"Requirements

Should have good knowledge of statistics and machine learning techniques

Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value

Should have good problem solving skills

Should have working knowledge or experience with tools such as R, Matlab etc

Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem

Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner

Responsibilities

Selecting features, building and optimizing classifiers using machine learning techniques.

Data mining using state-of-the-art methods.

Extending company’s data with third party sources of information when needed.

Enhancing data collection procedures to include information that is relevant for building analytic systems.

Processing, cleansing, and verifying the integrity of data used for analysis.

Doing ad-hoc analysis and presenting results in a clear manner.

Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications

Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc...

Experience with common data science toolkits, such as R, Matlab, Python related etc.

Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard

Proficiency in using query languages such as R, SQL etc. Experience in Python is plus

Experience with various sdks like mitie, dib, stanford NLP, etc are preferred

Good applied statistics skills, such as distributions, statistical testing, regression, etc.

Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise

We’re looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
154,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1506&ao=148364&s=58&guid=0000016baeade353b462a8951a2c366c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_f876d164&cb=1562003760373&jobListingId=3068374236,Data Science Course Mentor - India (Part-Time/Flexible/Remote),Springboard, – Bengaluru,"The CompanySpringboard is an online learning platform that helps you master in-demand skills through a mentor-led model and project-driven curriculum. The 1-on-1 mentorship supports you with personalized help and career advice from the best experts and keeps you accountable. The project-based curriculum designed with industry experts ensures that you learn skills that matter on the job and have a portfolio you can showcase to employers.Over the last 5+ years, we at Springboard have served 10,000+ learners across the world(>80% in the US).We also raised our Series A of $9.5M in December 2017(with the likes of Allen Blue, Neeraj Arora, Naveen Tewari and marquee VCs as our investors) and have grown our team in SF+ Bangalore to 80+The Opportunity: Springboard runs online, self-paced, Python- and R-based Data Science workshops in which participants learn with the help of a curated curriculum and 1-1 guidance from an expert mentor.Our mentor community - the biggest strength of our programs - comprises experts from the best organizations in the world. Our mentors range from data scientists and researchers at premier companies (Uber, Pandora, LinkedIn, Apple) to a wide variety of top-notch startups and consulting firms.After 5 successful years in the US(serving more than 10,000 learners) we are sprinting to launch Springboard in India. We will be offering job-guarantee programs in Data Science and AI/ML and are looking for mentors who are looking for an opportunity to give back by nurturing the next generation of Data Scientists/AI engineers. If you are as passionate about mentoring as you are about Data Science, and can give a few hours per week in return for an honorarium, we would love to hear from you.The Program:Completely onlineDesigned to take 6-9 months, depending on the courseParticipants in this course are working professionals and college students, interested in getting started with data scienceParticipants learn about Data Science with the help of a curated online curriculum and a personal mentorThey go through the curriculum at their own pace and have a weekly 30-minute check-in with their mentor to discuss questions, projects, and career advice!You: are as passionate about teaching Data Science as about Data Science itselfare that rare combination of programming, statistics and storytelling skillsare proficient in the curriculum topics of at least one of our Data Science Career Track program(taught in Python) are available for weekly, 30-minute video check-ins with students to help them set and achieve learning goals, answer subject matter questions, provide feedback on projects, and career advicehave at least 4 years of experience solving real-life data science problems, and are comfortable working with large datasetsare empathetic and have excellent communication skillsBenefits:Membership in a rich India mentor community of expert mentors from great companies like Flipkart, JP Morgan, KPMG, Zomato and moreMembership in our rich global community of mentors working with top companiesChange the lives of students in our program Help us revolutionize online education!Receive a monthly per-student honorariumWork at your convenienceWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
155,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2210&ao=132919&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5253925b&cb=1562003826193&jobListingId=3279086901,AI Machine Learning Engineer,EY, – Bengaluru,"Intro – Machine Learning Architect (Assistant

Director)

The AI@EY Team is looking for a Machine

Learning Architect with a background in machine learning (ML) and deep learning

(DL) technologies to help design and build cutting edge AI solutions. The AI@EY

Team is creating innovative AI technology and products that will transform EY

and our clients. The successful candidate will be part of a team building

innovative AI solutions that rely on AI and ML techniques including but not

limited to natural language processing, computer vision, deep learning, and

machine learning.

The AI@EY Team is creating a model for how

AI can reinvent large companies, and industries. Through EY’s network of more

than 250,000 professionals working in every sector, we have an opportunity to

offer AI products and services that transform how business is done in all types

of enterprises and to realize the vision of building a better working world.
What You’ll Do

Lead projects spanning machine learning, and high-performance engineering systems to deliver super powers to core business activities
Envision projects in foundational areas of the business using an arsenal of machine learning techniques
Serve as a resource for other individuals on the team-- mentoring junior engineers and advising leaders
Bridge industry and research, keeping the team focused on high-value problems at the cutting edge of emerging trends
Build the team’s profile both internally and externally, attending and presenting at local events

What You'll Need

MS or PhD in CS, EE or related disciplines.
6+ years experience with a track record of shipping high-impact technology projects at a premier technology company
Deep knowledge of and track record of machine learning development (e.g. sequential models, classification, deep learning)
Experience with machine learning infrastructure and shipping models at scale
Experience with big data and cloud based architectures
Ability to communicate complex black-box models to cross-functional stakeholders
Collaborative attitude and experience working in a cross-functional team
Excellent programming and algorithmic skills (we mainly use Java & Python)

Bonus Points for

Depth in NLP and information extraction, particularly experience in multi-language and business documentation
Experience working with data at scale, including experience with some or all of the following: HDFS, Cassandra, Kafka, Flink, Samza, Spark, EMR

"
156,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2722&ao=4341&s=58&guid=0000016baeaf7e9f99ef288f4e6e998e&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_1c9327f9&cb=1562003865840&jobListingId=2905030280,AI Machine Learning Engineer,EY, – Bengaluru,"Intro – Machine Learning Architect (Assistant

Director)

The AI@EY Team is looking for a Machine

Learning Architect with a background in machine learning (ML) and deep learning

(DL) technologies to help design and build cutting edge AI solutions. The AI@EY

Team is creating innovative AI technology and products that will transform EY

and our clients. The successful candidate will be part of a team building

innovative AI solutions that rely on AI and ML techniques including but not

limited to natural language processing, computer vision, deep learning, and

machine learning.

The AI@EY Team is creating a model for how

AI can reinvent large companies, and industries. Through EY’s network of more

than 250,000 professionals working in every sector, we have an opportunity to

offer AI products and services that transform how business is done in all types

of enterprises and to realize the vision of building a better working world.
What You’ll Do

Lead projects spanning machine learning, and high-performance engineering systems to deliver super powers to core business activities
Envision projects in foundational areas of the business using an arsenal of machine learning techniques
Serve as a resource for other individuals on the team-- mentoring junior engineers and advising leaders
Bridge industry and research, keeping the team focused on high-value problems at the cutting edge of emerging trends
Build the team’s profile both internally and externally, attending and presenting at local events

What You'll Need

MS or PhD in CS, EE or related disciplines.
6+ years experience with a track record of shipping high-impact technology projects at a premier technology company
Deep knowledge of and track record of machine learning development (e.g. sequential models, classification, deep learning)
Experience with machine learning infrastructure and shipping models at scale
Experience with big data and cloud based architectures
Ability to communicate complex black-box models to cross-functional stakeholders
Collaborative attitude and experience working in a cross-functional team
Excellent programming and algorithmic skills (we mainly use Java & Python)

Bonus Points for

Depth in NLP and information extraction, particularly experience in multi-language and business documentation
Experience working with data at scale, including experience with some or all of the following: HDFS, Cassandra, Kafka, Flink, Samza, Spark, EMR

"
157,https://www.glassdoor.co.in/partner/jobListing.htm?pos=3009&ao=437149&s=58&guid=0000016baeafe7388a34bfd62b4e5a9a&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_b4946791&cb=1562003892497&jobListingId=3272329907,AI Machine Learning Engineer,EY, – Bengaluru,"Intro – Machine Learning Architect (Assistant

Director)

The AI@EY Team is looking for a Machine

Learning Architect with a background in machine learning (ML) and deep learning

(DL) technologies to help design and build cutting edge AI solutions. The AI@EY

Team is creating innovative AI technology and products that will transform EY

and our clients. The successful candidate will be part of a team building

innovative AI solutions that rely on AI and ML techniques including but not

limited to natural language processing, computer vision, deep learning, and

machine learning.

The AI@EY Team is creating a model for how

AI can reinvent large companies, and industries. Through EY’s network of more

than 250,000 professionals working in every sector, we have an opportunity to

offer AI products and services that transform how business is done in all types

of enterprises and to realize the vision of building a better working world.
What You’ll Do

Lead projects spanning machine learning, and high-performance engineering systems to deliver super powers to core business activities
Envision projects in foundational areas of the business using an arsenal of machine learning techniques
Serve as a resource for other individuals on the team-- mentoring junior engineers and advising leaders
Bridge industry and research, keeping the team focused on high-value problems at the cutting edge of emerging trends
Build the team’s profile both internally and externally, attending and presenting at local events

What You'll Need

MS or PhD in CS, EE or related disciplines.
6+ years experience with a track record of shipping high-impact technology projects at a premier technology company
Deep knowledge of and track record of machine learning development (e.g. sequential models, classification, deep learning)
Experience with machine learning infrastructure and shipping models at scale
Experience with big data and cloud based architectures
Ability to communicate complex black-box models to cross-functional stakeholders
Collaborative attitude and experience working in a cross-functional team
Excellent programming and algorithmic skills (we mainly use Java & Python)

Bonus Points for

Depth in NLP and information extraction, particularly experience in multi-language and business documentation
Experience working with data at scale, including experience with some or all of the following: HDFS, Cassandra, Kafka, Flink, Samza, Spark, EMR

"
158,https://www.glassdoor.co.in/partner/jobListing.htm?pos=508&ao=437149&s=58&guid=0000016baeac946289d87fba82cd68ad&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_cee170f5&cb=1562003674684&jobListingId=3214862752,DATA SCIENTIST, – Bengaluru, – Bengaluru,"Intro – Machine Learning Architect (Assistant

Director)

The AI@EY Team is looking for a Machine

Learning Architect with a background in machine learning (ML) and deep learning

(DL) technologies to help design and build cutting edge AI solutions. The AI@EY

Team is creating innovative AI technology and products that will transform EY

and our clients. The successful candidate will be part of a team building

innovative AI solutions that rely on AI and ML techniques including but not

limited to natural language processing, computer vision, deep learning, and

machine learning.

The AI@EY Team is creating a model for how

AI can reinvent large companies, and industries. Through EY’s network of more

than 250,000 professionals working in every sector, we have an opportunity to

offer AI products and services that transform how business is done in all types

of enterprises and to realize the vision of building a better working world.
What You’ll Do

Lead projects spanning machine learning, and high-performance engineering systems to deliver super powers to core business activities
Envision projects in foundational areas of the business using an arsenal of machine learning techniques
Serve as a resource for other individuals on the team-- mentoring junior engineers and advising leaders
Bridge industry and research, keeping the team focused on high-value problems at the cutting edge of emerging trends
Build the team’s profile both internally and externally, attending and presenting at local events

What You'll Need

MS or PhD in CS, EE or related disciplines.
6+ years experience with a track record of shipping high-impact technology projects at a premier technology company
Deep knowledge of and track record of machine learning development (e.g. sequential models, classification, deep learning)
Experience with machine learning infrastructure and shipping models at scale
Experience with big data and cloud based architectures
Ability to communicate complex black-box models to cross-functional stakeholders
Collaborative attitude and experience working in a cross-functional team
Excellent programming and algorithmic skills (we mainly use Java & Python)

Bonus Points for

Depth in NLP and information extraction, particularly experience in multi-language and business documentation
Experience working with data at scale, including experience with some or all of the following: HDFS, Cassandra, Kafka, Flink, Samza, Spark, EMR

"
159,https://www.glassdoor.co.in/partner/jobListing.htm?pos=214&ao=437149&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1e392558&cb=1562003628515&jobListingId=3214867314,Data Scientist,Near, – Bengaluru,"The Opportunity

Near ingests and houses several terabytes of data every day from various data partners in domains such payments, telecom, real-estate, retail, content publishing etc. Near specializes in blending, managing and analysing large quantities of data and capturing insights within a popular SaaS platform known as AllSpark. The data scientists will be focused on generating quantitative and qualitative insights from the raw data sitting in its big data warehouse. The insights are primarily used by Near clients for branding and marketing their products, making rational and strategic decisions for the company to maximize profitability and improve customer experience.

Tasks include

Developing “core” data science models and capabilities - that power the Near Ambient Intelligence Platform and associated products.

Advanced data analytics include processing structured (payments, telecom, page clicks etc) and unstructured data in multiple formats (text, audio, video) spanning multiple domains including user profile data, geo-spatial data, network data and retail data.

Partner with technology and the business team to build a superior data quality pipeline that will feed the models.

Research and create intellectual property for the company that will benefit Near and its partners.

Use nonparametric and probabilistic models to generate insights keeping in mind the bias- variance trade-off .

Working closely with the Engineering team to “operationalize” and deploy the models.

Mentor/share knowledge of data science with other global members of the Near, document and partner with others as a team to deliver the maximum value for the company.

Understand and prioritize the data science work based on cost effectiveness and leveraging time management skills.

Attend conferences and organize workshops/meet-ups to be in touch with data science community.

Skills

Must have minimum of 3-5 years of industry experience in developing data science models.

Must have completed academic projects in data science experimenting with raw data and generating insights, publications are a plus.

Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.

Skilled at scientific programming languages such as Python, Java, R, Matlab, Clojure and writing deployable code into production.

Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.

Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.

Familiarity with R, Apache Spark (Java, Scala, Python), PyMC3/theano/tensorflow and other scientific python/R modules is a plus.

Need to be comfortable writing code for model building and bootstrap, test and own models through their lifecycle including devJDops and deploying into cloud.

Requirements

We are looking for a data scientist with a Master’s Degree, PhD is preferred.

An ideal candidate must have academic experience and must have published a few research papers.

Overall 6-9 years of experience with at least minimum 3 years working experience on any data driven company/platform.

Candidate is expected to have exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.

Passion for learning new technologies and be up-to-date with the scientific research community."
160,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1214&ao=437149&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_bd46c7aa&cb=1562003730774&jobListingId=3200987665,Data Engineer,Noodle.ai, – Bengaluru,"We are hiring top Data Engineers to join our team.

We are accelerating our growth as our company gains increasing traction in the exciting ""AI for the Enterprise"" market. We are looking for talented technologists who want to be part of a world-class team and bring with them a healthy mix of intellectual curiosity, desire to learn and passion for excellence.

As a Data Engineer, you will collaborate with the Noodle Client Service team, Data Scientists, SW Engineers, and UX Designers, as well as industry-specific experts from our clients. You will be responsible for developing, maintaining, and testing data solutions with a wide variety of data platforms including relational databases, big data platforms and no-sql databases. You will develop various data ingestion & transformation routines to acquire data from external data sources, manage distributed crawlers to parse data from web sources, and develop APIs for secure exchange of data. You will be involved in securing access to the data based on appropriate rights, implementing data quality routines and mechanisms to flag bad data for correction, and building QA and automation frameworks to monitor daily ingestion of data and provide alerts on errors and other problems.

Qualifications:

Must haves



3-6 years of experience with engineering data pipelines
BE/B.Tech or Advanced degree in a relevant field (Computer Science and Engineering, Technology and related fields)
Excellent knowledge of relational databases like SQL Server, PostgreSQL or MySQL
Proficient with writing SQL queries, Stored Procedures and Views
Strong fundamentals in any programming language like C#, Python or Java
Familiarity with any ETL tool like SSIS, Informatica Power Center, Talend or Pentaho
Excellent at writing code to parse JSON / HTML / Javascript etc.
Passion for learning and a desire to grow Noodlers are life-long learners!


Nice to haves



Strong knowledge of what works and what doesn't. This includes common pitfalls and mistakes when designing a data pipeline.
Comfortable working with both high performance on-premises SQL installations and cloud instances.
Familiarity with Hadoop and Spark
Demonstrated energy and passion that extends beyond your field of study Are you a computer engineer who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with you.
Experience with (and excitement for) interdisciplinary collaboration


Want to help shape the future of Enterprise Artificial Intelligence?

Let's noodle."
161,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2002&ao=140609&s=58&guid=0000016baeaeb1559758c2d824602746&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_433aec65&cb=1562003813142&jobListingId=3276894662,Data Engineer - MSBI,Quantiphi, – Bengaluru,"Required Skills:

2+ years hands-on experience in data warehouse projects with MS SQL Server 2008/2012

Bachelor's degree, preferably in Computer Science or equivalent professional experience

Strong SQL writing skills

Hands-on and deep experience with Warehouse schema design

Familiarity with Kimball data warehouse methodology

Experience using Business Intelligence Development Studio (BIDS) to build SSIS packages

Experience in gathering and analyzing business requirements

Understand project-specific requirements, standards, guidelines, and processes

Demonstrated success working in a team-based environment

Good written/oral communication skills

Strong analytical and problem solving skills"
162,https://www.glassdoor.co.in/partner/jobListing.htm?pos=328&ao=437149&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_7e04a93c&cb=1562003656992&jobListingId=3246460149,Data Scientist,Merak, – Bengaluru,"Bengaluru

We are looking for a Data Scientist to join our small team as we build advanced information extraction systems. We are a machine learning company and you will work directly on most of our core products.

You will be one of our first employees. So you need to have a great sense of ownership and commitment. In return, you'll get the opportunity for rapid personal growth as well as for significant impact on the product and long term company culture. We only expect people with some risk apetite to join us.

Skills we are looking for

Proficiency in Python and the OpenCV library

Solid understanding of common deep learning architectures like CNN and LSTMs

Solid understanding of classical machine learning algorithms like regression, random forests, SVMs etc.

Experience of working on real world computer vision projects. A broad familiarity with NLP is expected

Proficiency in deep learning frameworks - primarily TensorfFlow and Keras. Knowledge of Pytorch is a bonus

Comfort with working on Linux/Unix like terminals

Good grasp of basic ProbStats, Linear Algebra, and Calculus

Familiarity with other commonly used data science languages like C++, R, Julia, MATLAB, or Lua is an advantage

High level understanding of software engineering systems and practices - APIs, Databases, containers etc

Roles and Responsibilities

Experiment and implement new algorithms as we iteratively automate every single user interaction in our products

Own feature specific data pipelines from collection to cleaning to training to deployment

Own feature specific algorithms and deep learning models

Work with clients (sometimes on-site) to make customizations to our base products

Make incremental improvements to our existing systems

Qaulifications

Bachelor’s or a master’s degree in a related field, or an intriguing reason for not having one.

Personality Traits and Fit

Willingness to experiment with and learn and teach new technologies on the job.

Resourcefulness, which in case of a small startup like us can often be the difference between death and riches.

Leadership skills to nurture a team as we grow.

Need (yes, you read that right) to solve head-scratching challenges and a passion for getting things done.

reach out to us at pratyush@merak.ai with your resume and a strong reason for why you would like to join us

Who are we ?

We are a couple of engineers who set out to help businesses harness the power of deep learning and artificial intelligence. Early into our journey, we realized the raison d'être (read reason for existence) of technology. We strongly believe technology exists to help humans save time, money and most importantly effort. We stand by this firmly and through Merak.ai are relentlessly pursuing it.

Between the both of us we have extensive experience across Data Science, Product Development, Consumer Technology, Computer Vision, Machine Learning and Management Consulting. Eager to learn, quick to adapt and open to admitting mistakes, we are always willing to go the extra-mile to get things right. Easily excited by anything that is remotely technical and challenging, we challenge each other in new and different ways to be better than what we were yesterday.

Besides our love for technology and building great products, we are pious followers of Manchester United, Twitter, and Reading. If you are so inclined, we’d love for you to join us in kicking a ball around in Bengaluru."
163,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1417&ao=457171&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_80e84f81&cb=1562003752618&jobListingId=3281446325,Data Engineering Manager,Amazon, – Bengaluru,"Does the prospect of building large-scale extensible solutions to process Amazon scale data excites you? Do you want to create the next-generation tools for intuitive data access? Amazon's Retail Business Services (RBS) tech team needs a Data Engineering Manager to lead a team of BI and Data Engineers.

Amazon strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce platform. Amazon RBS team is responsible for many business critical programs in the Retail business to increase the available selections, reduce customer impacting defects in our content, and improve vendor profitability and relationships. Analytic dashboards and reports built on our data and data processing infrastructure are critical for the Business and operations team day to day functioning.

We are looking for a seasoned data engineering manager to build and continuously evolve the next gen data platform to process and report petabyte scale data from RBS systems, our catalog, and various other interfacing systems. You will work with the business and operations leaders and with other Amazon engineering teams to plan, design, execute and implement this platform. You will be responsible to manage a team of data and BI engineers, and apply solid task and people management skills to build a strong team. You will drive ongoing development of standard operating procedures and continuously raise the bar of team operations.

The ideal candidate will have prior experience in managing multiple Data Engineers & Business Intelligence Engineers, owning critical customer deliverables, lot of experience in heterogeneous technologies in DW space (map/reduce, columnar DBs etc.,). You should be capable of technical deep-dives, and have business acumen to partners with business to identify strategic opportunities where improvements in data infrastructure creates outsized business impact. Most importantly, you should be passionate about data and analytic.

Basic Qualifications

· Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).

· 6+ years of relevant experience in building DW/BI systems

· At least 2 years of experience in leading teams

· Demonstrated ability in data modeling, ETL development, and Data warehousing.

· Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)

· Strong technical and analytical aptitude; Excellent oral and written communication skills.

Preferred Qualifications

· Experience in building large scale DW/BI systems for internet companies

·

· Experience with AWS services including S3, Redshift, EMR and RDS.

·

· Proficiency in one or more scripting languages E.g. Python

· Machine Learning and Predictive Analytics
"
164,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2520&ao=437149&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_c2e64ebb&cb=1562003849876&jobListingId=3265294459,Machine Learning Engineer (Contract Role),LogMeIn, – Bengaluru,"Requirements:

Graduate in computer science/ Information systems Engg with min 3 years of product development experience.

Candidates having experience in ML / ML Classification would be preferred.

Hands-on knowledge on Python-flask, C#, ASP.NET Core MVC, Entity Framework.

Experience in NodeJS, SQL DB, Azure storage would be a plus.

Knowledge of cloud deployment, docker, Azure DevOps would be added advantage.

Excellent skills in communication and collaboration."
165,https://www.glassdoor.co.in/partner/jobListing.htm?pos=209&ao=437149&s=58&guid=0000016baeabe00eb1d9532564c807a6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d0c6ab70&cb=1562003628511&jobListingId=3279325855,Data Scientist,Myntra / Jabong, – Bengaluru,"Responsibilities:

Lead and Own the Thought Process on one or more of our core Data Science problems e.g. Product Clustering, Intertemporal Optimization, etc.

Actively participate and challenge assumptions in translating ambiguous business problems into one or more ML/optimization problems.

Implement data-driven solutions based on advanced ML and optimization algorithms to address business problems.

Research, experiment, and innovate ML/statistical approaches in various application areas of interest and contribute to IP.

Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring).

Deploy, maintain, and debug ML/decision models in production environment.

Analyze and assess data to ensure high data quality and correctness of downstream processes.

Define and own metrics on solution quality, data quality and stability of ML pipelines.

Communicate results to stakeholders and present data/insights to participate in and drive decision making.

Requirements:

Bachelors or Masters in a quantitative field from a top tier college.

Minimum of 3+ years experience in a data science role in a technology company.

Solid mathematical background (especially in linear algebra, probability theory, optimization theory, decision theory, operations research).

Familiarity with theoretical aspects of common ML techniques (generalized linear models, ensembles, SVMs, clustering algos, graphical models, etc.), statistical tests/metrics, experiment design, and evaluation methodologies.

Solid foundation in data structures, algorithms, and programming language theory.

Demonstrable track record of dealing with ambiguity, prioritizing needs, bias for iterative learning, and delivering results in a dynamic environment with minimal guidance.

Hands-on experience in at least one of the focus areas of WyngCommerce Data Science team: Product Clustering, Demand Forecasting, Intertemporal Optimization, Reinforcement Learning, Transfer Learning.

Good programming skills (fluent in Java/Python/SQL) with experience of using common ML toolkits (e.g., sklearn, tensor flow, keras, nltk) to build models for real world problems.

Computational thinking and familiarity with practical application requirements (e.g., latency, memory, processing time).

Experience using Cloud-based ML platforms (e.g., AWS Sagemaker, Azure ML), Cloud-based data storage, and deploying ML models in product environment in collaboration with engineering teams.

Excellent written and verbal communication skills for both technical and non-technical audiences.

(Plus Point) Experience of applying ML / other techniques in the domain of supply chain - and particularly in retail - for inventory optimization, demand forecasting, assortment planning, and other such problems.

(Nice to have) Research experience and publications in top ML/Data science conferences.

Skills: Optimization, Linear Algebra, Time Series Analysis, Algorithms & Data Structures, Machine Learning Data Science Python R."
166,https://www.glassdoor.co.in/partner/jobListing.htm?pos=925&ao=437149&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_9e37551c&cb=1562003705665&jobListingId=3245195924,Senior Data Scientist,Walmart Labs, – Bengaluru,"We are looking for savvy Data Scientists to join our growing team. They will be responsible for solving complex big-data problems in the display advertising space using data mining, machine learning, statistical analysis and computational economics. The right candidates will have strong depth and breadth knowledge in machine learning, data mining and statistics, reasonable programming and design skills to manipulate unstructured and big data and be able build prototypes that work on massive datasets. They should be able to apply business knowledge to perform broad data analysis as a precursor to modelling and to provide valuable business intelligence.

Requirements:

5+ yrs Experience.

Experience using data intelligently to optimize product performance.

Experience performing analysis on raw event data in modern data warehouse systems.

Deep understanding of data platforms in which you've previously worked.

Good understanding of how to grow and shape data tools and datasets to improve data-driven decision making.

Ability to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact.

Solid experience with Python (preferred) and/or R."
167,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1008&ao=437149&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_76e84336&cb=1562003715329&jobListingId=3268925302,Senior business data analyst,Brillio, – Bengaluru,"Senior business data analyst(Job Number: R00018229)

Description



Define and Document Business Rules, Includes: ownership, intended use, LOVs, data quality tests/business rules. - Identify & document the data standards that drive the respective functional business processes / Enterprise Data Model. - Assess Impact to Data maintenance Procedures - Create / Update Data maintenance Procedures - Develop post go live process for handling errors - Strong understanding of data and data rules - Hands-on with SQL and comfortable working in ambiguous situations - Knowledge of R and Python is a plus

Primary Location: IN-KA-Bangalore

Employee Status: Regular

Job Type: Standard"
168,https://www.glassdoor.co.in/partner/jobListing.htm?pos=926&ao=437149&s=58&guid=0000016baead0d9c95b34544170600ca&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_0e03930c&cb=1562003705666&jobListingId=3257046720,Lead Data Scientist,Head Digital Works, – Bengaluru,"Responsibilities:

Identify use cases in the sports domain, especially cricket.

Understand the sports domain, especially cricket, to identify use cases where analytics can play a major role.

Collaborate with various teams - tech, product, business, data warehousing, etc. to make sure there is an organisational alignment in solving the data science goals for business.

Preparing data sets specific to the use cases, process and transform the data to build predictive models, test the model performance, evaluate the model parameters and rebuild the model using new/improved variables, etc.

Map the results to KPIs and track the performance of the model and communicate the findings to the stakeholders - track the whole problem journey and understand how models have improved the existing problem.

Requirements:

Strong analytical and logical thinking.

7-8 Years of experience in building data science solutions (end to end).

Understanding of the sports domain, especially cricket.

Hands on experience (min. 5 years) working with complex analytical tools, such as Python or R.

Hands on experience in building models using a wide variety of algorithms - regression, classification, deep learning, text-based analytics such as NLP, LDA, etc.

Experience with data visualisation tools, such as Tableau/Spot fire/Qlikview."
169,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1523&ao=4120&s=58&guid=0000016baeade353b462a8951a2c366c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ed2a2d1b&cb=1562003760388&jobListingId=2757882786,Data Engineer,T&VS, – Bengaluru,"Job Description / Responsibilities


Build workflows to ensure data extraction quality and storage into our backend data storeArchitect, build and train ML/AI models that can predict outcomes and report on anomalies.Design data pipelines to perform ETL on content/data from multiple types of source systems.Create data analytics views using RDBMS/Key-Value stores, on private and public/cloudCreate software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:

2+ years of software development with Python2+ years of SQL (MySQL/Postgres) and Key-Value databases1+ years of experience with scikit2+ years of experience in data extraction, data transformation using custom Python/JavaExperience working with MapReduce/Hadoop/kafka/Elastic stackExperience with Node backend and React/ReduxExperience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stackExperience in testing or test driven developmentExperience with Data science and Machine Learning algorithm development

Location:

Hyderabad/Bangalore

Package:

Highly competitive to match experience and capability
"
170,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1421&ao=444236&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_1af7123a&cb=1562003752621&jobListingId=3275043430,Sr QA Data Engineer,Honeywell, – Bengaluru,"QA Data Engineer

Honeywell is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data/analytics, Internet of things, and design thinking. We are leading change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. Honeywell IT is at the forefront of this change and we are looking for a team member who thrives on challenging the status quo, embraces new technology and intelligent risk taking, has passion for innovation, is results-oriented and excels in a fast-paced environment.JOB ACTIVITIES We are looking for a Quality Assurance Data Engineer that will develop and execute tests (manual and automated) to ensure extracted and transformed data is loaded accurately from various sources (3rd party, Enterprise Analytics, IoT, internal) to the destination in the Honeywell Sentience platform (Hadoop and other MPP). The QA Data Engineer will check Data Validity, Data Accuracy, and perform Metadata Testing. The QA Data Engineer will also be responsible for assuring Data Integrity and Data Completeness in the landing, staging and publishing layer. The QA Data Engineer will plan, coordinate, and execute testing activities on critical data sets for the Honeywell business.· Review and understand business requirements and technical designs for data pipelines (ETL) and models in the Sentience platform.

· Create comprehensive test plans and test cases for testing data pipelines for multiple storage solutions, including distributed platforms such as Hadoop and MPP databases

· Plan, coordinate, and execute testing activities; Identify, record, and track defects

· Design, develop, and execute automation scripts for ETL & Data Storage Testing

Perform thorough regression testing when defects are resolved

YOU MUST HAVE:

· Bachelor’s degree in Computer Science or related field

· 4-5 years working experience in quality assurance, preferably on ETL / Data Warehouse

· Strong knowledge of QA methodologies, tools, and processes

· Experience in writing comprehensive test plans and test scripts

· Hands-on experience with automated testing tools

· Data extraction/modeling experience

· Experience with complex SQL and scripting (Perl, Python, Java etc.)

· Experience using the Hadoop ecosystem (Spark, Hive, NiFi, Informatica BDM, Sqoop, Flume, etc.)

· Ability to communicate effectively with both technical and non-technical team members

WE VALUE:

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Experience working with remote and global teams

· Experience with the Agile development methodologybody {

 font-family: 'Honeywell Sans Book', Arial, sans-serif;

}

Sr QA Data Engineer

Deliver business value through Right and Fast partnershipQA Data Engineer

Honeywell is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data/analytics, Internet of things, and design thinking. We are leading change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. Honeywell IT is at the forefront of this change and we are looking for a team member who thrives on challenging the status quo, embraces new technology and intelligent risk taking, has passion for innovation, is results-oriented and excels in a fast-paced environment.JOB ACTIVITIES We are looking for a Quality Assurance Data Engineer that will develop and execute tests (manual and automated) to ensure extracted and transformed data is loaded accurately from various sources (3rd party, Enterprise Analytics, IoT, internal) to the destination in the Honeywell Sentience platform (Hadoop and other MPP). The QA Data Engineer will check Data Validity, Data Accuracy, and perform Metadata Testing. The QA Data Engineer will also be responsible for assuring Data Integrity and Data Completeness in the landing, staging and publishing layer. The QA Data Engineer will plan, coordinate, and execute testing activities on critical data sets for the Honeywell business.· Review and understand business requirements and technical designs for data pipelines (ETL) and models in the Sentience platform.

· Create comprehensive test plans and test cases for testing data pipelines for multiple storage solutions, including distributed platforms such as Hadoop and MPP databases

· Plan, coordinate, and execute testing activities; Identify, record, and track defects

· Design, develop, and execute automation scripts for ETL & Data Storage Testing

Perform thorough regression testing when defects are resolved

YOU MUST HAVE:

· Bachelor’s degree in Computer Science or related field

· 4-5 years working experience in quality assurance, preferably on ETL / Data Warehouse

· Strong knowledge of QA methodologies, tools, and processes

· Experience in writing comprehensive test plans and test scripts

· Hands-on experience with automated testing tools

· Data extraction/modeling experience

· Experience with complex SQL and scripting (Perl, Python, Java etc.)

· Experience using the Hadoop ecosystem (Spark, Hive, NiFi, Informatica BDM, Sqoop, Flume, etc.)

· Ability to communicate effectively with both technical and non-technical team members

WE VALUE:

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Experience working with remote and global teams

· Experience with the Agile development methodologyKey Responsibilities
 QA  Hadoop
QA Data Engineer

Honeywell is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data/analytics, Internet of things, and design thinking. We are leading change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. Honeywell IT is at the forefront of this change and we are looking for a team member who thrives on challenging the status quo, embraces new technology and intelligent risk taking, has passion for innovation, is results-oriented and excels in a fast-paced environment.JOB ACTIVITIES We are looking for a Quality Assurance Data Engineer that will develop and execute tests (manual and automated) to ensure extracted and transformed data is loaded accurately from various sources (3rd party, Enterprise Analytics, IoT, internal) to the destination in the Honeywell Sentience platform (Hadoop and other MPP). The QA Data Engineer will check Data Validity, Data Accuracy, and perform Metadata Testing. The QA Data Engineer will also be responsible for assuring Data Integrity and Data Completeness in the landing, staging and publishing layer. The QA Data Engineer will plan, coordinate, and execute testing activities on critical data sets for the Honeywell business.· Review and understand business requirements and technical designs for data pipelines (ETL) and models in the Sentience platform.

· Create comprehensive test plans and test cases for testing data pipelines for multiple storage solutions, including distributed platforms such as Hadoop and MPP databases

· Plan, coordinate, and execute testing activities; Identify, record, and track defects

· Design, develop, and execute automation scripts for ETL & Data Storage Testing

Perform thorough regression testing when defects are resolved

YOU MUST HAVE:

· Bachelor’s degree in Computer Science or related field

· 4-5 years working experience in quality assurance, preferably on ETL / Data Warehouse

· Strong knowledge of QA methodologies, tools, and processes

· Experience in writing comprehensive test plans and test scripts

· Hands-on experience with automated testing tools

· Data extraction/modeling experience

· Experience with complex SQL and scripting (Perl, Python, Java etc.)

· Experience using the Hadoop ecosystem (Spark, Hive, NiFi, Informatica BDM, Sqoop, Flume, etc.)

· Ability to communicate effectively with both technical and non-technical team members

WE VALUE:

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration

· Experience with visualization software (Tableau, Spotfire, Qlikview, Angular js, D3.js)

· Experience working with remote and global teams

· Experience with the Agile development methodologyAdditional Information



JOB ID: req191085
Category: Engineering
Location: HW Camp II,Bldgs 9A&9B,Plot C2,RMZ Ecoworld,Varturhobli, Sarjapur Marathahalli Outer Ring Road, Bangalore, KARNATAKA 560103 IND
Exempt


Honeywell Technology Solutions"
171,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1115&ao=409834&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_4ad63741&cb=1562003722971&jobListingId=3247606465,Data Engineer: Enterprise Content Management,IBM, – Bengaluru,"Introduction

Your Role and Responsibilities

You and IBM IndiaIBM's Purpose is to be essential to our clients, to the world and one another and we are confident that together as IBMers we will drive this purpose. Joining IBM is about joining a culture of openness, teamwork, trust, and the invitation and expectation to have a voice. Join us and Do your Best Work Ever.

IBM is recognized gold standard for inclusion, reflected in winning, to name few, the 2018 Catalyst Award for advancing women in business, the National Award Best Employer of People with Disabilities and being named one of the top 5 2018 Top Companies for Women Technologists for building an inclusive workplace We advocate for fairness and equality as everyone is, and always has been, welcome at IBM.

We at IBM Global Business Services (GBS) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process management, supported by the industry's most sophisticated outcome-based delivery model. All designed to be the Digital Reinvention partner for leading clients across the world - providing value-led and asset-powered end to end solutions.

With a global footprint in over 170 countries, we are empowering clients to build upon their tremendous heritage in Application Innovation processes and also transform them to a Cloud, Cognitive and Social centric world. With skills across six sectors and 17 industries, all major service lines and competencies, IBMs GBS is a promising business unit in itself to be a part of.

Through our unique global delivery network; IBM offers global expertise coupled with a deep understanding of local capabilities, markets and cultures you could be part of and partner on some great projects with some of the best corporations in the world across geographies.

Your day in the role will include...

Mentor or coach for scrum teamsExpert into Agile Scrum principals, Task meeting/RetrospectiveProven in Relative estimation, Story-based developmentProficient in leading Iteration/sprint planning meeting, Conflict ResolutionStrong into Business Analysis planning and monitoring, Enterprise Analysis, Requirement management and communicationProvide objective guidance without personal or political considerationsExperienced in implementing agile techniques in different cultures and environments

You will come with...

Focus on people and Improvement by providing team a platform for improvement not only during the retro but all the time. Create a safe environment for healthy conflict and meaningful collaboration.Experience to provide training to the team on the agile methodologies Implement the winning strategy according as per the ground conditions.Agile processes in each sprint at user story level as per the Definition of Done (DoD).Successfully run agile projects of varying size and complexityIdentify project risks and raise them dedicatedlyAgile process during the project execution; (on the ground to answer all the questions immediately).

How well help you grow:

Youll have access to all the technical and management training courses that will help youYoull learn directly from guide developers in the field; our team leads love to mentorYou have the opportunity to work in many different areas to identify what really excites you


Required Professional and Technical Expertise

The candidate should have good experience in the FileNet Platforms (4.5, 5.1, 5.2 & 5.5 etc) with experience in IBM Case Manager IBM Content Manager tools. The candidate should have good experience in scripting on Filenet using scripting languages such as Ansible, bash script etc. Should have experience in Filenet upgrade activities. Should be proficient in designing, developing and supporting application solutions using FileNet Content Management. FileNet Content Management addresses steps for developing a content strategy for an application with content assets that need to be managed and organized: identifying and promoting content and asset management to manage the infrastructure to store, access, and manage a full spectrum of digital information.

Preferred Professional and Technical Expertise


IBM Filenet


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM

About IBM

Location Statement

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
"
172,https://www.glassdoor.co.in/partner/jobListing.htm?pos=304&ao=437149&s=58&guid=0000016baeac4ef49bf2ad7919214954&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_914f057f&cb=1562003656967&jobListingId=3279509445,Data Scientist,Educational Initiatives, – Bengaluru,"Role and Responsibilities

Data mining using state-of-the-art methods

Processing, cleansing and verifying the integrity of data used for analysis

Extending companys data with third party sources of information when needed

Enhancing data collection procedures to include information that is relevant for building analytic systems

Doing ad-hoc analysis and presenting results in a clear manner

Selecting features, building and optimizing classifiers using machine learning techniques

Productionize models and integrate as features to specific products

Creating automated anomaly detection systems and constant tracking of its performance

Develop a strong mechanism to continuously improve data collection and storage process ensuring data consistency and quality

Must have

Hands on experience with any statistical analysis environments such as R, Python

Proficient in Microsoft office

Familiarity with significance testing, sampling, descriptive statistics, Bayesian models and multivariate statistics

Comfortable with relational and non-relational databases and API development

Education

Must have an engineering degree from Tier -1 institute preferably with coursework in operation research, statistics, machine learning or programming

Hands on Experience with any statistical analysis environments such as R, Python

Proficient in Microsoft office

Familiarity with significance testing, sampling, descriptive statistics, Bayesian models and multivariate statistics

Comfortable with relational and non-relational databases and API development

2-4 years of experience in the analytics domain"
173,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1210&ao=437149&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_50f55fc6&cb=1562003730766&jobListingId=3201207012,Data Engineer,NIRA, – Bengaluru,"Responsibilities:

Build systems that ingest, process, map and analyze core data.

Build data infrastructure solutions that'll deliver data for multiple use cases: reporting, credit risk analysis, collection analysis, engagement, demand prediction and more.

Write scrapers to automate and optimize the use of publicly available information.

Build systems for rapid ingestion and integration of new data sources.

Requirements:

Experience modelling data in SQL and NoSQL databases.

Experience with NLP techniques applied to scraping and data transformation tasks.

Experience working with DynamoDB and other noSQL databases.

Familiarity with AWS Lambda micro-services architecture is preferred.

Familiarity with NLP techniques and graph analysis is preferred."
174,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1607&ao=437149&s=58&guid=0000016baeae10d6a5800c7f504ba34c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_0d7d396e&cb=1562003772044&jobListingId=3201547800,Research Data Scientists,Sequretek, – Bengaluru,"Position title

Research Data Scientists

Job Location

Bangalore

About us & Vision

Sequretek Research Lab, core research centre of Sequretek, is seeking passionate researchers to tackle a variety of problems that impact the bleeding edge of machine learning and artificial intelligence, with a focus on applications in computer security. We’re developing a team by drawing from the research fields in statistics, computer science, mathematics and related fields preferably with a base of Security to help us achieve these goals

Why Sequretek?

You will be part of a highly visible, agile team working on critical problems that directly affect the company’s success. Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry. As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Experience



The Lab is based out of Bangalore, India
MS. in computer science, statistics, or applied math
4-12 years of experience applying statistical/ML algorithms and techniques to real-world data sets
Expert knowledge of languages such as R or Python
Proficiency in Probability, Statistics and Linear Algebra
Familiarity with Data science platforms, Tools and frameworks
Designs scalable processes to collect, manipulate, present, and analyse large datasets in a production-ready environment
Experience with large volumes of data, algorithms, and prototyping
Strong written and oral skills (in English)
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc


Key Responsibilities



Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets

Position: Research Data Scientists

Name*

Email*

CV & Documents*

Add file

(Doc or PDF files only)



Required fields


Phone

Send Application

Thank you for submitting your application. We will contact you shortly!"
175,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2321&ao=4120&s=58&guid=0000016baeaf02b2ab5fbd2932bb3fa0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_85914b21&cb=1562003834809&jobListingId=3167078147,Data Engineer (Funding Circle), – Bengaluru, – Bengaluru,"Position title

Research Data Scientists

Job Location

Bangalore

About us & Vision

Sequretek Research Lab, core research centre of Sequretek, is seeking passionate researchers to tackle a variety of problems that impact the bleeding edge of machine learning and artificial intelligence, with a focus on applications in computer security. We’re developing a team by drawing from the research fields in statistics, computer science, mathematics and related fields preferably with a base of Security to help us achieve these goals

Why Sequretek?

You will be part of a highly visible, agile team working on critical problems that directly affect the company’s success. Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry. As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Experience



The Lab is based out of Bangalore, India
MS. in computer science, statistics, or applied math
4-12 years of experience applying statistical/ML algorithms and techniques to real-world data sets
Expert knowledge of languages such as R or Python
Proficiency in Probability, Statistics and Linear Algebra
Familiarity with Data science platforms, Tools and frameworks
Designs scalable processes to collect, manipulate, present, and analyse large datasets in a production-ready environment
Experience with large volumes of data, algorithms, and prototyping
Strong written and oral skills (in English)
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc


Key Responsibilities



Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets

Position: Research Data Scientists

Name*

Email*

CV & Documents*

Add file

(Doc or PDF files only)



Required fields


Phone

Send Application

Thank you for submitting your application. We will contact you shortly!"
176,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1206&ao=437149&s=58&guid=0000016baead6f72aa0ae4156a657a80&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_99aff67d&cb=1562003730763&jobListingId=3201191412,Data Scientist (Senior Analyst - TDIM),JLL, – Bengaluru,"#JLLTechAmbitions

Duties & responsibilities

Use various ML/AI techniques to build Actionable Insights derived from customer and internal database

Build ML models based on various techniques such as Classification, Clustering, Regression, and Prediction

Work with Product Manager to discuss and identify data needs and uses cases

Exploration of different forms of data to identify patterns and provide actionable insights

Manage deployment of ML models from research to production environments

Evaluate various techniques such as Deep Learning, Reinforcement Learning, Statistical analysis and NLP that can be applied to solve use cases

Ensuring that rigorous design and development practices are followed in the design of models

Implement techniques such as offline learning, online learning, zero shot learning, etc. to continuously improve the accuracy of the models

Plan and participate in Sprint activities such as Sprint Planning, Spring Backlog grooming, roadmap discussions, etc.

Estimate stories/tasks based on a prioritized backlog

Key skills

Strong knowledge of Statistical and Mathematical foundations required for ML

Production experience with building and deploying ML models

Experience with ML techniques such as NLP, Time-Series, Clustering, Classification, and Regression

Experience with tools such as Tensor Flow, skit-learn, Keras, R, Pytorch, etc

Strong development experience in Python

Experience with implementation of data cleansing and normalization techniques

Ability to compare models for Generalization and Bias as related to use cases

Experience in build automation tools

Experience in working with Container Management/Orchestration Systems such as Kubernetes, Apache Mesos, AWS ECS, etc

Experience with Stream Analysis and ML with tools such as Spark, Apache Flink, etc

Experience with one or more public clouds (AWS, GCP, Azure)

Employee specification

Bachelors degree in Electronics & Communication Engineering or Computer Science discipline. Advance degree preferred.

5+ years experience as a Data Scientist with 3 years in a production environment

Capability to self-learn new software applications and programming languages.

Effective written and verbal communication skills, including technical writing.

Excellent technical, analytical and organizational skills. Project management skills desired."
177,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2521&ao=433315&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_6ace8110&cb=1562003849877&jobListingId=3140638486,Marketing BI Data Modeler,Hewlett Packard Enterprise, – Bengaluru,"At Hewlett Packard Enterprise (HPE), we live by three core values that drive our business: Partner. Innovate. Act. These values combine to help us create important work all over the world to advance how people live and work.

HPE makes Hybrid IT simple. HPE helps customers to design the right mix of Hybrid IT to serve their unique needs. We bring next generation infrastructure that uses intelligent software to simplify and accelerate the delivery of new apps, services and business insights. Providing with new ways to deliver and manage IT on-premises and in the cloud.

Applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a team or project leader providing direction to team activities and facilitates information validation and team decision making process. Exercises independent judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to make decisions on complex business issues.

Education and Experience

BA or BS in Communications, Marketing, Business Administration or field relevant to subject matter.5+ years of experience in marketing technology/automation, information technology (as a BI or data analyst).

Knowledge and Skills

Strong experience with BI data design and development (QlikView preferred)Superior knowledge of relational databases and data modelingHigh organizational and project management skillsExceptional analytical and time management skillsExcellent ability to translate client requirements into effective solutionsSound ability to interact with end users and craft clear technical requirements from business languageSolid writing and editing skills some peer or manager edits typically needed.Solid organization and program management skills. Ability to link communications plans and activities to business results.

We offer:

• A competitive salary and extensive social benefits

• Diverse and dynamic work environment

• Work-life balance and support for career development

• Want to know more about HPE? Then lets stay connected!

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1042685"
178,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1604&ao=272234&s=58&guid=0000016baeae10d6a5800c7f504ba34c&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_396815cd&cb=1562003772041&jobListingId=3240242488,Lead Data Analyst,AIG, – Bengaluru,"Functional Area:OP - OperationsEstimated Travel Percentage (%): Up to 25%Relocation Provided: NoAIG ANALYTICS & SERVICES PRIVATE LIMITEDJob Description

Job Title: Lead Data Analyst/Scientist, Data Analytics and Monitoring – Global Compliance Group, Bangalore, India

Estimated Travel Percentage (%): Up to 25%

AIG’s Global Compliance Group’s (“GCG”) Data Analytics and Monitoring Team is seeking an individual to drive the implementation of Data Analytics and Automation solutions for the Compliance Department.

GCG is a centralized compliance function with oversight responsibility for managing compliance risks and sustaining compliance management across AIG’s businesses, functions, legal entities and countries of operation. The Compliance Data Analytics and Monitoring Program is one of the key functions of the GCG, and is aligned with the Compliance Risk Taxonomy with a focus on assessing compliance risks and related controls as they pertain to AIG and Business Policies and Standards, as well as key country and state laws and regulations.

As a Data Analyst/Scientist, you will have an exciting opportunity to learn about AIG’s products and services across multiple businesses, including General Insurance, Life & Retirement and Investments. In addition, you will be part of the Program’s transformation efforts in rolling out Data Analytics and Monitoring program, and supporting the use of automation across the department.

GCG is seeking candidates who have excelled in previous work experience, possess strong analytical, quantitative and interpersonal skills, and are enthusiastic about and committed to AIG to contribute to the firm’s strategic goals. You will be expected to bring an Analytical and Innovation mindset to a team-oriented environment.

Specific Responsibilities

Strong problem solving skills with emphasis on Data Analytics and Continuous Monitoring.Mine and analyze large amounts of data from multiple data sources to identify and interpret patterns that are applicable to the Compliance organization.Develop models using various industry standard tools to automate transaction testing and manual processes.Work with different stakeholders globally to identify opportunities for leveraging data and analytics to drive business solutions.Manage department Analytics Infrastructure and Data Warehouse.Good working knowledge of Robotic Process Automation and Machine Learning.Good understanding of Risk based Analytics with goal to provide assurance on Compliance Risks.Provide ongoing surveillance, review, and analysis of key risk indicators to identify red flags and potential compliance violations.Proven track record in Analytics Story-Telling and effectively communicating findings.Collaborate with the Compliance Testing team members and provide data analytics and automated testing support during the testing lifecycle, including planning, testing of controls and reporting.Train Compliance Testing team members on available automated tools and work to improve the overall testing review process, including full population testing.Build close working relationships with business and functional leaders, colleagues across other assurance functions, and fellow team members.Use predictive modeling to increase and optimize value of the Analytics SolutionsExperience using statistical languages (Python, R) to manipulate data and draw insights

Qualifications

5-7 years of relevant analytics experience.Bachelor’s or Master’s Degree, preferably in Data Analytics, Information Science, Computer Science, Data Science, Statistics, , and/or other related discipline.

Experience developing solutions utilizing Analytics, BI, database, and Visualization tools (e.g., SQL, KNIME, Rapid Miner, Alteryx, Power BI, Tableau, Python, UIPath, Netezza, and Hadoop).A strong drive to learn and master new technologies and techniques.Experience working in a multi-project environment and across multiple countries.Solid foundational knowledge of Compliance testing and/or insurance business processes, including the relevance of key applicable laws and regulations.Strong project management skills, including effective attention to detail.Strong interpersonal skills to establish effective working relationships with and provide constructive feedback to stakeholders, colleagues and reviewers.Strong verbal and written communication skill, including presentation skills.Effective time management skills; coordinate and prioritize competing initiatives while meeting deadlines.Ability to educate team members in Analytics and Automation best practices.Ability to identify process improvements and suggest efficiencies.Ability to document processes, and transfer knowledge to team members.

It has been and will continue to be the policy of American International Group, Inc., its subsidiaries and affiliates to be an Equal Opportunity Employer. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories.

At AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives."
179,https://www.glassdoor.co.in/partner/jobListing.htm?pos=3016&ao=437149&s=58&guid=0000016baeafe7388a34bfd62b4e5a9a&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5dee4b9a&cb=1562003892507&jobListingId=3270237898,Lead Data Analyst,AIG, – Bengaluru,"Functional Area:OP - OperationsEstimated Travel Percentage (%): Up to 25%Relocation Provided: NoAIG ANALYTICS & SERVICES PRIVATE LIMITEDJob Description

Job Title: Lead Data Analyst/Scientist, Data Analytics and Monitoring – Global Compliance Group, Bangalore, India

Estimated Travel Percentage (%): Up to 25%

AIG’s Global Compliance Group’s (“GCG”) Data Analytics and Monitoring Team is seeking an individual to drive the implementation of Data Analytics and Automation solutions for the Compliance Department.

GCG is a centralized compliance function with oversight responsibility for managing compliance risks and sustaining compliance management across AIG’s businesses, functions, legal entities and countries of operation. The Compliance Data Analytics and Monitoring Program is one of the key functions of the GCG, and is aligned with the Compliance Risk Taxonomy with a focus on assessing compliance risks and related controls as they pertain to AIG and Business Policies and Standards, as well as key country and state laws and regulations.

As a Data Analyst/Scientist, you will have an exciting opportunity to learn about AIG’s products and services across multiple businesses, including General Insurance, Life & Retirement and Investments. In addition, you will be part of the Program’s transformation efforts in rolling out Data Analytics and Monitoring program, and supporting the use of automation across the department.

GCG is seeking candidates who have excelled in previous work experience, possess strong analytical, quantitative and interpersonal skills, and are enthusiastic about and committed to AIG to contribute to the firm’s strategic goals. You will be expected to bring an Analytical and Innovation mindset to a team-oriented environment.

Specific Responsibilities

Strong problem solving skills with emphasis on Data Analytics and Continuous Monitoring.Mine and analyze large amounts of data from multiple data sources to identify and interpret patterns that are applicable to the Compliance organization.Develop models using various industry standard tools to automate transaction testing and manual processes.Work with different stakeholders globally to identify opportunities for leveraging data and analytics to drive business solutions.Manage department Analytics Infrastructure and Data Warehouse.Good working knowledge of Robotic Process Automation and Machine Learning.Good understanding of Risk based Analytics with goal to provide assurance on Compliance Risks.Provide ongoing surveillance, review, and analysis of key risk indicators to identify red flags and potential compliance violations.Proven track record in Analytics Story-Telling and effectively communicating findings.Collaborate with the Compliance Testing team members and provide data analytics and automated testing support during the testing lifecycle, including planning, testing of controls and reporting.Train Compliance Testing team members on available automated tools and work to improve the overall testing review process, including full population testing.Build close working relationships with business and functional leaders, colleagues across other assurance functions, and fellow team members.Use predictive modeling to increase and optimize value of the Analytics SolutionsExperience using statistical languages (Python, R) to manipulate data and draw insights

Qualifications

5-7 years of relevant analytics experience.Bachelor’s or Master’s Degree, preferably in Data Analytics, Information Science, Computer Science, Data Science, Statistics, , and/or other related discipline.

Experience developing solutions utilizing Analytics, BI, database, and Visualization tools (e.g., SQL, KNIME, Rapid Miner, Alteryx, Power BI, Tableau, Python, UIPath, Netezza, and Hadoop).A strong drive to learn and master new technologies and techniques.Experience working in a multi-project environment and across multiple countries.Solid foundational knowledge of Compliance testing and/or insurance business processes, including the relevance of key applicable laws and regulations.Strong project management skills, including effective attention to detail.Strong interpersonal skills to establish effective working relationships with and provide constructive feedback to stakeholders, colleagues and reviewers.Strong verbal and written communication skill, including presentation skills.Effective time management skills; coordinate and prioritize competing initiatives while meeting deadlines.Ability to educate team members in Analytics and Automation best practices.Ability to identify process improvements and suggest efficiencies.Ability to document processes, and transfer knowledge to team members.

It has been and will continue to be the policy of American International Group, Inc., its subsidiaries and affiliates to be an Equal Opportunity Employer. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories.

At AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives."
180,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1808&ao=437149&s=58&guid=0000016baeae7564a2953d77b61044d8&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_185d6575&cb=1562003797801&jobListingId=3255093748,Data Engineer,ExpertEase, – Bengaluru,"Responsibilities

Setting up and maintenance of data pipelines for Data Analytics and Machine Learning tasks to meet tech and business data requirements.

Maintenance of versioned datasets to enable faster data analyticsAutomation of manual tasks.

Setting up and maintenance of data reporting tools like redash, report mailers, etc.

Responsible for ETL jobs, migration of data across various clusters/databases.

Ensuring quality of data, analytics pipeline reliability, and data stack efficiency.

Setting up and maintenance of Real Time Analytics Stack- Daily Reports - Business & TechSetting up and maintenance of Batch Data Analytics Engine.

Database optimization and management (MySql, postgresql, mongodb, cassandra, etc).

Data Analytics Support for App Analytics of User Experience and Usage Patterns.

User Onboarding and Engagement Analysis.

Usage Statistics & growth analytics Doctor & Patient Statistics Optimal Allocation Strategy & Tracking.

Requirements

Database and Data management & Analysis Tools.

Worked on ETL jobs, data migration.

Mysql, Elasticsearch, python or Scripting frameworks, nodejs.

Data analytics experience.

Basic Web App Development (Js) for Dashboards & Reporting.

Marketing Analytics - Track Cohorts and optimize marketing costs & improve targeting.

Doctor App & Consulting Experience analytics

Regards

HR - Wahid

Email id -wahid.s@expertease.co.in

contact - 040 - 47473355

whatsapp - 9100033522

Salary: Not Disclosed by Recruiter

Industry: Medical / Healthcare / Hospitals

Functional Area: IT Software - Application Programming, Maintenance

Role Category: Programming & Design

Role: Software Developer

Employment Type: Permanent Job, Full Time

Keyskills:

Data AnalyticsMachine LearningData ReportingReporting Tools"
181,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2301&ao=4120&s=58&guid=0000016baeaf02b2ab5fbd2932bb3fa0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_af7463af&cb=1562003834787&jobListingId=2993828600,machine learning engineers, – Bengaluru, – Bengaluru,"Responsibilities

Setting up and maintenance of data pipelines for Data Analytics and Machine Learning tasks to meet tech and business data requirements.

Maintenance of versioned datasets to enable faster data analyticsAutomation of manual tasks.

Setting up and maintenance of data reporting tools like redash, report mailers, etc.

Responsible for ETL jobs, migration of data across various clusters/databases.

Ensuring quality of data, analytics pipeline reliability, and data stack efficiency.

Setting up and maintenance of Real Time Analytics Stack- Daily Reports - Business & TechSetting up and maintenance of Batch Data Analytics Engine.

Database optimization and management (MySql, postgresql, mongodb, cassandra, etc).

Data Analytics Support for App Analytics of User Experience and Usage Patterns.

User Onboarding and Engagement Analysis.

Usage Statistics & growth analytics Doctor & Patient Statistics Optimal Allocation Strategy & Tracking.

Requirements

Database and Data management & Analysis Tools.

Worked on ETL jobs, data migration.

Mysql, Elasticsearch, python or Scripting frameworks, nodejs.

Data analytics experience.

Basic Web App Development (Js) for Dashboards & Reporting.

Marketing Analytics - Track Cohorts and optimize marketing costs & improve targeting.

Doctor App & Consulting Experience analytics

Regards

HR - Wahid

Email id -wahid.s@expertease.co.in

contact - 040 - 47473355

whatsapp - 9100033522

Salary: Not Disclosed by Recruiter

Industry: Medical / Healthcare / Hospitals

Functional Area: IT Software - Application Programming, Maintenance

Role Category: Programming & Design

Role: Software Developer

Employment Type: Permanent Job, Full Time

Keyskills:

Data AnalyticsMachine LearningData ReportingReporting Tools"
182,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1320&ao=437149&s=58&guid=0000016baead935d998135bfad78c409&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5b9f650e&cb=1562003740660&jobListingId=3200484157,Data Engineer,MoEngage Inc., – Bengaluru,"MoEngage India Pvt Ltd is a technology company based out of Bangalore and San Francisco. We are focused on solving the problem of retention and engagement in mobile apps. We are building an User Analytics and Engagement platform to help app companies understand user behaviour in real time and deliver personalised interactions (big data personalisation at scale). We work with most of the top consumer‐internet companies in India across E‐commerce, Travel, Food, etc. We are a fast‐growing team of young people, who worked earlier at mobile and startup companies.

We have seen a considerable growth since the inception of the company, to give a sense of scale we deal with, imagine receiving mobile user events from major e-commerce , travel and food companies together on a global scale. Maintaining the infrastructure on such a scale is a huge challenge. We face interesting and exciting challenges on a daily basis, ingesting high rate of data from users (more than 130k per second) means things like scalability, availability and efficiency are hugely important. We are looking for smart Data engineer to fill this role.

What you will be doing:

Design and develop data processing solutions choosing best tools.

Build and maintain data ingest-retrieval pipelines.

Develop solutions to get data insight by enabling analysing, visualisation, monitoring and alerting.

Dev-ops work to keep the data-platform scalable, reliable and secure.

What we expect:

Strong understanding of Computer science and distributed system fundamentals.

Hands-on experience of building real time streaming solutions with Kafka.

2+ years of experience in any JVM language(Scala/Java).

Hands-on experience with one of the cloud platforms like AWS.

Understanding and Hands-on experience of Big-data technologies(Like - Kafka, Kafka connect, Kafka streams, Spark, Zookeeper, SAMZA, HBase, ELK, Druid, S3, Athena, BigQuery)

Perks:

Work at Scale and challenge yourself

Work with a smart team which grew up in the Mobile First world

Free Lunch and Snacks plus caffeine all day

TT table, Poker nights and team outings"
183,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1707&ao=409834&s=58&guid=0000016baeae4fcb883179e091fafa57&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_d3606629&cb=1562003788192&jobListingId=3261703862,Data Engineer-WCE,IBM, – Bengaluru,"Introduction

Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that literally make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of.

Your Role and Responsibilities

Who you are: As a Data Engineer-WCE, You have:


Hands on experience in Hadoop ecosystems such as HDFS, MapReduce, Yarn, Hive and Sqoop. Developed Scala scripts using both DataFrame/SQL/Datasets in Spark 2.1 for Data Aggregation, querying and Analysis.Good knowledge in Spark Core, Spark SQL.Created Python and Unix Shell Scripts.

What youll do: As a Data Engineer-WCE, You will:


Hands on experience in modelling databases (particularly nosql), working on indexes, materialized views, performance tuning / optimization of queries, data migration scripts, etc.Experience in developing backend components in Java including RESTful APIs with knowledge of Spring Framework, JSON based messaging formatUnderstand the use of docker/Kubernetes in developing applications for cloud deploymentUse of Microservices based ArchitectureFollow coding best practices with unit testing using established unit test framework - TestNG/JUnitAdopt the development agile practice in the team to maintain high quality of code established with code reviewsAdapt to development of applications using source control tools such as Git/GitHub

How well help you grow:



Youll have access to all the technical and management training courses to become the expert you want to be.Youll learn directly from Senior members/leaders in this field.You'll have the opportunity to work with multiple clients.


Required Professional and Technical Expertise


3-8 years of experience of product development in reputed product development / start up companies.Hands-on experience on the following skills: Java, Restful API, no SQL database (Cassandra, Couchbase), Hadoop/Hadoop Distributed File System. Working knowledge of Docker.


Preferred Professional and Technical Expertise


Experience in working in platforms- Horton works, Cloudera and AWS.Solving the Hadoop related issues. Ability to work individually as well as in a team with analytical skills.Proven communication skills, self-motivated, quick learner.Willing to learn new technologies to improve the work efficiency.


About Business Unit

At IBM Cognitive Applications, we build open applications that unlock the power of data for clients, partners, and developers. Running on top of IBM's unique Hybrid, Multicloud and AI infrastructures, these applications work across horizontal domains and bring our technology to life for end users. Cognitive Applications unit includes: Watson Customer Engagement, Watson IoT, Watson Media and Weather, Talent & Collaboration, and IBM Developer teams

Your Life @ IBM

What matters to you when youre looking for your next career challenge? Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible. Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM

IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
"
184,https://www.glassdoor.co.in/partner/jobListing.htm?pos=715&ao=443080&s=58&guid=0000016baeacd17180fc1f5efc998aed&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ea0d65a7&cb=1562003690287&jobListingId=3256197230,Digital Industry Solution - Senior Data Scientist & Machine Learning Experts,ABB, – Bengaluru,"Join ABB and work in a team that is dedicated to creating a future where innovative digital technologies allow greater access to cleaner energy.

ABB is a global technology leader in industrial digitalization. ABB operates in more than 100 countries with about 147,000 employees and $34 billion revenue.

In India, ABB has been operating for over a century. At present, we have 40 factories at 9 locations that develop best-in-class products bringing together global expertise, with local experience. India is also home to ABB group’s largest engineering design and R&D center, where our engineers work on cutting-edge technologies to develop the future offerings from engineering tools to analytics solutions.

Industrial Automation Division provides modern solutions for various types of industries. The division consists of eight business units: Oil, Gas and Chemicals (IAOG), Process Industries (IAPI), Power Generation (IAPG). Marine and Ports (IAMP), Turbocharging (IATU), Control Technologies (IACT), Measurement and Analytics (IAMA) and Machine & Factory Automation (IAMF). There are 1800+ employees in IA division.

As Digital Industry Solution - Senior Data Scientist & Machine Learning experts you will be part of Industrial Automation - Digital Organization and will be based in Bangalore.

We are an international pioneering technology leader that is writing the future of industrial digitalization. At the forefront is our Software Development Center which provides industry leading software and deep domain expertise to help the world’s most asset-intensive industries solve their biggest challenges. To strengthen our Industrial Automation Analytics team, we are looking for and experts Data Science for developing enterprise solutions for on-premise and cloud platforms like Azure / AWS.

Tasks• Designing and developing statistical models and applications fitting to business requirement.



Designing and developing machine learning and deep learning-based solutions.
Perform data mining, pattern recognition, statistical analysis using large structure and unstructured data including time-series, device data, image, documents etc.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks understand business scenarios, identifying and applying right AI / cognitive computing methodologies.
Analyze the data, understanding of characteristics, evaluate alternate models, validate hypothesis through theoretical and empirical approaches.
Defining the value proposition for different advanced analytics initiatives.
Create scalable models and algorithms for integrating into proprietary tools and products.
Evaluation, analysis and documentation of business requirements and translation into proper advanced analytics solution approaches.
Analyze the data, understanding of characteristics, evaluate alternate models, validate hypothesis through theoretical and empirical approaches.
Develop and implement simulation environment for optimization across operations and supply chain.
Create statistical and predictive models for equipment monitoring, failure detection, life estimation and life extension.
Build tools and support structures needed for analyzing data, perform data cleansing, feature selection and feature engineering and organizing experiments in conjunction with best practices.
Understand various data structures and apply methods to clean and transform the data.
Run Spark, Python, Deep learning models in production, build new Machine Learning tools/library and consolidate existing ones.
Living ABB’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.


RequirementsTechnology



Understanding and practical skills preferably in the following:


o Proven experience as a Machine Learning, Statistics, Deep Learning, Recommendation system (Prescriptive analytics), Neural Networks and NLP.

o Strong understanding of statistical modeling and its applications to solve business requirements.

o Conceptual understanding of various modeling techniques and Pros & Cons for the approaches.

o Good understanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries like Apache Spark, Apache Flink, Azure Machine learning.

o Hands on experience with R, Python, Java, Tensorflow and Big data machine learning platforms.

o Understanding of data structures, data modeling and software architecture.

o Deep knowledge of math, probability, statistics and algorithms.

o Outstanding analytical and problem-solving skills.

o In depth knowledge of Python, R, Java languages and machine learning libraries.

o Good understanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries like Apache Spark, Apache Flink, Azure Machine learning.

o Strong background in data structures and algorithms.

o Exposure on Database technologies – Oracle, SQL Server, Cosmos DB, MONGO DB and NoSQL databases.

Desirable



Experience in developing solutions for Energy and process industries would be preferable.
Knowledge of data science and software engineering.
Cloud platforms, especially Azure™.

Soft Skills and Experience:

Strong oral and written communication skills in English.
Should have an experience of 5 - 10 years in relevant field.
Strong understanding of Industry Benchmarks and associated standards.


Additional informationFor any further information, please visit ABB career site

http://new.abb.com/jobs/center#JobCountry=any&JobCity=any&JobFunction=any&JobRole=any&JobText=

Important, please include in your CV the following passage:

“I hereby agree for my personal data, included in my job application, to be processed in line with the needs of recruitment, in accordance with the Law on Personal Data Protection of 29th August 1997 (Law Gazette from 2002, No.101, heading 926, as amended).”"
185,https://www.glassdoor.co.in/partner/jobListing.htm?pos=3019&ao=437149&s=58&guid=0000016baeafe7388a34bfd62b4e5a9a&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_13ec2fbf&cb=1562003892509&jobListingId=3274956699,Digital Industry Solution - Senior Data Scientist & Machine Learning Experts,ABB, – Bengaluru,"Join ABB and work in a team that is dedicated to creating a future where innovative digital technologies allow greater access to cleaner energy.

ABB is a global technology leader in industrial digitalization. ABB operates in more than 100 countries with about 147,000 employees and $34 billion revenue.

In India, ABB has been operating for over a century. At present, we have 40 factories at 9 locations that develop best-in-class products bringing together global expertise, with local experience. India is also home to ABB group’s largest engineering design and R&D center, where our engineers work on cutting-edge technologies to develop the future offerings from engineering tools to analytics solutions.

Industrial Automation Division provides modern solutions for various types of industries. The division consists of eight business units: Oil, Gas and Chemicals (IAOG), Process Industries (IAPI), Power Generation (IAPG). Marine and Ports (IAMP), Turbocharging (IATU), Control Technologies (IACT), Measurement and Analytics (IAMA) and Machine & Factory Automation (IAMF). There are 1800+ employees in IA division.

As Digital Industry Solution - Senior Data Scientist & Machine Learning experts you will be part of Industrial Automation - Digital Organization and will be based in Bangalore.

We are an international pioneering technology leader that is writing the future of industrial digitalization. At the forefront is our Software Development Center which provides industry leading software and deep domain expertise to help the world’s most asset-intensive industries solve their biggest challenges. To strengthen our Industrial Automation Analytics team, we are looking for and experts Data Science for developing enterprise solutions for on-premise and cloud platforms like Azure / AWS.

Tasks• Designing and developing statistical models and applications fitting to business requirement.



Designing and developing machine learning and deep learning-based solutions.
Perform data mining, pattern recognition, statistical analysis using large structure and unstructured data including time-series, device data, image, documents etc.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks understand business scenarios, identifying and applying right AI / cognitive computing methodologies.
Analyze the data, understanding of characteristics, evaluate alternate models, validate hypothesis through theoretical and empirical approaches.
Defining the value proposition for different advanced analytics initiatives.
Create scalable models and algorithms for integrating into proprietary tools and products.
Evaluation, analysis and documentation of business requirements and translation into proper advanced analytics solution approaches.
Analyze the data, understanding of characteristics, evaluate alternate models, validate hypothesis through theoretical and empirical approaches.
Develop and implement simulation environment for optimization across operations and supply chain.
Create statistical and predictive models for equipment monitoring, failure detection, life estimation and life extension.
Build tools and support structures needed for analyzing data, perform data cleansing, feature selection and feature engineering and organizing experiments in conjunction with best practices.
Understand various data structures and apply methods to clean and transform the data.
Run Spark, Python, Deep learning models in production, build new Machine Learning tools/library and consolidate existing ones.
Living ABB’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.


RequirementsTechnology



Understanding and practical skills preferably in the following:


o Proven experience as a Machine Learning, Statistics, Deep Learning, Recommendation system (Prescriptive analytics), Neural Networks and NLP.

o Strong understanding of statistical modeling and its applications to solve business requirements.

o Conceptual understanding of various modeling techniques and Pros & Cons for the approaches.

o Good understanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries like Apache Spark, Apache Flink, Azure Machine learning.

o Hands on experience with R, Python, Java, Tensorflow and Big data machine learning platforms.

o Understanding of data structures, data modeling and software architecture.

o Deep knowledge of math, probability, statistics and algorithms.

o Outstanding analytical and problem-solving skills.

o In depth knowledge of Python, R, Java languages and machine learning libraries.

o Good understanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries like Apache Spark, Apache Flink, Azure Machine learning.

o Strong background in data structures and algorithms.

o Exposure on Database technologies – Oracle, SQL Server, Cosmos DB, MONGO DB and NoSQL databases.

Desirable



Experience in developing solutions for Energy and process industries would be preferable.
Knowledge of data science and software engineering.
Cloud platforms, especially Azure™.

Soft Skills and Experience:

Strong oral and written communication skills in English.
Should have an experience of 5 - 10 years in relevant field.
Strong understanding of Industry Benchmarks and associated standards.


Additional informationFor any further information, please visit ABB career site

http://new.abb.com/jobs/center#JobCountry=any&JobCity=any&JobFunction=any&JobRole=any&JobText=

Important, please include in your CV the following passage:

“I hereby agree for my personal data, included in my job application, to be processed in line with the needs of recruitment, in accordance with the Law on Personal Data Protection of 29th August 1997 (Law Gazette from 2002, No.101, heading 926, as amended).”"
186,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1112&ao=437149&s=58&guid=0000016baead512d93f11de47c2bf2a3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_4085ca79&cb=1562003722969&jobListingId=3250050494,Data Scientist Operations Research,Grofers, – Bengaluru,"Grofers is a low-price online supermarket. We enable customers to order products via our mobile application or website across categories such as grocery, fruits & vegetables, beauty & wellness, household care, baby care, pet care, bakery and meats & seafood and get them delivered to their doorstep. At Grofers we believe in improving the quality of life of our customers by providing them best products at best prices. To be able to meet customer expectations and enrich their shopping experience, we provide them with products they best relate with, help them save money on everyday purchases, and give them the spending power they need. We operate in 13 cities in India and are continuously growing. We’ve raised $226.5 million till date from SoftBank, Tiger Global and Sequoia Capital.

Objective of this Role

As a Data Scientist – Operations Research you will be part of a highly energetic supply chain product team and be part in building next-gen supply chain products for Grofers. You will participate in planning and launching new products and deployments across Pan-India and identifying areas of opportunities

Responsibilities:

Specific day to day responsibilities will include, but will not be limited to:



Design, build, configure and solutioning applications to meet Grofers business process and requirements.
Coordinate with operations and training team for new Product deployments and feedback
Update relevant stakeholders about newly launched features and provide support for product related


queries



Drive and Track adoption of deployed features
Coordinate with tech and product team to report bugs and product enhancement
Resolve ad-hoc queries raised by operations team/business teams
Work with design and engineering teams through feature implementations


Qualification/Desired Attributes



Linear Programming, Graphical Solution,
BFS, Simplex Method, Duality theory, Dual Simplex Method, Sensitivity Analysis,
Nonlinear Programming, Optimization Models and Techniques, Constraint Optimization, Unconstrained


Optimization, KKT, Relaxation Method,



Integer Programming, Branch and Bound Method, Cutting Plane Algorithm,
Linear Integer Programming, Mixed Integer Programming, Bilinear Programming.
Knowing SQL is added advantage
Expert in Python, R programming. Preferable to have knowledge in GUROBI / IBM ILOG CPLEX.
Good to know basics of Data Analysis, Supply Chain Management and retail industry.
Work with Data Team and Product Manager to understand business requirement and build OR Models


such as linear programming model / integer programming model / mixed-integer programming model and

solve it.



Must have experience in communication skills, logics of Operations Research and programming.
Preferred to have knowledge in Warehouse Optimization, Replenishment strategy, Purchase – Demand


planning – Dispatch planning in the supply chain management, Network Optimization, Forecasting and

Predictive analysis in business applications. .



Required qualification is PhD in Operations Research, M.Sc / M. Tech in Operations Research. If any other


discipline has experience in Operations Research modelling they can also apply.

Excited? You will be, once you visit our Engineering Blog where you can deep dive into all the cool stuff that our engineers have been working on.

All candidates interested in exploring the opportunity are requested to apply with us on careers@grofers.com"
187,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1423&ao=136249&s=58&guid=0000016baeadc50792c64f535be4d6a0&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_21e8566e&cb=1562003752623&jobListingId=3280811801,Data Scientist - 4 to 6 Years,Capgemini, – Bengaluru,"Short Description

Qualifications

Job Responsibilities

"
188,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2415&ao=437149&s=58&guid=0000016baeaf24ef886cc75aedc25f50&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_ae72a4c8&cb=1562003842917&jobListingId=3206307128,Big Data Engineer,Xebia, – Bengaluru,"Creating complex data processing pipelines, as part of diverse, high energy teams

Designing scalable implementations of the models developed by our Data Scientists

Hands-on programming based on TDD, usually in a pair programming environment

Deploying data pipelines in production based on Continuous Delivery practices

Advising clients on the usage of different distributed storage and computing technologies from the plethora of options available in the ecosystem

What we look for in you?

Strong development experience is a must. Consistent track record for education and professional career.

Experience with Apache Spark (required)

Experience with Hadoop administration and development (required)

Good to have experience with Storm, Kafka, NiFi, Spark Streaming, Spark MLlib, Spark GraphX, Flink, Samza, Map Reduce

Familiarity with data loading tools like Flume, Sqoop.

Knowledge of workflow/schedulers like Oozie.

Proven understanding with Hadoop, HBase, Hive, Pig, and HBase.

Good understanding of Object oriented design, Design Patterns

Has done development or debugging on Linux/ Unix platforms.

Motivation to learn innovative trade of programming, debugging and deploying

Self starter, with excellent self-study skills and growth aspirations

Excellent written and verbal communication skills. Flexible attitude, perform under pressure.

Test driven development, a commitment to quality and a thorough approach to the work.

A good team player with ability to meet tight deadlines in a fast-paced environment

Suitable qualifications and industry certifications

Skills we're looking for

4+ years Big Data ecosystem experience along with admin, development, cloud and app integration experience

3+ years Consulting experience

3+ years enterprise projects – customer centricity, optimization, predictive engines, enterprise data hub

Experience in Big Data application development involving various data processing techniques Data Ingestion, In-Stream data processing, Batch Analytics

Excellent knowledge, experience with the Hadoop stack (Hadoop, Spark, Spark Streaming, H2o.ai, Hbase, Sqoop, Flume, Shark, Oozie, etc.).

Solid exposure to Core Java and distributed computing

Good understanding of NoSQL platforms like HBase, Couch Base, Vertica, MongoDB, Cassandra

Proficient in SQL queries and stored procedures.

Proficient in SQL, NoSQL, relational database design and methods for efficiently retrieving data Prior experience with Hadoop, HBase, Hive, Pig and Map/Reduce.

Location: Bangalore

Our culture

We thrive for authority. This can only be achieved by working with the best people, offering them the most challenging projects and create a continuous learning environment.

All this is in place so you can accelerate your career.

What can you expect?

Inspiring working environment

The most challenging assignments

Every 2nd week in-house knowledge sharing session (XKE).

Trust

Freedom to accelerate

Much more!"
189,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2530&ao=4120&s=58&guid=0000016baeaf4089b7fd28dcede3deff&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_595d5b8b&cb=1562003849890&jobListingId=2619100978,Computer Vision/Deep Learning Research Scientist, – Bengaluru, – Bengaluru,"Creating complex data processing pipelines, as part of diverse, high energy teams

Designing scalable implementations of the models developed by our Data Scientists

Hands-on programming based on TDD, usually in a pair programming environment

Deploying data pipelines in production based on Continuous Delivery practices

Advising clients on the usage of different distributed storage and computing technologies from the plethora of options available in the ecosystem

What we look for in you?

Strong development experience is a must. Consistent track record for education and professional career.

Experience with Apache Spark (required)

Experience with Hadoop administration and development (required)

Good to have experience with Storm, Kafka, NiFi, Spark Streaming, Spark MLlib, Spark GraphX, Flink, Samza, Map Reduce

Familiarity with data loading tools like Flume, Sqoop.

Knowledge of workflow/schedulers like Oozie.

Proven understanding with Hadoop, HBase, Hive, Pig, and HBase.

Good understanding of Object oriented design, Design Patterns

Has done development or debugging on Linux/ Unix platforms.

Motivation to learn innovative trade of programming, debugging and deploying

Self starter, with excellent self-study skills and growth aspirations

Excellent written and verbal communication skills. Flexible attitude, perform under pressure.

Test driven development, a commitment to quality and a thorough approach to the work.

A good team player with ability to meet tight deadlines in a fast-paced environment

Suitable qualifications and industry certifications

Skills we're looking for

4+ years Big Data ecosystem experience along with admin, development, cloud and app integration experience

3+ years Consulting experience

3+ years enterprise projects – customer centricity, optimization, predictive engines, enterprise data hub

Experience in Big Data application development involving various data processing techniques Data Ingestion, In-Stream data processing, Batch Analytics

Excellent knowledge, experience with the Hadoop stack (Hadoop, Spark, Spark Streaming, H2o.ai, Hbase, Sqoop, Flume, Shark, Oozie, etc.).

Solid exposure to Core Java and distributed computing

Good understanding of NoSQL platforms like HBase, Couch Base, Vertica, MongoDB, Cassandra

Proficient in SQL queries and stored procedures.

Proficient in SQL, NoSQL, relational database design and methods for efficiently retrieving data Prior experience with Hadoop, HBase, Hive, Pig and Map/Reduce.

Location: Bangalore

Our culture

We thrive for authority. This can only be achieved by working with the best people, offering them the most challenging projects and create a continuous learning environment.

All this is in place so you can accelerate your career.

What can you expect?

Inspiring working environment

The most challenging assignments

Every 2nd week in-house knowledge sharing session (XKE).

Trust

Freedom to accelerate

Much more!"
190,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1905&ao=643978&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e42e2837&cb=1562003805553&jobListingId=3272953662,Data Engineer,Alstom, – Bengaluru,"As a promoter of sustainable mobility, Alstom develops and markets systems, equipment and services for the transport sector. Alstom offers a complete range of solutions (from high-speed trains to metros, tramways and e-buses), passenger solutions, customised services (maintenance, modernisation), infrastructure, signalling and digital mobility solutions. Alstom is a world leader in integrated transport systems. The company recorded sales of €7.3 billion and booked €10.0 billion of orders in the 2016/17 fiscal year. Headquartered in France, Alstom is present in over 60 countries and employs 32,800 people. UNIFE report forecasts India's accessible market at 4B€ over 2016-18, with growth of 6.6%. Alstom has established a strong presence in India and is currently executing metro projects in several Indian cities including Chennai, Kochi and Lucknow where it is supplying Rolling Stock manufactured out its state of the art facility at SriCity in Andhra Pradesh. In the Mainline space, Alstom is executing Signaling & Power Supply Systems for the 343 Km. section on World Bank funded Eastern Dedicated Freight Corridor. Construction of the new electric locomotive factory for manufacturing and supply of 800 units of high horse power locomotives is also in full swing at Madhepura in Bihar. Alstom has set up an Engineering Centre of Excellence in Bengaluru, and this coupled with a strong manufacturing base as well as localized supply chains, is uniquely positioned to serve customers across the globe. Today, Alstom in India employs close to 3000 people and in line with Government of India’s ‘Make in India’ policy initiative, Alstom has been investing heavily in the country in producing world class rolling stock, components, design, research and development to not only serve the domestic market, but also rest of the world. 

 

 

OVERALL PURPOSE OF THE ROLE

The data engineer reports to Platform Services Delivery Manager. Responsible for preparing data for analytical or operational uses. The specific tasks handled by data engineer will include building data pipelines to pull together information from different source systems; integrating, consolidating and cleansing data; and structuring it for use in individual analytics applications.

 

STRUCTURE, REPORTING, NETWORKS & LINKS

Organization Structure

CITO

|-- VP Business Solutions & Innovation

|-- Shared Services Director

|--Platform Services Delivery Manager

|-- Data Engineer

 

Organizational Reporting: Reports to Platform Services Delivery Manager

 

Networks & Links

Internally

Shared Services TeamDigital Platform TeamInnovation TeamApplication Platform OwnersBusiness process ownersInfrastructure team

Externally

Third-party technology providersStrategic Partners

 

Location

Position will be based in BangaloreWilling to travel occasionally for onsite meetings and team workshops as required

 

RESPONSIBILITIES  :-

The Data Engineer should:

 Develop, Test, Create and maintain optimal data pipeline architectureAssemble large, complex data sets that meet functional / non-functional business requirementsIdentify, design, and implement internal process improvements, such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etcBuild / Leverage existing infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologiesWork with stakeholders of Data and Design teams to assist with data-related technical issues and support their data infrastructure needsEmploy a variety of languages and tools to marry systems togetherWork closely with Data Scientists to to strive for greater functionality in our data systems and aid smooth data transformations and pre-processing

 

Qualifications & Skills 

EDUCATION  

Bachelor’s/Master’s degree in Computer Science Engineering /Technology or other quantitative field

 

BEHAVIORAL COMPETENCIES 

As a data Engineer, the candidate should demonstrate:

A strong sense for collaboration and being a team playerArticulate issues and propose solutions.Structured thought process and articulationCritical thinking and problem-solving skillsAnalytical bent of mind and be willing to question the status quoSelf Driven & innovative thinkerSense of urgency, go-getter attitudeIndividual contributor and proactive and have leadership skills.Relentless learner with a dedication to learn new technologies and methods

 

TECHNICAL COMPETENCIES & EXPERIENCE 

 To be considered for this role, candidate needs to possess the following skills experience and attributes:

 Mandatory to Have (Minimum 3+ Years of experience)

Experience working with Data Scientists / Data AnalystsExperience with relational SQL and NoSQL databases, including Postgres or MongoDB or CassandraExperience with data pipeline and workflow management tools: Denodo (preferred), Azkaban, Luigi, Airflow, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etcExperience with DevOps agile tools and techniques: Gitlab, TortoiseSVN, JIRA, MS Teams etcExperience with big data tools: Hadoop, Hive, Spark, Kafka, etc à At least must have a knowledge

 Nice to have

Experience with cloud services: Azure, AWS - EC2, EMR, RDS, RedshiftExperience with stream-processing systems: Storm, Spark-Streaming, etc

 

 

Alstom is committed to create a diverse & international working environment, that reflects the future of our industry, our clients and end-users. As an employee, you will have a unique opportunity to continue to build your career and directly contribute to the expanding growth of the global transport industry"
191,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2924&ao=437149&s=58&guid=0000016baeafd19cb39e3a19237322e3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_a200d523&cb=1562003887236&jobListingId=3280141745,Data Engineer,Alstom, – Bengaluru,"As a promoter of sustainable mobility, Alstom develops and markets systems, equipment and services for the transport sector. Alstom offers a complete range of solutions (from high-speed trains to metros, tramways and e-buses), passenger solutions, customised services (maintenance, modernisation), infrastructure, signalling and digital mobility solutions. Alstom is a world leader in integrated transport systems. The company recorded sales of €7.3 billion and booked €10.0 billion of orders in the 2016/17 fiscal year. Headquartered in France, Alstom is present in over 60 countries and employs 32,800 people. UNIFE report forecasts India's accessible market at 4B€ over 2016-18, with growth of 6.6%. Alstom has established a strong presence in India and is currently executing metro projects in several Indian cities including Chennai, Kochi and Lucknow where it is supplying Rolling Stock manufactured out its state of the art facility at SriCity in Andhra Pradesh. In the Mainline space, Alstom is executing Signaling & Power Supply Systems for the 343 Km. section on World Bank funded Eastern Dedicated Freight Corridor. Construction of the new electric locomotive factory for manufacturing and supply of 800 units of high horse power locomotives is also in full swing at Madhepura in Bihar. Alstom has set up an Engineering Centre of Excellence in Bengaluru, and this coupled with a strong manufacturing base as well as localized supply chains, is uniquely positioned to serve customers across the globe. Today, Alstom in India employs close to 3000 people and in line with Government of India’s ‘Make in India’ policy initiative, Alstom has been investing heavily in the country in producing world class rolling stock, components, design, research and development to not only serve the domestic market, but also rest of the world. 

 

 

OVERALL PURPOSE OF THE ROLE

The data engineer reports to Platform Services Delivery Manager. Responsible for preparing data for analytical or operational uses. The specific tasks handled by data engineer will include building data pipelines to pull together information from different source systems; integrating, consolidating and cleansing data; and structuring it for use in individual analytics applications.

 

STRUCTURE, REPORTING, NETWORKS & LINKS

Organization Structure

CITO

|-- VP Business Solutions & Innovation

|-- Shared Services Director

|--Platform Services Delivery Manager

|-- Data Engineer

 

Organizational Reporting: Reports to Platform Services Delivery Manager

 

Networks & Links

Internally

Shared Services TeamDigital Platform TeamInnovation TeamApplication Platform OwnersBusiness process ownersInfrastructure team

Externally

Third-party technology providersStrategic Partners

 

Location

Position will be based in BangaloreWilling to travel occasionally for onsite meetings and team workshops as required

 

RESPONSIBILITIES  :-

The Data Engineer should:

 Develop, Test, Create and maintain optimal data pipeline architectureAssemble large, complex data sets that meet functional / non-functional business requirementsIdentify, design, and implement internal process improvements, such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etcBuild / Leverage existing infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologiesWork with stakeholders of Data and Design teams to assist with data-related technical issues and support their data infrastructure needsEmploy a variety of languages and tools to marry systems togetherWork closely with Data Scientists to to strive for greater functionality in our data systems and aid smooth data transformations and pre-processing

 

Qualifications & Skills 

EDUCATION  

Bachelor’s/Master’s degree in Computer Science Engineering /Technology or other quantitative field

 

BEHAVIORAL COMPETENCIES 

As a data Engineer, the candidate should demonstrate:

A strong sense for collaboration and being a team playerArticulate issues and propose solutions.Structured thought process and articulationCritical thinking and problem-solving skillsAnalytical bent of mind and be willing to question the status quoSelf Driven & innovative thinkerSense of urgency, go-getter attitudeIndividual contributor and proactive and have leadership skills.Relentless learner with a dedication to learn new technologies and methods

 

TECHNICAL COMPETENCIES & EXPERIENCE 

 To be considered for this role, candidate needs to possess the following skills experience and attributes:

 Mandatory to Have (Minimum 3+ Years of experience)

Experience working with Data Scientists / Data AnalystsExperience with relational SQL and NoSQL databases, including Postgres or MongoDB or CassandraExperience with data pipeline and workflow management tools: Denodo (preferred), Azkaban, Luigi, Airflow, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etcExperience with DevOps agile tools and techniques: Gitlab, TortoiseSVN, JIRA, MS Teams etcExperience with big data tools: Hadoop, Hive, Spark, Kafka, etc à At least must have a knowledge

 Nice to have

Experience with cloud services: Azure, AWS - EC2, EMR, RDS, RedshiftExperience with stream-processing systems: Storm, Spark-Streaming, etc

 

 

Alstom is committed to create a diverse & international working environment, that reflects the future of our industry, our clients and end-users. As an employee, you will have a unique opportunity to continue to build your career and directly contribute to the expanding growth of the global transport industry"
192,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1902&ao=4120&s=58&guid=0000016baeae937c9ecca8ed9b6487c3&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_e75cae46&cb=1562003805551&jobListingId=3280616639,Data Engineer,Tata Consultancy Services, – Bengaluru,"
Job Description



Must-Have
o 


Exposure

 to scripting and automation such as PowerShell, R, Python

o 


Understanding

 how to analyze, cleanse, join and transform data.

o 


Experience

 with ETL and/or data integration tools ( eg. Informatica, SSIS, Talend, MuleSoft,

 Dell Boomi etc…)

o 


Experience

 in designing solutions using databases and data storage technology such as

 RDBMS, NoSQL, MongoDB, Hadoop, Cassandra etc.

o 


Experience

 of working in at least one of the public cloud platform such as Azure, AWS,

 Google Cloud and using IaaS / PaaS / SaaS components in building highly

 scalable solutions

o 


Implementing

 designed / specified solutions into the chosen platform (e.g. Azure Data

 Factories / Data Lakes, HDInsight or traditional software).
 Good-to-Have

o 


Experience

 of designing solutions deployed on Microsoft and Linux operating systems

o 


Be

 up to date with data processing technology / platforms such as Spark,

 PowerBI, and Tableau.

o 


Good

 understanding of infrastructure components and their fit in different types

 of data solutions
 




Job Function
TECHNOLOGY

Role
Developer

Job Id
146258

Desired Skills
Powershell


Desired Candidate Profile


Qualifications :

 BACHELOR OF ENGINEERING

"
193,https://www.glassdoor.co.in/partner/jobListing.htm?pos=822&ao=437149&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_80c01006&cb=1562003698149&jobListingId=3258138821,Data Scientist,SuccessFactors, – Bengaluru,"SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.

SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Team

The Competitive and Market Intelligence (CMI) team is responsible for analyzing market trends, understanding key competitors in each market, and assessing the impact to SAP’s overall strategic direction and execution. CMI is a part of the Corporate Strategy Group. CMI Crystal Ball is global account intelligence platform that use modern digital analytics to deliver insights into what SAP customers and prospects own and intend to purchase. The CMI Crystal Ball platform injects Big Data account intelligence from an ecosystem of data vendors to enable marketing and sales stronger lead generation and more efficient prospecting. The CMI Data Scientist Expert will report to the CMI Crystal Ball lead and will be virtually be based in India.

Purpose and Objective

The Data Scientist Expert will be virtually based in India CMI Crystal Ball is looking for an outstanding data scientist with the following 3 objectives:



Lead Crystal Ball platform projects. Drive planning and monitor end-to-end execution of platform projects. Ensure business needs are accomplished in the development of back-end functionality and UX.
Develop and design market data analysis programs using internal and external data, enhance account intelligence signals to potential markets, account profiles, target accounts, product opportunities and marketing strategies. Query and aggregate heterogenous data sources to support global programs on account intelligence
Define, propose and implement experimental research strategies on account intelligence. Consult with decision makers and senior management regarding strategic research, planning and analysis, providing insight, knowledge and understanding of markets, solutions and accounts

Role Requirements

For this Data Scientist position we are considering experienced candidates with high analytical problem-solving skills. A experience in scientific and technical work is required. This position requires highly cross-functional coordination with SAP Internal teams and external vendors.

An ideal candidate should possess the following expertise:

Bachelors or Masters’ in Mathematics, Physics, Computer Science or an equivalent area
At least four years of professional experience, 2 in Data Science
Software Development experience
Proven leadership skills or project management expertise
Proficient in Data mining techniques and data analysis to drive optimization and improvement of solution
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets
Experience querying databases and using statistical computer languages: R, SQL, etc.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Coordinate with different functional and technical teams to implement models and monitor outcomes
Manage relationship with project stakeholders, including internal and external clients, keeping stakeholders informed of progress and issues in order to manage expectations on all project requirements and deliverables
Manage and communicate a clear vision of the project’s objectives, and motivate the project team to achieve them; create a project environment that enables peak performance by team members
Must have hands-on project experience in HANA data modelling
experience in creating Attribute Views, Analytic Views, Graphical and Scripted Calculation Views, Creating Restricted & Calculated Columns

WHAT YOU GET FROM US

Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.

SAP'S DIVERSITY COMMITMENT

To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com).

Successful candidates might be required to undergo a background verification with an external vendor.

Additional Locations:
"
194,https://www.glassdoor.co.in/partner/jobListing.htm?pos=415&ao=4120&s=58&guid=0000016baeac7587be95eddabde7cc60&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_bf2e9554&cb=1562003666779&jobListingId=2859260358,Research Data Scientist,Han Digital Solution, – Bengaluru,"
Job Description :We are looking for candidates who are passionate about a highly demanding and critical role and who want to pursue their career as researchers and to provide problem-solving solutions to meet business process and application requirements.

Roles and Responsibilities :

Ability to tackle a variety of problems that impact the bleeding edge of machine learning and artificial intelligence, with a focus on applications in computer security/ Cyber Security Domain.
The candidates will be part of a highly visible, agile team working on critical problems that directly affect the company's success.
The researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
As part of the research group, you will leverage your problem-solving and analytical skills to further the capabilities of the organization, as well as publish and present new and novel research.
To build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security.
Approaches problems from an adversarial mindset to circumvent prediction systems.
Works with internal product and engineering teams to drive the development of new products.
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve.
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems.
Invests time in research including publications, and is committed to keeping up with AI trends.
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets.
The Lab is based out of Bangalore, India.
2. 5+ years of experience applying statistical/ML algorithms and techniques to real-world data sets.
Expert knowledge of languages such as R or Python.
Proficiency in Probability, Statistics, and Linear Algebra.
Familiarity with Data science platforms, Tools, and frameworks.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment.
Experience with large volumes of data, algorithms, and prototyping.
Strong written and oral skills (in English).
Prefer great appreciation or expertise in Security products such as Endpoint detection, protection, and response, Managed detection and response etc.


Key Job Attributes :

 Deep Learning

 ANN

 Machine Leaning

 Logistic Regression

 Convolutional networks

 Clustering and segmentation

 Sequence modeling

 ARIMA

 NLTK

 Statistician
Educational Qualifications :PG : MS - Computer Science/ Statistics/Operational Research/Applied mathematicsKey Skills :ANN

 ML

 AI

 Deep Learning

 Data Science

 Python

 R

 CART

 SVM

 Operations ResearchContact Details :Email Id : subhendu@handigital.com
"
195,https://www.glassdoor.co.in/partner/jobListing.htm?pos=807&ao=7438&s=58&guid=0000016baeacf03bb33c46098e90a8c6&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&ea=1&cs=1_baee69a7&cb=1562003698137&jobListingId=3206921217,Machine Learning Engineer,Unbxd Inc, – Bengaluru,"
Machine Learning Engineer responsibilities include:



Designing and developing machine learning and deep learning systems
Running machine learning tests and experiments
Implementing appropriate ML algorithms


Job briefWe are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products.

Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.

Your ultimate goal will be to shape and build efficient self-learning applications.Responsibilities



Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field


Requirements



Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Master’s degree is a plus
"
196,https://www.glassdoor.co.in/partner/jobListing.htm?pos=505&ao=433326&s=58&guid=0000016baeac946289d87fba82cd68ad&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_80a1c79a&cb=1562003674682&jobListingId=3159931373,Data Scientist,EdgeVerve Systems, – Bengaluru,"Role Data Scientist  Auto req ID 634BR  State / Region / Province KARNATAKA  Work Location BANGALORE  Company EdgeVerve Systems Ltd  Practice Unit EDGEEV  Job Description· 

Demonstrable experience in Research, design andprototyping robust and scalable models based on machine learning (regression,classification, clustering, time series analysis etc.), data mining, andstatistical modeling to answer key business problems

· 

Ability to quickly build tools and supportstructures needed to analyze data, perform elements of data cleaning, featureselection and feature engineering and organize experiments in conjunction withbest practices

· 

Experience working with or for Financial Institutionin area like Fraud detection / Risk modelling / UW modelling etc. is highlydesired

· 

NLP & Text Mining Experience is a big plus.

· 

Strong understanding of Statistics.

· 

Strong programming background experience inScala / Python for spark and libraries like Pandas, Sklearn, NLTK and etc.

· 

Experience in scalable data management tools -Relational and NoSQL databases

· 

Knowledge of Big Data architectures a strongplus; Have basic knowledge in big data (storage and processing) tools likeHadoop, Hive, Spark and etc.

· 

Knowledge of Pythons data analysis and machinelearning libraries a strong plus; Have experience/knowledge in SparkML andPySpark"
197,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1012&ao=132033&s=58&guid=0000016baead30f6aeffe6cf8d7d0935&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_61ffb8ed&cb=1562003715338&jobListingId=3049402108,Lead Data Engineer,ThoughtWorks, – Bengaluru,"ThoughtWorks India is looking for talented data engineers passionate about building large scale data processing systems to help manage the ever-growing information needs of our clients.

You will be responsible for -


Creating complex data processing pipelines, as part of diverse, high energy teams
Designing scalable implementations of the models developed by our Data Scientists
Hands-on programming in Python, Java, Scala based on TDD, usually in a pair programming environment
Deploying data pipelines in production based on Continuous Delivery practices
Advising clients on the usage of different distributed storage and computing technologies from the plethora of options available in the ecosystem

Ideally, you should have - 


Minimum of 8 years of overall industry experience
5+ years of experience building and deploying large scale data processing pipelines in a production environment
Experience building data pipelines and data centric applications using distributed storage platforms like HDFS, S3, NoSql databases (Hbase, Cassandra, etc) and distributed processing platforms like Hadoop, Spark, Hive, Oozie, Airflow, etc in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions.
Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum
Knowledge of software best practices, like Test-Driven Development (TDD) and Continuous Integration (CI)
Strong communication and client-facing skills with the ability to work in a consulting environment is essential
Senior developers (6+ years) are expected to be the Architect for small and large enterprise projects. On larger projects, you are expected to work closely with the fellow architects to come up with the architecture and take it further.
Desire to contribute to the wider technical community through collaboration, coaching, and mentoring of other technologists

If you relish the idea of being part of a community that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you!

 


#LI-INDIA

 "
198,https://www.glassdoor.co.in/partner/jobListing.htm?pos=1703&ao=651146&s=58&guid=0000016baeae4fcb883179e091fafa57&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_5aab790b&cb=1562003788188&jobListingId=3208231503,OneID Assoc Data Analyst,Neustar, – Bengaluru,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:R-2333 OneID Assoc Data Analyst (Open Date: 04/26/2019)Primary Location:BANGALOREJob Description:

Neustar, Inc. (NYSE: NSR) is a trusted, neutral provider of real-time information and analytics to the communications services, financial services, retail, educational, and media and advertising sectors. Neustar applies its advanced, secure technologies to help its clients promote and protect their businesses. More information is available at www.neustar.biz.

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, continuous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

We are looking for Associate Data Analyst to bring big data, marketing analytics, and database technology together to deliver best-in-class insights. You must be a hands-on data guru who’s passionate about data, database product development, and play well with others. If you have a curiosity for different industries and companies, a passion for data analytics, and skills to create effective and repeatable data transformation and profiling methods, we would like to hear from you.

Data is rarely perfect. We are looking for data analysts who will ensure we have the best data for client marketing insights. You will work in a cross functional team that spans Strategy, Data Management, Analytical Insights, and Product Solutions. You will use a keen eye, an understanding of the client’s industry and business practice, and common sense.

Responsibilities:

Analyze data and identify data pattern to bring insight out of data.Build story around the data findings and explain in simple words.Data discovery and validation.Follow best practices and document the processes.Pay attention to Detail.

Skills and Experience:

Bachelor in computer science/engineering/statistics/economics (master degree preferred).1-3 years of experience in data analysis and exploratory analysis.Have strong analytical thinking and soft skills.Experience in Hive SQL.Strong in MS Excel for data crunching.Good knowledge of Hadoop platform.Should be team person and strong interpersonal skills.

Nice to have:

Experience in digital marketing, campaigning and advertising.Experience in Spark SQL.

Why work with us?

Because you love to build beautiful, innovative solutions that wow the customer.Because you believe in changing the status quo and are up for the challenge of your life.Because you know you can make a difference to people, places and things.

About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

DIVERSITY

Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability

Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY

Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability

Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws."
199,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2229&ao=135191&s=58&guid=0000016baeaee421b9943164e607bbd2&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_34cb8a22&cb=1562003826222&jobListingId=3282995973,Sr Member Technical Staff - Modeling Engineering,Rambus, – Bengaluru,"At Rambus, we are turning incredible possibilities into everyday reality by helping to deliver the innovations that greatly impact the world we live in. We create leading-edge semiconductor and IP products, spanning memory and interfaces to security to smart sensors. Our products are integrated into tens of billions of devices and systems around the globe, running critical applications for Big Data, Internet of Things (IoT), mobile, consumer and media platforms. And our history runs deep – we have been in Silicon Valley for 25+ years and are continually anticipating key technology trends and are developing innovations that drive market changes. From a pure IP provider to becoming a fabless chipmaker, Rambus is evolving to address critical challenges in the semiconductor industry. As a dynamic organization, we are always seeking to hire exceptional talent to join some of the brightest inventors and engineers in the world to explore their passions to develop products that have real life impact. As well, Rambus benefits are among the most comprehensive and competitive in Silicon Valley.Responsible for Co-simulation of mix signal IPs of SERDES and Memory PHY.Designing behavioral models of mixed signal designs for use in functional verification.Developing a generic modeling framework in System Verilog that can be reused for various designs.Documenting the model functionality, architecture and usage model.Electrical/Electronic/CS Engineering degreeExpert in co-simulation methodology and toolset.Prior working experience of System-Verilog and UVM is must.Knowledge of DDR3/4, High Speed SERDES Protocols etc.Clear communication and presentation skills.Relevant Experience – 3 - 6 YearsGood to have - Knowledge of C++, System-C, Verilog-A languages, and modeling Virtual Platforms is appreciated.Hspice/Spectre spice language understandingDSP conceptsRambus offers an extremely competitive compensation package, which includes a strong base salary, bonus, equity, matching 401(k), employee stock purchase plan, comprehensive medical and dental benefits, time-off program and gym membership. Rambus creates cutting-edge semiconductor and IP products, spanning memory and interfaces to security, smart sensors and lighting. Our chips, customizable IP cores, architecture licenses, tools, services, training and innovations improve the competitive advantage of our customers. We collaborate with the industry, partnering with leading ASIC and SoC designers, foundries, IP developers, EDA companies and validation labs. Our products are integrated into tens of billions of devices and systems, powering and securing diverse applications, including Big Data, Internet of Things (IoT), mobile, consumer and media platforms. At Rambus, we are makers of better. For more information about Rambus, visit rambus.com. For additional information on life at Rambus and our current openings, check out rambus.com/careers/."
200,https://www.glassdoor.co.in/partner/jobListing.htm?pos=2420&ao=116277&s=58&guid=0000016baeaf24ef886cc75aedc25f50&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&cs=1_bc7f5572&cb=1562003842921&jobListingId=2479060660,Data Analyst (0-2 Years) for a fastest growing startup company,Zyoin, – Bengaluru,"We are looking for a Data Analyst for one of our esteemed Clients for Bangalore Location.

RESPONSIBILITIES:

Strong knowledge of reporting packages SQL.
Should be very good at Excel, Dash boarding, Business reports.
Strong analytical skills with the ability to collect, organised, analyse, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.

REQUIREMENT:

Interpret data, analyse results using statistical techniques and provide ongoing reports.
Maintaining business dashboards/reports and reporting it to management.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Work closely with management to prioritize business and information needs.
Data cleaning, data collection and data interpretation.
"
